25567/600000: episode: 36, duration: 13.727s, episode steps: 610, steps per second:  44, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.007192, mae: 0.048469, mean_q: 0.077000, mean_eps: 0.949432
  26102/600000: episode: 37, duration: 11.881s, episode steps: 535, steps per second:  45, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.007197, mae: 0.047995, mean_q: 0.064971, mean_eps: 0.948332
  26749/600000: episode: 38, duration: 13.288s, episode steps: 647, steps per second:  49, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.007832, mae: 0.049827, mean_q: 0.069318, mean_eps: 0.947148
  27389/600000: episode: 39, duration: 13.377s, episode steps: 640, steps per second:  48, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.008593, mae: 0.052353, mean_q: 0.071454, mean_eps: 0.945860
  27801/600000: episode: 40, duration: 11.593s, episode steps: 412, steps per second:  36, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007756, mae: 0.049303, mean_q: 0.066817, mean_eps: 0.944808
  28619/600000: episode: 41, duration: 20.870s, episode steps: 818, steps per second:  39, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.005667, mae: 0.045916, mean_q: 0.061772, mean_eps: 0.943580
  29100/600000: episode: 42, duration: 11.896s, episode steps: 481, steps per second:  40, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006351, mae: 0.047218, mean_q: 0.063353, mean_eps: 0.942284
  30430/600000: episode: 43, duration: 34.299s, episode steps: 1330, steps per second:  39, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006854, mae: 0.056752, mean_q: 0.077452, mean_eps: 0.940472
  30915/600000: episode: 44, duration: 12.876s, episode steps: 485, steps per second:  38, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.006967, mae: 0.075569, mean_q: 0.100950, mean_eps: 0.938656
  31393/600000: episode: 45, duration: 13.742s, episode steps: 478, steps per second:  35, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.007352, mae: 0.077938, mean_q: 0.105067, mean_eps: 0.937692
  31889/600000: episode: 46, duration: 15.643s, episode steps: 496, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007012, mae: 0.075264, mean_q: 0.099886, mean_eps: 0.936716
  32302/600000: episode: 47, duration: 13.294s, episode steps: 413, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.005215, mae: 0.073045, mean_q: 0.098104, mean_eps: 0.935808
  32700/600000: episode: 48, duration: 12.556s, episode steps: 398, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006663, mae: 0.074738, mean_q: 0.098791, mean_eps: 0.935000
  33679/600000: episode: 49, duration: 27.840s, episode steps: 979, steps per second:  35, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006680, mae: 0.075783, mean_q: 0.098296, mean_eps: 0.933624
  34219/600000: episode: 50, duration: 13.917s, episode steps: 540, steps per second:  39, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.005836, mae: 0.074384, mean_q: 0.099265, mean_eps: 0.932104
  34803/600000: episode: 51, duration: 18.242s, episode steps: 584, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.007948, mae: 0.078537, mean_q: 0.104225, mean_eps: 0.930980
  35183/600000: episode: 52, duration: 10.296s, episode steps: 380, steps per second:  37, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006342, mae: 0.089967, mean_q: 0.120467, mean_eps: 0.930016
  35975/600000: episode: 53, duration: 20.590s, episode steps: 792, steps per second:  38, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006426, mae: 0.110274, mean_q: 0.145471, mean_eps: 0.928844
  37371/600000: episode: 54, duration: 36.203s, episode steps: 1396, steps per second:  39, episode reward: 26.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.007521, mae: 0.113767, mean_q: 0.149588, mean_eps: 0.926656
  38097/600000: episode: 55, duration: 15.829s, episode steps: 726, steps per second:  46, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.006473, mae: 0.111719, mean_q: 0.151312, mean_eps: 0.924532
  38574/600000: episode: 56, duration: 10.950s, episode steps: 477, steps per second:  44, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.006404, mae: 0.110462, mean_q: 0.146448, mean_eps: 0.923328
  39370/600000: episode: 57, duration: 21.090s, episode steps: 796, steps per second:  38, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.008212, mae: 0.114756, mean_q: 0.148769, mean_eps: 0.922056
  40450/600000: episode: 58, duration: 27.832s, episode steps: 1080, steps per second:  39, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.006724, mae: 0.118900, mean_q: 0.155975, mean_eps: 0.920180
  41236/600000: episode: 59, duration: 22.322s, episode steps: 786, steps per second:  35, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006970, mae: 0.131535, mean_q: 0.175760, mean_eps: 0.918316
  41963/600000: episode: 60, duration: 19.634s, episode steps: 727, steps per second:  37, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007652, mae: 0.134841, mean_q: 0.176893, mean_eps: 0.916804
  42585/600000: episode: 61, duration: 16.734s, episode steps: 622, steps per second:  37, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006968, mae: 0.131612, mean_q: 0.174208, mean_eps: 0.915452
  43608/600000: episode: 62, duration: 30.134s, episode steps: 1023, steps per second:  34, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.006172, mae: 0.130007, mean_q: 0.169714, mean_eps: 0.913808
  44246/600000: episode: 63, duration: 21.486s, episode steps: 638, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006736, mae: 0.132125, mean_q: 0.173226, mean_eps: 0.912148
  44919/600000: episode: 64, duration: 17.417s, episode steps: 673, steps per second:  39, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006570, mae: 0.130996, mean_q: 0.171134, mean_eps: 0.910836
  46020/600000: episode: 65, duration: 32.133s, episode steps: 1101, steps per second:  34, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006454, mae: 0.157954, mean_q: 0.205746, mean_eps: 0.909064
  47064/600000: episode: 66, duration: 32.207s, episode steps: 1044, steps per second:  32, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007594, mae: 0.163424, mean_q: 0.213335, mean_eps: 0.906920
  47792/600000: episode: 67, duration: 23.480s, episode steps: 728, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006755, mae: 0.160794, mean_q: 0.208098, mean_eps: 0.905148
  48392/600000: episode: 68, duration: 15.743s, episode steps: 600, steps per second:  38, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006222, mae: 0.160704, mean_q: 0.209015, mean_eps: 0.903820
  48984/600000: episode: 69, duration: 15.892s, episode steps: 592, steps per second:  37, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.005026, mae: 0.156270, mean_q: 0.203037, mean_eps: 0.902628
  49560/600000: episode: 70, duration: 15.775s, episode steps: 576, steps per second:  37, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.006922, mae: 0.162143, mean_q: 0.209692, mean_eps: 0.901460
  50207/600000: episode: 71, duration: 15.952s, episode steps: 647, steps per second:  41, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006051, mae: 0.168191, mean_q: 0.219356, mean_eps: 0.900236
  51494/600000: episode: 72, duration: 30.365s, episode steps: 1287, steps per second:  42, episode reward: 10.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006819, mae: 0.190966, mean_q: 0.245931, mean_eps: 0.898300
  51895/600000: episode: 73, duration: 9.773s, episode steps: 401, steps per second:  41, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.005939, mae: 0.190177, mean_q: 0.244123, mean_eps: 0.896612
  52387/600000: episode: 74, duration: 12.772s, episode steps: 492, steps per second:  39, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006883, mae: 0.194198, mean_q: 0.250056, mean_eps: 0.895720
  53009/600000: episode: 75, duration: 17.189s, episode steps: 622, steps per second:  36, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.006422, mae: 0.191291, mean_q: 0.243683, mean_eps: 0.894604
  53701/600000: episode: 76, duration: 14.752s, episode steps: 692, steps per second:  47, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.006007, mae: 0.189311, mean_q: 0.240726, mean_eps: 0.893288
  54729/600000: episode: 77, duration: 25.632s, episode steps: 1028, steps per second:  40, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005958, mae: 0.189161, mean_q: 0.241298, mean_eps: 0.891568
  55487/600000: episode: 78, duration: 19.561s, episode steps: 758, steps per second:  39, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.005737, mae: 0.197097, mean_q: 0.251661, mean_eps: 0.889784
  55844/600000: episode: 79, duration: 7.915s, episode steps: 357, steps per second:  45, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006172, mae: 0.204050, mean_q: 0.261521, mean_eps: 0.888672
  56623/600000: episode: 80, duration: 19.847s, episode steps: 779, steps per second:  39, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006014, mae: 0.203377, mean_q: 0.257978, mean_eps: 0.887536
  57612/600000: episode: 81, duration: 25.297s, episode steps: 989, steps per second:  39, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007415, mae: 0.206658, mean_q: 0.261820, mean_eps: 0.885768
  58399/600000: episode: 82, duration: 21.813s, episode steps: 787, steps per second:  36, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.006495, mae: 0.204701, mean_q: 0.260648, mean_eps: 0.883992
  59185/600000: episode: 83, duration: 21.610s, episode steps: 786, steps per second:  36, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.005564, mae: 0.202149, mean_q: 0.257850, mean_eps: 0.882416
  59750/600000: episode: 84, duration: 15.083s, episode steps: 565, steps per second:  37, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005462, mae: 0.201838, mean_q: 0.256853, mean_eps: 0.881064
  60431/600000: episode: 85, duration: 15.505s, episode steps: 681, steps per second:  44, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.006333, mae: 0.227351, mean_q: 0.288803, mean_eps: 0.879820
  61070/600000: episode: 86, duration: 15.871s, episode steps: 639, steps per second:  40, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.007498, mae: 0.239019, mean_q: 0.303110, mean_eps: 0.878500
  61443/600000: episode: 87, duration: 9.929s, episode steps: 373, steps per second:  38, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.008774, mae: 0.245934, mean_q: 0.311243, mean_eps: 0.877488
  62013/600000: episode: 88, duration: 15.923s, episode steps: 570, steps per second:  36, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008773, mae: 0.243769, mean_q: 0.310426, mean_eps: 0.876544
  62844/600000: episode: 89, duration: 21.352s, episode steps: 831, steps per second:  39, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.006755, mae: 0.242089, mean_q: 0.307169, mean_eps: 0.875144
  63493/600000: episode: 90, duration: 16.632s, episode steps: 649, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005574, mae: 0.234456, mean_q: 0.296861, mean_eps: 0.873664
  64291/600000: episode: 91, duration: 22.530s, episode steps: 798, steps per second:  35, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005337, mae: 0.237148, mean_q: 0.299596, mean_eps: 0.872216
  64943/600000: episode: 92, duration: 15.463s, episode steps: 652, steps per second:  42, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.005877, mae: 0.240148, mean_q: 0.303061, mean_eps: 0.870768
  65522/600000: episode: 93, duration: 13.751s, episode steps: 579, steps per second:  42, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.006437, mae: 0.263515, mean_q: 0.332635, mean_eps: 0.869536
  65911/600000: episode: 94, duration: 9.175s, episode steps: 389, steps per second:  42, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.009093, mae: 0.272118, mean_q: 0.344344, mean_eps: 0.868568
  66566/600000: episode: 95, duration: 16.297s, episode steps: 655, steps per second:  40, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.007550, mae: 0.270842, mean_q: 0.341922, mean_eps: 0.867524
  67497/600000: episode: 96, duration: 20.165s, episode steps: 931, steps per second:  46, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006693, mae: 0.269822, mean_q: 0.341119, mean_eps: 0.865936
  68221/600000: episode: 97, duration: 15.915s, episode steps: 724, steps per second:  45, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007568, mae: 0.271672, mean_q: 0.342755, mean_eps: 0.864280
  68889/600000: episode: 98, duration: 18.670s, episode steps: 668, steps per second:  36, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006546, mae: 0.271795, mean_q: 0.345114, mean_eps: 0.862888
  69507/600000: episode: 99, duration: 16.837s, episode steps: 618, steps per second:  37, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006426, mae: 0.269137, mean_q: 0.341428, mean_eps: 0.861604
  70144/600000: episode: 100, duration: 15.559s, episode steps: 637, steps per second:  41, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006600, mae: 0.274605, mean_q: 0.346263, mean_eps: 0.860352
  70536/600000: episode: 101, duration: 9.743s, episode steps: 392, steps per second:  40, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.005568, mae: 0.290448, mean_q: 0.364694, mean_eps: 0.859324
  71176/600000: episode: 102, duration: 18.484s, episode steps: 640, steps per second:  35, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.006424, mae: 0.294697, mean_q: 0.369030, mean_eps: 0.858292
  71954/600000: episode: 103, duration: 21.862s, episode steps: 778, steps per second:  36, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.008047, mae: 0.300087, mean_q: 0.376550, mean_eps: 0.856872
  72351/600000: episode: 104, duration: 11.098s, episode steps: 397, steps per second:  36, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.006211, mae: 0.295424, mean_q: 0.371349, mean_eps: 0.855696
  73017/600000: episode: 105, duration: 18.304s, episode steps: 666, steps per second:  36, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.007518, mae: 0.297126, mean_q: 0.372715, mean_eps: 0.854632
  73843/600000: episode: 106, duration: 20.407s, episode steps: 826, steps per second:  40, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007573, mae: 0.298654, mean_q: 0.375766, mean_eps: 0.853140
  74516/600000: episode: 107, duration: 14.752s, episode steps: 673, steps per second:  46, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.006138, mae: 0.295033, mean_q: 0.370255, mean_eps: 0.851644
  75241/600000: episode: 108, duration: 17.947s, episode steps: 725, steps per second:  40, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007822, mae: 0.315592, mean_q: 0.395931, mean_eps: 0.850244
  75718/600000: episode: 109, duration: 13.010s, episode steps: 477, steps per second:  37, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007390, mae: 0.337274, mean_q: 0.423415, mean_eps: 0.849040
  76208/600000: episode: 110, duration: 13.522s, episode steps: 490, steps per second:  36, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.629 [0.000, 5.000],  loss: 0.007322, mae: 0.340078, mean_q: 0.426479, mean_eps: 0.848076
  76927/600000: episode: 111, duration: 17.912s, episode steps: 719, steps per second:  40, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.007882, mae: 0.349602, mean_q: 0.435478, mean_eps: 0.846868
  77501/600000: episode: 112, duration: 13.753s, episode steps: 574, steps per second:  42, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.007741, mae: 0.340032, mean_q: 0.424434, mean_eps: 0.845572
  78120/600000: episode: 113, duration: 18.189s, episode steps: 619, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.007442, mae: 0.342507, mean_q: 0.428166, mean_eps: 0.844380
  78790/600000: episode: 114, duration: 17.864s, episode steps: 670, steps per second:  38, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.005805, mae: 0.336292, mean_q: 0.420067, mean_eps: 0.843092
  79460/600000: episode: 115, duration: 17.008s, episode steps: 670, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007415, mae: 0.345565, mean_q: 0.431689, mean_eps: 0.841752
  79841/600000: episode: 116, duration: 10.207s, episode steps: 381, steps per second:  37, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.007898, mae: 0.341936, mean_q: 0.427787, mean_eps: 0.840700
  80726/600000: episode: 117, duration: 22.819s, episode steps: 885, steps per second:  39, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007173, mae: 0.357121, mean_q: 0.447336, mean_eps: 0.839432
  81519/600000: episode: 118, duration: 16.665s, episode steps: 793, steps per second:  48, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.007422, mae: 0.366828, mean_q: 0.459725, mean_eps: 0.837756
  82179/600000: episode: 119, duration: 14.978s, episode steps: 660, steps per second:  44, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006898, mae: 0.360180, mean_q: 0.450577, mean_eps: 0.836304
  82692/600000: episode: 120, duration: 14.788s, episode steps: 513, steps per second:  35, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.007715, mae: 0.367427, mean_q: 0.456174, mean_eps: 0.835132
  83103/600000: episode: 121, duration: 11.179s, episode steps: 411, steps per second:  37, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007444, mae: 0.364356, mean_q: 0.454620, mean_eps: 0.834208
  83624/600000: episode: 122, duration: 12.421s, episode steps: 521, steps per second:  42, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006498, mae: 0.362586, mean_q: 0.452153, mean_eps: 0.833276
  84195/600000: episode: 123, duration: 13.991s, episode steps: 571, steps per second:  41, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.008414, mae: 0.367809, mean_q: 0.457749, mean_eps: 0.832184
  84535/600000: episode: 124, duration: 8.146s, episode steps: 340, steps per second:  42, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007526, mae: 0.363025, mean_q: 0.455087, mean_eps: 0.831272
  85029/600000: episode: 125, duration: 12.134s, episode steps: 494, steps per second:  41, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006542, mae: 0.360832, mean_q: 0.451946, mean_eps: 0.830436
  85726/600000: episode: 126, duration: 15.744s, episode steps: 697, steps per second:  44, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008112, mae: 0.378214, mean_q: 0.471920, mean_eps: 0.829244
  86417/600000: episode: 127, duration: 16.304s, episode steps: 691, steps per second:  42, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007773, mae: 0.377836, mean_q: 0.472538, mean_eps: 0.827856
  87111/600000: episode: 128, duration: 17.373s, episode steps: 694, steps per second:  40, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007861, mae: 0.379614, mean_q: 0.474988, mean_eps: 0.826472
  88084/600000: episode: 129, duration: 27.921s, episode steps: 973, steps per second:  35, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.007133, mae: 0.379165, mean_q: 0.472694, mean_eps: 0.824808
  88995/600000: episode: 130, duration: 23.652s, episode steps: 911, steps per second:  39, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.007495, mae: 0.380119, mean_q: 0.472926, mean_eps: 0.822924
  89604/600000: episode: 131, duration: 18.050s, episode steps: 609, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.005970, mae: 0.383491, mean_q: 0.478475, mean_eps: 0.821404
  90000/600000: episode: 132, duration: 11.107s, episode steps: 396, steps per second:  36, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.005849, mae: 0.375702, mean_q: 0.467152, mean_eps: 0.820400
  90637/600000: episode: 133, duration: 17.402s, episode steps: 637, steps per second:  37, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006739, mae: 0.387944, mean_q: 0.481963, mean_eps: 0.819364
  90942/600000: episode: 134, duration: 9.122s, episode steps: 305, steps per second:  33, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.009215, mae: 0.407333, mean_q: 0.507519, mean_eps: 0.818420
  92101/600000: episode: 135, duration: 32.437s, episode steps: 1159, steps per second:  36, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007209, mae: 0.392585, mean_q: 0.489361, mean_eps: 0.816956
  92871/600000: episode: 136, duration: 19.153s, episode steps: 770, steps per second:  40, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006929, mae: 0.393046, mean_q: 0.488919, mean_eps: 0.815028
  93426/600000: episode: 137, duration: 12.794s, episode steps: 555, steps per second:  43, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.007392, mae: 0.402184, mean_q: 0.499897, mean_eps: 0.813704
  94498/600000: episode: 138, duration: 26.075s, episode steps: 1072, steps per second:  41, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.007407, mae: 0.395777, mean_q: 0.493569, mean_eps: 0.812076
  95466/600000: episode: 139, duration: 22.771s, episode steps: 968, steps per second:  43, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.007217, mae: 0.409921, mean_q: 0.510865, mean_eps: 0.810036
  95979/600000: episode: 140, duration: 11.074s, episode steps: 513, steps per second:  46, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.007774, mae: 0.420551, mean_q: 0.524680, mean_eps: 0.808556
  96623/600000: episode: 141, duration: 16.518s, episode steps: 644, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.007984, mae: 0.417078, mean_q: 0.517898, mean_eps: 0.807400
  97296/600000: episode: 142, duration: 19.750s, episode steps: 673, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.008082, mae: 0.416474, mean_q: 0.516701, mean_eps: 0.806084
  97962/600000: episode: 143, duration: 19.168s, episode steps: 666, steps per second:  35, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006018, mae: 0.418983, mean_q: 0.520761, mean_eps: 0.804744
  98694/600000: episode: 144, duration: 19.451s, episode steps: 732, steps per second:  38, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006453, mae: 0.416577, mean_q: 0.516818, mean_eps: 0.803344
  99203/600000: episode: 145, duration: 13.772s, episode steps: 509, steps per second:  37, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007267, mae: 0.419865, mean_q: 0.522233, mean_eps: 0.802104
  99605/600000: episode: 146, duration: 11.705s, episode steps: 402, steps per second:  34, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.008687, mae: 0.416588, mean_q: 0.514054, mean_eps: 0.801192
 100366/600000: episode: 147, duration: 22.157s, episode steps: 761, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006676, mae: 0.430363, mean_q: 0.533564, mean_eps: 0.800028
 100995/600000: episode: 148, duration: 18.898s, episode steps: 629, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.008165, mae: 0.449401, mean_q: 0.557325, mean_eps: 0.798640
 101345/600000: episode: 149, duration: 10.751s, episode steps: 350, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.008381, mae: 0.452597, mean_q: 0.560178, mean_eps: 0.797660
 101742/600000: episode: 150, duration: 12.049s, episode steps: 397, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.006409, mae: 0.443473, mean_q: 0.549723, mean_eps: 0.796912
 102127/600000: episode: 151, duration: 10.012s, episode steps: 385, steps per second:  38, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.006978, mae: 0.450471, mean_q: 0.557464, mean_eps: 0.796132
 102670/600000: episode: 152, duration: 15.430s, episode steps: 543, steps per second:  35, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006935, mae: 0.444186, mean_q: 0.549335, mean_eps: 0.795204
 103058/600000: episode: 153, duration: 12.603s, episode steps: 388, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.007838, mae: 0.449688, mean_q: 0.554929, mean_eps: 0.794272
 103485/600000: episode: 154, duration: 13.477s, episode steps: 427, steps per second:  32, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.008099, mae: 0.455796, mean_q: 0.564080, mean_eps: 0.793456
 104296/600000: episode: 155, duration: 22.493s, episode steps: 811, steps per second:  36, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.008383, mae: 0.448742, mean_q: 0.554008, mean_eps: 0.792220
 104947/600000: episode: 156, duration: 20.425s, episode steps: 651, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.008710, mae: 0.449106, mean_q: 0.554184, mean_eps: 0.790760
 105900/600000: episode: 157, duration: 27.418s, episode steps: 953, steps per second:  35, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.007837, mae: 0.480499, mean_q: 0.594481, mean_eps: 0.789156
 107035/600000: episode: 158, duration: 29.383s, episode steps: 1135, steps per second:  39, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.007208, mae: 0.486579, mean_q: 0.601692, mean_eps: 0.787068
 108088/600000: episode: 159, duration: 25.358s, episode steps: 1053, steps per second:  42, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007751, mae: 0.483224, mean_q: 0.598123, mean_eps: 0.784880
 108723/600000: episode: 160, duration: 13.691s, episode steps: 635, steps per second:  46, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007832, mae: 0.489155, mean_q: 0.605376, mean_eps: 0.783192
 109363/600000: episode: 161, duration: 13.505s, episode steps: 640, steps per second:  47, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007070, mae: 0.486723, mean_q: 0.599550, mean_eps: 0.781916
 110740/600000: episode: 162, duration: 35.401s, episode steps: 1377, steps per second:  39, episode reward: 21.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.008350, mae: 0.508196, mean_q: 0.626906, mean_eps: 0.779900
 111124/600000: episode: 163, duration: 9.538s, episode steps: 384, steps per second:  40, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.008587, mae: 0.515893, mean_q: 0.635833, mean_eps: 0.778140
 111746/600000: episode: 164, duration: 15.085s, episode steps: 622, steps per second:  41, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007938, mae: 0.520304, mean_q: 0.642876, mean_eps: 0.777132
 112466/600000: episode: 165, duration: 21.732s, episode steps: 720, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.008766, mae: 0.522897, mean_q: 0.644470, mean_eps: 0.775788
 113286/600000: episode: 166, duration: 25.042s, episode steps: 820, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007835, mae: 0.513035, mean_q: 0.631893, mean_eps: 0.774248
 114459/600000: episode: 167, duration: 37.379s, episode steps: 1173, steps per second:  31, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.008347, mae: 0.527101, mean_q: 0.649357, mean_eps: 0.772256
 115655/600000: episode: 168, duration: 34.257s, episode steps: 1196, steps per second:  35, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.007919, mae: 0.541225, mean_q: 0.667188, mean_eps: 0.769888
 116321/600000: episode: 169, duration: 21.495s, episode steps: 666, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.808 [0.000, 5.000],  loss: 0.009281, mae: 0.573760, mean_q: 0.706606, mean_eps: 0.768024
 116816/600000: episode: 170, duration: 14.763s, episode steps: 495, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.824 [0.000, 5.000],  loss: 0.008638, mae: 0.561913, mean_q: 0.691607, mean_eps: 0.766864
 117871/600000: episode: 171, duration: 26.794s, episode steps: 1055, steps per second:  39, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.009550, mae: 0.571862, mean_q: 0.703327, mean_eps: 0.765316
 118529/600000: episode: 172, duration: 16.851s, episode steps: 658, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.007987, mae: 0.567675, mean_q: 0.696830, mean_eps: 0.763600
 119559/600000: episode: 173, duration: 23.568s, episode steps: 1030, steps per second:  44, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.008382, mae: 0.566790, mean_q: 0.696843, mean_eps: 0.761912
 120233/600000: episode: 174, duration: 14.937s, episode steps: 674, steps per second:  45, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.008686, mae: 0.574054, mean_q: 0.707056, mean_eps: 0.760208
 120868/600000: episode: 175, duration: 16.499s, episode steps: 635, steps per second:  38, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.009296, mae: 0.594301, mean_q: 0.731253, mean_eps: 0.758900
 121619/600000: episode: 176, duration: 18.350s, episode steps: 751, steps per second:  41, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.010151, mae: 0.590827, mean_q: 0.728035, mean_eps: 0.757516
 122250/600000: episode: 177, duration: 13.735s, episode steps: 631, steps per second:  46, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.007631, mae: 0.584742, mean_q: 0.720558, mean_eps: 0.756132
 122885/600000: episode: 178, duration: 13.269s, episode steps: 635, steps per second:  48, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.009352, mae: 0.597816, mean_q: 0.735247, mean_eps: 0.754864
 123590/600000: episode: 179, duration: 21.152s, episode steps: 705, steps per second:  33, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.008016, mae: 0.592373, mean_q: 0.729917, mean_eps: 0.753524
 124405/600000: episode: 180, duration: 20.086s, episode steps: 815, steps per second:  41, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.008178, mae: 0.589016, mean_q: 0.723205, mean_eps: 0.752004
 125872/600000: episode: 181, duration: 36.651s, episode steps: 1467, steps per second:  40, episode reward: 27.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.008743, mae: 0.619246, mean_q: 0.760346, mean_eps: 0.749724
 126643/600000: episode: 182, duration: 19.628s, episode steps: 771, steps per second:  39, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.009443, mae: 0.630838, mean_q: 0.776451, mean_eps: 0.747488
 127286/600000: episode: 183, duration: 15.423s, episode steps: 643, steps per second:  42, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.008794, mae: 0.637845, mean_q: 0.784742, mean_eps: 0.746072
 127856/600000: episode: 184, duration: 14.088s, episode steps: 570, steps per second:  40, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.008694, mae: 0.626149, mean_q: 0.769092, mean_eps: 0.744860
 128533/600000: episode: 185, duration: 16.972s, episode steps: 677, steps per second:  40, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.009933, mae: 0.624921, mean_q: 0.765388, mean_eps: 0.743612
 129433/600000: episode: 186, duration: 19.965s, episode steps: 900, steps per second:  45, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.008634, mae: 0.633072, mean_q: 0.777070, mean_eps: 0.742032
 129903/600000: episode: 187, duration: 11.580s, episode steps: 470, steps per second:  41, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.010461, mae: 0.629567, mean_q: 0.772529, mean_eps: 0.740664
 130555/600000: episode: 188, duration: 15.564s, episode steps: 652, steps per second:  42, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.008554, mae: 0.659876, mean_q: 0.810408, mean_eps: 0.739544
 131223/600000: episode: 189, duration: 17.899s, episode steps: 668, steps per second:  37, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008659, mae: 0.662960, mean_q: 0.814015, mean_eps: 0.738224
 131630/600000: episode: 190, duration: 10.361s, episode steps: 407, steps per second:  39, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.008204, mae: 0.659170, mean_q: 0.809116, mean_eps: 0.737148
 132315/600000: episode: 191, duration: 18.065s, episode steps: 685, steps per second:  38, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.009825, mae: 0.652934, mean_q: 0.801106, mean_eps: 0.736056
 132718/600000: episode: 192, duration: 12.472s, episode steps: 403, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.007545, mae: 0.658989, mean_q: 0.808893, mean_eps: 0.734968
 133271/600000: episode: 193, duration: 15.541s, episode steps: 553, steps per second:  36, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.729 [0.000, 5.000],  loss: 0.008891, mae: 0.650100, mean_q: 0.795196, mean_eps: 0.734012
 133956/600000: episode: 194, duration: 17.578s, episode steps: 685, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.008381, mae: 0.647598, mean_q: 0.792667, mean_eps: 0.732776
 134471/600000: episode: 195, duration: 13.027s, episode steps: 515, steps per second:  40, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.009391, mae: 0.659122, mean_q: 0.806786, mean_eps: 0.731576
 134926/600000: episode: 196, duration: 11.768s, episode steps: 455, steps per second:  39, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.008705, mae: 0.653760, mean_q: 0.800127, mean_eps: 0.730604
 135999/600000: episode: 197, duration: 28.265s, episode steps: 1073, steps per second:  38, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.008880, mae: 0.672882, mean_q: 0.824910, mean_eps: 0.729076
 136722/600000: episode: 198, duration: 17.464s, episode steps: 723, steps per second:  41, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.008276, mae: 0.673648, mean_q: 0.825781, mean_eps: 0.727280
 137123/600000: episode: 199, duration: 10.460s, episode steps: 401, steps per second:  38, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.008269, mae: 0.676384, mean_q: 0.827368, mean_eps: 0.726156
 138007/600000: episode: 200, duration: 27.880s, episode steps: 884, steps per second:  32, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007591, mae: 0.675753, mean_q: 0.828309, mean_eps: 0.724872
 138913/600000: episode: 201, duration: 26.608s, episode steps: 906, steps per second:  34, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.009424, mae: 0.674447, mean_q: 0.824694, mean_eps: 0.723080
 139314/600000: episode: 202, duration: 11.934s, episode steps: 401, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.007419, mae: 0.674347, mean_q: 0.825668, mean_eps: 0.721772
 140104/600000: episode: 203, duration: 21.816s, episode steps: 790, steps per second:  36, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008268, mae: 0.679754, mean_q: 0.832064, mean_eps: 0.720584
 141218/600000: episode: 204, duration: 33.319s, episode steps: 1114, steps per second:  33, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.009401, mae: 0.713765, mean_q: 0.874643, mean_eps: 0.718680
 142181/600000: episode: 205, duration: 28.737s, episode steps: 963, steps per second:  34, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007947, mae: 0.709156, mean_q: 0.868712, mean_eps: 0.716600
 142668/600000: episode: 206, duration: 12.566s, episode steps: 487, steps per second:  39, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.010360, mae: 0.719026, mean_q: 0.878613, mean_eps: 0.715152
 143276/600000: episode: 207, duration: 15.573s, episode steps: 608, steps per second:  39, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.009465, mae: 0.718479, mean_q: 0.879125, mean_eps: 0.714060
 143656/600000: episode: 208, duration: 9.149s, episode steps: 380, steps per second:  42, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.009331, mae: 0.724850, mean_q: 0.886644, mean_eps: 0.713072
 144020/600000: episode: 209, duration: 8.415s, episode steps: 364, steps per second:  43, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.008478, mae: 0.707184, mean_q: 0.865749, mean_eps: 0.712328
 144558/600000: episode: 210, duration: 13.983s, episode steps: 538, steps per second:  38, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.009715, mae: 0.723230, mean_q: 0.887079, mean_eps: 0.711424
 145055/600000: episode: 211, duration: 11.457s, episode steps: 497, steps per second:  43, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.009368, mae: 0.711921, mean_q: 0.871538, mean_eps: 0.710388
 145585/600000: episode: 212, duration: 12.160s, episode steps: 530, steps per second:  44, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.009145, mae: 0.747525, mean_q: 0.915859, mean_eps: 0.709360
 146196/600000: episode: 213, duration: 16.823s, episode steps: 611, steps per second:  36, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.009628, mae: 0.734459, mean_q: 0.899497, mean_eps: 0.708220
 147019/600000: episode: 214, duration: 22.538s, episode steps: 823, steps per second:  37, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.010514, mae: 0.740815, mean_q: 0.907618, mean_eps: 0.706788
 148043/600000: episode: 215, duration: 26.782s, episode steps: 1024, steps per second:  38, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.008944, mae: 0.738653, mean_q: 0.905040, mean_eps: 0.704940
 148995/600000: episode: 216, duration: 23.593s, episode steps: 952, steps per second:  40, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.010175, mae: 0.744198, mean_q: 0.910045, mean_eps: 0.702964
 149932/600000: episode: 217, duration: 21.837s, episode steps: 937, steps per second:  43, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008056, mae: 0.750004, mean_q: 0.919248, mean_eps: 0.701076
 150651/600000: episode: 218, duration: 18.975s, episode steps: 719, steps per second:  38, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.009187, mae: 0.760739, mean_q: 0.931204, mean_eps: 0.699420
 151090/600000: episode: 219, duration: 12.232s, episode steps: 439, steps per second:  36, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.009990, mae: 0.761560, mean_q: 0.932829, mean_eps: 0.698260
 151892/600000: episode: 220, duration: 22.046s, episode steps: 802, steps per second:  36, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.009547, mae: 0.759163, mean_q: 0.927906, mean_eps: 0.697020
 152274/600000: episode: 221, duration: 8.427s, episode steps: 382, steps per second:  45, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.011545, mae: 0.775301, mean_q: 0.946129, mean_eps: 0.695836
 153496/600000: episode: 222, duration: 32.750s, episode steps: 1222, steps per second:  37, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.008692, mae: 0.758323, mean_q: 0.927740, mean_eps: 0.694232
 154324/600000: episode: 223, duration: 21.090s, episode steps: 828, steps per second:  39, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010105, mae: 0.756391, mean_q: 0.925019, mean_eps: 0.692184
 154934/600000: episode: 224, duration: 16.816s, episode steps: 610, steps per second:  36, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.008073, mae: 0.767391, mean_q: 0.938659, mean_eps: 0.690744
 156075/600000: episode: 225, duration: 34.017s, episode steps: 1141, steps per second:  34, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.009978, mae: 0.778061, mean_q: 0.951240, mean_eps: 0.688992
 156568/600000: episode: 226, duration: 10.566s, episode steps: 493, steps per second:  47, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.009530, mae: 0.763605, mean_q: 0.934151, mean_eps: 0.687360
 157342/600000: episode: 227, duration: 19.435s, episode steps: 774, steps per second:  40, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.009477, mae: 0.778931, mean_q: 0.952663, mean_eps: 0.686092
 157976/600000: episode: 228, duration: 14.959s, episode steps: 634, steps per second:  42, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.009435, mae: 0.777502, mean_q: 0.949311, mean_eps: 0.684684
 158392/600000: episode: 229, duration: 10.706s, episode steps: 416, steps per second:  39, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.010446, mae: 0.772030, mean_q: 0.944251, mean_eps: 0.683636
 159270/600000: episode: 230, duration: 21.695s, episode steps: 878, steps per second:  40, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.009651, mae: 0.783086, mean_q: 0.955998, mean_eps: 0.682340
 159791/600000: episode: 231, duration: 14.079s, episode steps: 521, steps per second:  37, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010052, mae: 0.780121, mean_q: 0.953871, mean_eps: 0.680940
 160308/600000: episode: 232, duration: 15.072s, episode steps: 517, steps per second:  34, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.009554, mae: 0.789359, mean_q: 0.966707, mean_eps: 0.679904
 160674/600000: episode: 233, duration: 10.251s, episode steps: 366, steps per second:  36, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.009000, mae: 0.787970, mean_q: 0.962615, mean_eps: 0.679020
 161339/600000: episode: 234, duration: 16.795s, episode steps: 665, steps per second:  40, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.010048, mae: 0.797431, mean_q: 0.975242, mean_eps: 0.677988
 161839/600000: episode: 235, duration: 12.379s, episode steps: 500, steps per second:  40, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.009192, mae: 0.792590, mean_q: 0.969976, mean_eps: 0.676824
 162362/600000: episode: 236, duration: 13.076s, episode steps: 523, steps per second:  40, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.010973, mae: 0.792666, mean_q: 0.968852, mean_eps: 0.675800
 163044/600000: episode: 237, duration: 16.206s, episode steps: 682, steps per second:  42, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.008246, mae: 0.793610, mean_q: 0.971082, mean_eps: 0.674596
 163578/600000: episode: 238, duration: 11.408s, episode steps: 534, steps per second:  47, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.010200, mae: 0.794009, mean_q: 0.970188, mean_eps: 0.673380
 164216/600000: episode: 239, duration: 13.780s, episode steps: 638, steps per second:  46, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.009300, mae: 0.800833, mean_q: 0.979189, mean_eps: 0.672208
 164723/600000: episode: 240, duration: 13.336s, episode steps: 507, steps per second:  38, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.010282, mae: 0.802594, mean_q: 0.981081, mean_eps: 0.671064
 165231/600000: episode: 241, duration: 14.252s, episode steps: 508, steps per second:  36, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.007898, mae: 0.799380, mean_q: 0.978578, mean_eps: 0.670048
 165883/600000: episode: 242, duration: 16.750s, episode steps: 652, steps per second:  39, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.010733, mae: 0.821586, mean_q: 1.005016, mean_eps: 0.668888
 166541/600000: episode: 243, duration: 15.811s, episode steps: 658, steps per second:  42, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.010986, mae: 0.830547, mean_q: 1.017291, mean_eps: 0.667576
 167108/600000: episode: 244, duration: 13.688s, episode steps: 567, steps per second:  41, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.009782, mae: 0.809931, mean_q: 0.991423, mean_eps: 0.666352
 167624/600000: episode: 245, duration: 13.245s, episode steps: 516, steps per second:  39, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.011648, mae: 0.817172, mean_q: 0.999748, mean_eps: 0.665272
 168129/600000: episode: 246, duration: 12.674s, episode steps: 505, steps per second:  40, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.009238, mae: 0.812085, mean_q: 0.995149, mean_eps: 0.664248
 169055/600000: episode: 247, duration: 23.823s, episode steps: 926, steps per second:  39, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.009212, mae: 0.819689, mean_q: 1.002409, mean_eps: 0.662816
 170142/600000: episode: 248, duration: 33.827s, episode steps: 1087, steps per second:  32, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.010663, mae: 0.822511, mean_q: 1.005627, mean_eps: 0.660804
 170917/600000: episode: 249, duration: 19.959s, episode steps: 775, steps per second:  39, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.009950, mae: 0.877176, mean_q: 1.071972, mean_eps: 0.658940
 171562/600000: episode: 250, duration: 20.406s, episode steps: 645, steps per second:  32, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.008799, mae: 0.877106, mean_q: 1.071164, mean_eps: 0.657520
 171954/600000: episode: 251, duration: 11.013s, episode steps: 392, steps per second:  36, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.009050, mae: 0.873440, mean_q: 1.067535, mean_eps: 0.656484
 173154/600000: episode: 252, duration: 33.232s, episode steps: 1200, steps per second:  36, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.009442, mae: 0.860432, mean_q: 1.052624, mean_eps: 0.654892
 173571/600000: episode: 253, duration: 10.872s, episode steps: 417, steps per second:  38, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.736 [0.000, 5.000],  loss: 0.009910, mae: 0.869455, mean_q: 1.062368, mean_eps: 0.653276
 174287/600000: episode: 254, duration: 19.936s, episode steps: 716, steps per second:  36, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.011103, mae: 0.875376, mean_q: 1.069015, mean_eps: 0.652144
 174745/600000: episode: 255, duration: 10.446s, episode steps: 458, steps per second:  44, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.010645, mae: 0.871060, mean_q: 1.062826, mean_eps: 0.650968
 175245/600000: episode: 256, duration: 11.107s, episode steps: 500, steps per second:  45, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.010266, mae: 0.914808, mean_q: 1.116328, mean_eps: 0.650008
 176182/600000: episode: 257, duration: 22.076s, episode steps: 937, steps per second:  42, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.010043, mae: 0.921781, mean_q: 1.124809, mean_eps: 0.648572
 176809/600000: episode: 258, duration: 14.787s, episode steps: 627, steps per second:  42, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.010906, mae: 0.917796, mean_q: 1.120407, mean_eps: 0.647008
 177760/600000: episode: 259, duration: 21.169s, episode steps: 951, steps per second:  45, episode reward:  9.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.010152, mae: 0.918164, mean_q: 1.120656, mean_eps: 0.645432
 178591/600000: episode: 260, duration: 19.032s, episode steps: 831, steps per second:  44, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.011950, mae: 0.927090, mean_q: 1.130771, mean_eps: 0.643652
 178981/600000: episode: 261, duration: 10.619s, episode steps: 390, steps per second:  37, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.008662, mae: 0.928134, mean_q: 1.133719, mean_eps: 0.642428
 180063/600000: episode: 262, duration: 28.070s, episode steps: 1082, steps per second:  39, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.009283, mae: 0.935834, mean_q: 1.142427, mean_eps: 0.640956
 180658/600000: episode: 263, duration: 16.315s, episode steps: 595, steps per second:  36, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.010615, mae: 0.942380, mean_q: 1.151974, mean_eps: 0.639280
 181316/600000: episode: 264, duration: 17.527s, episode steps: 658, steps per second:  38, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.012188, mae: 0.938463, mean_q: 1.145663, mean_eps: 0.638028
 182050/600000: episode: 265, duration: 22.057s, episode steps: 734, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.011894, mae: 0.930121, mean_q: 1.135782, mean_eps: 0.636636
 182709/600000: episode: 266, duration: 17.332s, episode steps: 659, steps per second:  38, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.010460, mae: 0.918469, mean_q: 1.121486, mean_eps: 0.635240
 183107/600000: episode: 267, duration: 12.308s, episode steps: 398, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.010608, mae: 0.921584, mean_q: 1.124428, mean_eps: 0.634184
 183482/600000: episode: 268, duration: 11.104s, episode steps: 375, steps per second:  34, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.010698, mae: 0.933613, mean_q: 1.142720, mean_eps: 0.633412
 184153/600000: episode: 269, duration: 18.782s, episode steps: 671, steps per second:  36, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.010087, mae: 0.918858, mean_q: 1.123706, mean_eps: 0.632364
 185282/600000: episode: 270, duration: 30.780s, episode steps: 1129, steps per second:  37, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.010614, mae: 0.940511, mean_q: 1.148075, mean_eps: 0.630564
 185806/600000: episode: 271, duration: 15.994s, episode steps: 524, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.011180, mae: 0.982752, mean_q: 1.199721, mean_eps: 0.628912
 186556/600000: episode: 272, duration: 19.808s, episode steps: 750, steps per second:  38, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010373, mae: 0.974164, mean_q: 1.191143, mean_eps: 0.627640
 187097/600000: episode: 273, duration: 15.531s, episode steps: 541, steps per second:  35, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.009361, mae: 0.957628, mean_q: 1.168412, mean_eps: 0.626348
 187747/600000: episode: 274, duration: 18.632s, episode steps: 650, steps per second:  35, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.010421, mae: 0.965879, mean_q: 1.178085, mean_eps: 0.625156
 188264/600000: episode: 275, duration: 13.753s, episode steps: 517, steps per second:  38, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.195 [0.000, 5.000],  loss: 0.010169, mae: 0.966751, mean_q: 1.180902, mean_eps: 0.623992
 189103/600000: episode: 276, duration: 18.832s, episode steps: 839, steps per second:  45, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010053, mae: 0.965438, mean_q: 1.178162, mean_eps: 0.622636
 189579/600000: episode: 277, duration: 12.703s, episode steps: 476, steps per second:  37, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.008994, mae: 0.969607, mean_q: 1.183539, mean_eps: 0.621320
 190377/600000: episode: 278, duration: 21.456s, episode steps: 798, steps per second:  37, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.010700, mae: 0.984073, mean_q: 1.201252, mean_eps: 0.620044
 191040/600000: episode: 279, duration: 15.120s, episode steps: 663, steps per second:  44, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.012065, mae: 0.976384, mean_q: 1.190633, mean_eps: 0.618584
 191827/600000: episode: 280, duration: 18.864s, episode steps: 787, steps per second:  42, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011412, mae: 0.971155, mean_q: 1.185377, mean_eps: 0.617136
 192787/600000: episode: 281, duration: 28.103s, episode steps: 960, steps per second:  34, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.010862, mae: 0.966581, mean_q: 1.179634, mean_eps: 0.615388
 193441/600000: episode: 282, duration: 16.067s, episode steps: 654, steps per second:  41, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.010589, mae: 0.975633, mean_q: 1.192968, mean_eps: 0.613772
 194053/600000: episode: 283, duration: 17.861s, episode steps: 612, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.011744, mae: 0.977029, mean_q: 1.194202, mean_eps: 0.612504
 194958/600000: episode: 284, duration: 27.077s, episode steps: 905, steps per second:  33, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.011135, mae: 0.982286, mean_q: 1.200307, mean_eps: 0.610988
 195574/600000: episode: 285, duration: 16.992s, episode steps: 616, steps per second:  36, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.011061, mae: 0.994552, mean_q: 1.214507, mean_eps: 0.609468
 196440/600000: episode: 286, duration: 25.235s, episode steps: 866, steps per second:  34, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.010714, mae: 0.994128, mean_q: 1.213761, mean_eps: 0.607988
 196932/600000: episode: 287, duration: 14.131s, episode steps: 492, steps per second:  35, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.012767, mae: 1.017149, mean_q: 1.241692, mean_eps: 0.606632
 197304/600000: episode: 288, duration: 9.245s, episode steps: 372, steps per second:  40, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.011173, mae: 0.991746, mean_q: 1.211772, mean_eps: 0.605768
 197952/600000: episode: 289, duration: 16.829s, episode steps: 648, steps per second:  39, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.011071, mae: 0.994637, mean_q: 1.216261, mean_eps: 0.604748
 198369/600000: episode: 290, duration: 11.613s, episode steps: 417, steps per second:  36, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.909 [0.000, 5.000],  loss: 0.011841, mae: 1.003844, mean_q: 1.226873, mean_eps: 0.603680
 198861/600000: episode: 291, duration: 13.318s, episode steps: 492, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.010499, mae: 0.986672, mean_q: 1.206515, mean_eps: 0.602768
 199341/600000: episode: 292, duration: 13.109s, episode steps: 480, steps per second:  37, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.011094, mae: 1.013251, mean_q: 1.236460, mean_eps: 0.601796
 199833/600000: episode: 293, duration: 12.748s, episode steps: 492, steps per second:  39, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.011936, mae: 1.008276, mean_q: 1.230892, mean_eps: 0.600824
 200639/600000: episode: 294, duration: 22.540s, episode steps: 806, steps per second:  36, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.011076, mae: 1.016931, mean_q: 1.242571, mean_eps: 0.599528
 201040/600000: episode: 295, duration: 11.417s, episode steps: 401, steps per second:  35, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.008927, mae: 1.017701, mean_q: 1.244551, mean_eps: 0.598324
 201619/600000: episode: 296, duration: 15.870s, episode steps: 579, steps per second:  36, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.010772, mae: 1.017260, mean_q: 1.242097, mean_eps: 0.597344
 202290/600000: episode: 297, duration: 15.824s, episode steps: 671, steps per second:  42, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.011575, mae: 1.013990, mean_q: 1.237479, mean_eps: 0.596092
 203401/600000: episode: 298, duration: 26.745s, episode steps: 1111, steps per second:  42, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.010643, mae: 1.023775, mean_q: 1.249637, mean_eps: 0.594308
 204072/600000: episode: 299, duration: 15.943s, episode steps: 671, steps per second:  42, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.010621, mae: 1.015678, mean_q: 1.240058, mean_eps: 0.592528
 204681/600000: episode: 300, duration: 13.308s, episode steps: 609, steps per second:  46, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.801 [0.000, 5.000],  loss: 0.010474, mae: 1.016196, mean_q: 1.241070, mean_eps: 0.591248
 205549/600000: episode: 301, duration: 21.120s, episode steps: 868, steps per second:  41, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.010835, mae: 1.040066, mean_q: 1.270610, mean_eps: 0.589768
 206302/600000: episode: 302, duration: 22.365s, episode steps: 753, steps per second:  34, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.011655, mae: 1.054885, mean_q: 1.288209, mean_eps: 0.588148
 207358/600000: episode: 303, duration: 24.970s, episode steps: 1056, steps per second:  42, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.013004, mae: 1.048377, mean_q: 1.278967, mean_eps: 0.586340
 207867/600000: episode: 304, duration: 13.336s, episode steps: 509, steps per second:  38, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.012858, mae: 1.040571, mean_q: 1.269600, mean_eps: 0.584776
 208417/600000: episode: 305, duration: 14.722s, episode steps: 550, steps per second:  37, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.011298, mae: 1.044932, mean_q: 1.274794, mean_eps: 0.583716
 208796/600000: episode: 306, duration: 11.447s, episode steps: 379, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.010648, mae: 1.040410, mean_q: 1.271807, mean_eps: 0.582788
 209187/600000: episode: 307, duration: 11.948s, episode steps: 391, steps per second:  33, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.009255, mae: 1.038367, mean_q: 1.266770, mean_eps: 0.582020
 209879/600000: episode: 308, duration: 20.111s, episode steps: 692, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.012593, mae: 1.048326, mean_q: 1.280259, mean_eps: 0.580936
 210387/600000: episode: 309, duration: 14.295s, episode steps: 508, steps per second:  36, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.011301, mae: 1.097550, mean_q: 1.342473, mean_eps: 0.579736
 211041/600000: episode: 310, duration: 17.095s, episode steps: 654, steps per second:  38, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.011679, mae: 1.085944, mean_q: 1.327641, mean_eps: 0.578572
 211975/600000: episode: 311, duration: 26.632s, episode steps: 934, steps per second:  35, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.010648, mae: 1.095363, mean_q: 1.338043, mean_eps: 0.576984
 212518/600000: episode: 312, duration: 15.718s, episode steps: 543, steps per second:  35, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.011073, mae: 1.090529, mean_q: 1.332832, mean_eps: 0.575508
 213223/600000: episode: 313, duration: 20.564s, episode steps: 705, steps per second:  34, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.011529, mae: 1.098316, mean_q: 1.340919, mean_eps: 0.574260
 213731/600000: episode: 314, duration: 13.409s, episode steps: 508, steps per second:  38, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.011310, mae: 1.101161, mean_q: 1.345130, mean_eps: 0.573048
 214650/600000: episode: 315, duration: 29.493s, episode steps: 919, steps per second:  31, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.011213, mae: 1.094628, mean_q: 1.337997, mean_eps: 0.571620
 215222/600000: episode: 316, duration: 14.996s, episode steps: 572, steps per second:  38, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.011601, mae: 1.090641, mean_q: 1.330117, mean_eps: 0.570128
 215978/600000: episode: 317, duration: 18.454s, episode steps: 756, steps per second:  41, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.010631, mae: 1.099665, mean_q: 1.343300, mean_eps: 0.568800
 216472/600000: episode: 318, duration: 12.557s, episode steps: 494, steps per second:  39, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.013181, mae: 1.086657, mean_q: 1.325560, mean_eps: 0.567552
 217577/600000: episode: 319, duration: 27.382s, episode steps: 1105, steps per second:  40, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.012561, mae: 1.092491, mean_q: 1.333786, mean_eps: 0.565952
 218198/600000: episode: 320, duration: 13.524s, episode steps: 621, steps per second:  46, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.011709, mae: 1.100300, mean_q: 1.343755, mean_eps: 0.564224
 219324/600000: episode: 321, duration: 33.198s, episode steps: 1126, steps per second:  34, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.011604, mae: 1.095647, mean_q: 1.339835, mean_eps: 0.562480
 220028/600000: episode: 322, duration: 18.916s, episode steps: 704, steps per second:  37, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.011685, mae: 1.109252, mean_q: 1.353692, mean_eps: 0.560652
 221145/600000: episode: 323, duration: 26.919s, episode steps: 1117, steps per second:  41, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.011162, mae: 1.119551, mean_q: 1.368284, mean_eps: 0.558828
 221658/600000: episode: 324, duration: 13.064s, episode steps: 513, steps per second:  39, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.010779, mae: 1.125107, mean_q: 1.375985, mean_eps: 0.557196
 222473/600000: episode: 325, duration: 18.736s, episode steps: 815, steps per second:  43, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.011544, mae: 1.116011, mean_q: 1.364838, mean_eps: 0.555868
 223026/600000: episode: 326, duration: 13.214s, episode steps: 553, steps per second:  42, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.012446, mae: 1.108305, mean_q: 1.352469, mean_eps: 0.554500
 223548/600000: episode: 327, duration: 11.636s, episode steps: 522, steps per second:  45, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.011844, mae: 1.124900, mean_q: 1.373221, mean_eps: 0.553428
 224088/600000: episode: 328, duration: 10.912s, episode steps: 540, steps per second:  49, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.012868, mae: 1.129680, mean_q: 1.378555, mean_eps: 0.552368
 224660/600000: episode: 329, duration: 16.293s, episode steps: 572, steps per second:  35, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.012072, mae: 1.117685, mean_q: 1.364322, mean_eps: 0.551256
 225163/600000: episode: 330, duration: 8.746s, episode steps: 503, steps per second:  58, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.010145, mae: 1.118209, mean_q: 1.365533, mean_eps: 0.550180
 225866/600000: episode: 331, duration: 12.742s, episode steps: 703, steps per second:  55, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.010674, mae: 1.159074, mean_q: 1.414056, mean_eps: 0.548972
 226547/600000: episode: 332, duration: 11.979s, episode steps: 681, steps per second:  57, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.872 [0.000, 5.000],  loss: 0.013336, mae: 1.165883, mean_q: 1.422156, mean_eps: 0.547588
 227087/600000: episode: 333, duration: 9.171s, episode steps: 540, steps per second:  59, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.980 [0.000, 5.000],  loss: 0.014322, mae: 1.169056, mean_q: 1.425874, mean_eps: 0.546368
 227671/600000: episode: 334, duration: 10.116s, episode steps: 584, steps per second:  58, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.013200, mae: 1.165801, mean_q: 1.423289, mean_eps: 0.545244
 228143/600000: episode: 335, duration: 7.959s, episode steps: 472, steps per second:  59, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.011693, mae: 1.171013, mean_q: 1.430434, mean_eps: 0.544188
 228763/600000: episode: 336, duration: 10.198s, episode steps: 620, steps per second:  61, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.011936, mae: 1.163492, mean_q: 1.419749, mean_eps: 0.543096
 229393/600000: episode: 337, duration: 11.154s, episode steps: 630, steps per second:  56, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.012193, mae: 1.157469, mean_q: 1.412369, mean_eps: 0.541844
 230376/600000: episode: 338, duration: 20.074s, episode steps: 983, steps per second:  49, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.011345, mae: 1.159403, mean_q: 1.413997, mean_eps: 0.540232
 231117/600000: episode: 339, duration: 16.051s, episode steps: 741, steps per second:  46, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.011083, mae: 1.170909, mean_q: 1.428187, mean_eps: 0.538508
 231809/600000: episode: 340, duration: 12.919s, episode steps: 692, steps per second:  54, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.011368, mae: 1.171890, mean_q: 1.428542, mean_eps: 0.537072
 232292/600000: episode: 341, duration: 8.699s, episode steps: 483, steps per second:  56, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.015055, mae: 1.165203, mean_q: 1.422543, mean_eps: 0.535900
 232800/600000: episode: 342, duration: 9.581s, episode steps: 508, steps per second:  53, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.013296, mae: 1.188829, mean_q: 1.448245, mean_eps: 0.534912
 233445/600000: episode: 343, duration: 12.573s, episode steps: 645, steps per second:  51, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.013106, mae: 1.175564, mean_q: 1.433357, mean_eps: 0.533756
 234368/600000: episode: 344, duration: 15.834s, episode steps: 923, steps per second:  58, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.012165, mae: 1.176781, mean_q: 1.434767, mean_eps: 0.532188
 234993/600000: episode: 345, duration: 10.627s, episode steps: 625, steps per second:  59, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.013138, mae: 1.191686, mean_q: 1.451026, mean_eps: 0.530640
 236154/600000: episode: 346, duration: 18.557s, episode steps: 1161, steps per second:  63, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.012224, mae: 1.207233, mean_q: 1.471810, mean_eps: 0.528852
 236723/600000: episode: 347, duration: 10.320s, episode steps: 569, steps per second:  55, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.011819, mae: 1.193086, mean_q: 1.452663, mean_eps: 0.527124
 237506/600000: episode: 348, duration: 13.859s, episode steps: 783, steps per second:  56, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.013776, mae: 1.198721, mean_q: 1.459949, mean_eps: 0.525772
 238203/600000: episode: 349, duration: 11.500s, episode steps: 697, steps per second:  61, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.012963, mae: 1.193584, mean_q: 1.454689, mean_eps: 0.524292
 238914/600000: episode: 350, duration: 11.558s, episode steps: 711, steps per second:  62, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.956 [0.000, 5.000],  loss: 0.013347, mae: 1.211760, mean_q: 1.480383, mean_eps: 0.522884
 239830/600000: episode: 351, duration: 14.570s, episode steps: 916, steps per second:  63, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.090 [0.000, 5.000],  loss: 0.012788, mae: 1.188302, mean_q: 1.447774, mean_eps: 0.521256
 240532/600000: episode: 352, duration: 12.082s, episode steps: 702, steps per second:  58, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.011863, mae: 1.216508, mean_q: 1.483133, mean_eps: 0.519640
 241102/600000: episode: 353, duration: 10.536s, episode steps: 570, steps per second:  54, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.012153, mae: 1.225274, mean_q: 1.493318, mean_eps: 0.518368
 241770/600000: episode: 354, duration: 12.236s, episode steps: 668, steps per second:  55, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.013635, mae: 1.221037, mean_q: 1.486404, mean_eps: 0.517128
 242660/600000: episode: 355, duration: 15.544s, episode steps: 890, steps per second:  57, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.012431, mae: 1.222505, mean_q: 1.490092, mean_eps: 0.515572
 243158/600000: episode: 356, duration: 8.872s, episode steps: 498, steps per second:  56, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.011801, mae: 1.220579, mean_q: 1.488595, mean_eps: 0.514184
 244055/600000: episode: 357, duration: 17.038s, episode steps: 897, steps per second:  53, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.012369, mae: 1.243532, mean_q: 1.514878, mean_eps: 0.512788
 244826/600000: episode: 358, duration: 14.267s, episode steps: 771, steps per second:  54, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.013557, mae: 1.230375, mean_q: 1.499058, mean_eps: 0.511120
 245809/600000: episode: 359, duration: 17.757s, episode steps: 983, steps per second:  55, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.011050, mae: 1.231364, mean_q: 1.500834, mean_eps: 0.509364
 246626/600000: episode: 360, duration: 14.481s, episode steps: 817, steps per second:  56, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.013225, mae: 1.234335, mean_q: 1.503635, mean_eps: 0.507564
 247569/600000: episode: 361, duration: 16.459s, episode steps: 943, steps per second:  57, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.013237, mae: 1.237687, mean_q: 1.508376, mean_eps: 0.505804
 248088/600000: episode: 362, duration: 8.323s, episode steps: 519, steps per second:  62, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.015572, mae: 1.248154, mean_q: 1.518152, mean_eps: 0.504344
 249173/600000: episode: 363, duration: 17.716s, episode steps: 1085, steps per second:  61, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.014141, mae: 1.232421, mean_q: 1.500447, mean_eps: 0.502740
 249760/600000: episode: 364, duration: 9.552s, episode steps: 587, steps per second:  61, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.012183, mae: 1.256718, mean_q: 1.530531, mean_eps: 0.501068
 250676/600000: episode: 365, duration: 15.586s, episode steps: 916, steps per second:  59, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.012911, mae: 1.252580, mean_q: 1.526753, mean_eps: 0.499568
 251227/600000: episode: 366, duration: 9.320s, episode steps: 551, steps per second:  59, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.013057, mae: 1.262619, mean_q: 1.540905, mean_eps: 0.498100
 251977/600000: episode: 367, duration: 12.925s, episode steps: 750, steps per second:  58, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.014582, mae: 1.265201, mean_q: 1.542413, mean_eps: 0.496796
 252510/600000: episode: 368, duration: 8.679s, episode steps: 533, steps per second:  61, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.012510, mae: 1.273854, mean_q: 1.551342, mean_eps: 0.495512
 253206/600000: episode: 369, duration: 11.882s, episode steps: 696, steps per second:  59, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.012467, mae: 1.277050, mean_q: 1.554108, mean_eps: 0.494284
 254163/600000: episode: 370, duration: 16.551s, episode steps: 957, steps per second:  58, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.011713, mae: 1.241073, mean_q: 1.510889, mean_eps: 0.492632
 254842/600000: episode: 371, duration: 11.738s, episode steps: 679, steps per second:  58, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.012104, mae: 1.257304, mean_q: 1.531847, mean_eps: 0.490996
 255662/600000: episode: 372, duration: 13.441s, episode steps: 820, steps per second:  61, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.014003, mae: 1.306032, mean_q: 1.591462, mean_eps: 0.489496
 256369/600000: episode: 373, duration: 11.154s, episode steps: 707, steps per second:  63, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.013801, mae: 1.299878, mean_q: 1.585188, mean_eps: 0.487968
 257474/600000: episode: 374, duration: 17.744s, episode steps: 1105, steps per second:  62, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.012876, mae: 1.294401, mean_q: 1.576559, mean_eps: 0.486156
 258283/600000: episode: 375, duration: 13.737s, episode steps: 809, steps per second:  59, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.011623, mae: 1.303050, mean_q: 1.590018, mean_eps: 0.484244
 258912/600000: episode: 376, duration: 10.494s, episode steps: 629, steps per second:  60, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.011475, mae: 1.294722, mean_q: 1.576148, mean_eps: 0.482808
 259486/600000: episode: 377, duration: 9.638s, episode steps: 574, steps per second:  60, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.011965, mae: 1.298266, mean_q: 1.579513, mean_eps: 0.481604
 260408/600000: episode: 378, duration: 14.780s, episode steps: 922, steps per second:  62, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.983 [0.000, 5.000],  loss: 0.011943, mae: 1.309747, mean_q: 1.594793, mean_eps: 0.480108
 261160/600000: episode: 379, duration: 12.522s, episode steps: 752, steps per second:  60, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.013737, mae: 1.316496, mean_q: 1.600749, mean_eps: 0.478436
 261922/600000: episode: 380, duration: 12.940s, episode steps: 762, steps per second:  59, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.012297, mae: 1.299325, mean_q: 1.580256, mean_eps: 0.476920
 262613/600000: episode: 381, duration: 11.172s, episode steps: 691, steps per second:  62, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.011431, mae: 1.299045, mean_q: 1.580569, mean_eps: 0.475464
 263270/600000: episode: 382, duration: 11.077s, episode steps: 657, steps per second:  59, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.015062, mae: 1.331837, mean_q: 1.619356, mean_eps: 0.474116
 264145/600000: episode: 383, duration: 14.860s, episode steps: 875, steps per second:  59, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.014431, mae: 1.321401, mean_q: 1.608833, mean_eps: 0.472584
 264715/600000: episode: 384, duration: 10.789s, episode steps: 570, steps per second:  53, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.013278, mae: 1.313684, mean_q: 1.599877, mean_eps: 0.471140
 265330/600000: episode: 385, duration: 11.024s, episode steps: 615, steps per second:  56, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.288 [0.000, 5.000],  loss: 0.012887, mae: 1.322303, mean_q: 1.609997, mean_eps: 0.469956
 265904/600000: episode: 386, duration: 11.035s, episode steps: 574, steps per second:  52, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.011159, mae: 1.335394, mean_q: 1.626039, mean_eps: 0.468768
 266562/600000: episode: 387, duration: 11.087s, episode steps: 658, steps per second:  59, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.012075, mae: 1.331251, mean_q: 1.620440, mean_eps: 0.467536
 267247/600000: episode: 388, duration: 11.372s, episode steps: 685, steps per second:  60, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.013248, mae: 1.326459, mean_q: 1.613200, mean_eps: 0.466192
 267842/600000: episode: 389, duration: 9.855s, episode steps: 595, steps per second:  60, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.012849, mae: 1.328813, mean_q: 1.617115, mean_eps: 0.464912
 268789/600000: episode: 390, duration: 16.314s, episode steps: 947, steps per second:  58, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.013685, mae: 1.322364, mean_q: 1.607771, mean_eps: 0.463368
 269408/600000: episode: 391, duration: 10.566s, episode steps: 619, steps per second:  59, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.012225, mae: 1.333906, mean_q: 1.620961, mean_eps: 0.461804
 270370/600000: episode: 392, duration: 15.653s, episode steps: 962, steps per second:  61, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.974 [0.000, 5.000],  loss: 0.013518, mae: 1.346815, mean_q: 1.639813, mean_eps: 0.460224
 271209/600000: episode: 393, duration: 13.769s, episode steps: 839, steps per second:  61, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.012226, mae: 1.359844, mean_q: 1.653269, mean_eps: 0.458420
 271709/600000: episode: 394, duration: 9.256s, episode steps: 500, steps per second:  54, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.014526, mae: 1.368191, mean_q: 1.662562, mean_eps: 0.457080
 272505/600000: episode: 395, duration: 13.775s, episode steps: 796, steps per second:  58, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.014556, mae: 1.377458, mean_q: 1.672891, mean_eps: 0.455784
 273353/600000: episode: 396, duration: 14.938s, episode steps: 848, steps per second:  57, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.012733, mae: 1.360729, mean_q: 1.655173, mean_eps: 0.454140
 274847/600000: episode: 397, duration: 25.025s, episode steps: 1494, steps per second:  60, episode reward: 32.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.014421, mae: 1.367492, mean_q: 1.662803, mean_eps: 0.451800
 275731/600000: episode: 398, duration: 15.177s, episode steps: 884, steps per second:  58, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.012225, mae: 1.387295, mean_q: 1.687297, mean_eps: 0.449424
 276529/600000: episode: 399, duration: 13.141s, episode steps: 798, steps per second:  61, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.013466, mae: 1.409715, mean_q: 1.714185, mean_eps: 0.447740
 277253/600000: episode: 400, duration: 11.392s, episode steps: 724, steps per second:  64, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.011660, mae: 1.390480, mean_q: 1.692417, mean_eps: 0.446216
 278284/600000: episode: 401, duration: 16.329s, episode steps: 1031, steps per second:  63, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.012025, mae: 1.401221, mean_q: 1.703769, mean_eps: 0.444464
 279046/600000: episode: 402, duration: 13.295s, episode steps: 762, steps per second:  57, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.014117, mae: 1.382948, mean_q: 1.680406, mean_eps: 0.442672
 279823/600000: episode: 403, duration: 13.014s, episode steps: 777, steps per second:  60, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.014780, mae: 1.405620, mean_q: 1.708351, mean_eps: 0.441132
 280805/600000: episode: 404, duration: 15.890s, episode steps: 982, steps per second:  62, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.013299, mae: 1.402609, mean_q: 1.703908, mean_eps: 0.439372
 281339/600000: episode: 405, duration: 8.340s, episode steps: 534, steps per second:  64, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.013914, mae: 1.410767, mean_q: 1.714104, mean_eps: 0.437856
 281870/600000: episode: 406, duration: 8.570s, episode steps: 531, steps per second:  62, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.011512, mae: 1.400857, mean_q: 1.702770, mean_eps: 0.436792
 282720/600000: episode: 407, duration: 13.731s, episode steps: 850, steps per second:  62, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.085 [0.000, 5.000],  loss: 0.013878, mae: 1.411068, mean_q: 1.714309, mean_eps: 0.435412
 283247/600000: episode: 408, duration: 8.871s, episode steps: 527, steps per second:  59, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.015455, mae: 1.432686, mean_q: 1.740646, mean_eps: 0.434036
 283895/600000: episode: 409, duration: 10.940s, episode steps: 648, steps per second:  59, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.013647, mae: 1.398684, mean_q: 1.697516, mean_eps: 0.432860
 284595/600000: episode: 410, duration: 12.317s, episode steps: 700, steps per second:  57, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.030 [0.000, 5.000],  loss: 0.011730, mae: 1.387998, mean_q: 1.685626, mean_eps: 0.431512
 285159/600000: episode: 411, duration: 10.529s, episode steps: 564, steps per second:  54, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.062 [0.000, 5.000],  loss: 0.013042, mae: 1.406261, mean_q: 1.708187, mean_eps: 0.430248
 286008/600000: episode: 412, duration: 15.200s, episode steps: 849, steps per second:  56, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.012194, mae: 1.378258, mean_q: 1.673490, mean_eps: 0.428836
 287605/600000: episode: 413, duration: 28.942s, episode steps: 1597, steps per second:  55, episode reward: 31.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013078, mae: 1.399014, mean_q: 1.700657, mean_eps: 0.426388
 288199/600000: episode: 414, duration: 10.040s, episode steps: 594, steps per second:  59, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.013523, mae: 1.391180, mean_q: 1.689841, mean_eps: 0.424196
 288890/600000: episode: 415, duration: 11.572s, episode steps: 691, steps per second:  60, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.012698, mae: 1.391757, mean_q: 1.689895, mean_eps: 0.422912
 289432/600000: episode: 416, duration: 9.449s, episode steps: 542, steps per second:  57, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.015812, mae: 1.416652, mean_q: 1.718758, mean_eps: 0.421680
 289892/600000: episode: 417, duration: 7.773s, episode steps: 460, steps per second:  59, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.014819, mae: 1.406874, mean_q: 1.709839, mean_eps: 0.420680
 290847/600000: episode: 418, duration: 16.870s, episode steps: 955, steps per second:  57, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.012338, mae: 1.438756, mean_q: 1.750466, mean_eps: 0.419264
 291198/600000: episode: 419, duration: 6.096s, episode steps: 351, steps per second:  58, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.012078, mae: 1.456115, mean_q: 1.768626, mean_eps: 0.417956
 291880/600000: episode: 420, duration: 11.298s, episode steps: 682, steps per second:  60, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013572, mae: 1.462235, mean_q: 1.777218, mean_eps: 0.416924
 293047/600000: episode: 421, duration: 21.189s, episode steps: 1167, steps per second:  55, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.014134, mae: 1.463415, mean_q: 1.778920, mean_eps: 0.415076
 293558/600000: episode: 422, duration: 9.536s, episode steps: 511, steps per second:  54, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.015019, mae: 1.456424, mean_q: 1.769930, mean_eps: 0.413396
 294143/600000: episode: 423, duration: 10.633s, episode steps: 585, steps per second:  55, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.014 [0.000, 5.000],  loss: 0.014256, mae: 1.423693, mean_q: 1.730875, mean_eps: 0.412300
 294661/600000: episode: 424, duration: 9.310s, episode steps: 518, steps per second:  56, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.014664, mae: 1.480324, mean_q: 1.801100, mean_eps: 0.411196
 295698/600000: episode: 425, duration: 17.951s, episode steps: 1037, steps per second:  58, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.014612, mae: 1.444224, mean_q: 1.755888, mean_eps: 0.409640
 296107/600000: episode: 426, duration: 7.091s, episode steps: 409, steps per second:  58, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.010567, mae: 1.445810, mean_q: 1.758498, mean_eps: 0.408196
 296722/600000: episode: 427, duration: 11.168s, episode steps: 615, steps per second:  55, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.013082, mae: 1.439640, mean_q: 1.749745, mean_eps: 0.407172
 298166/600000: episode: 428, duration: 23.908s, episode steps: 1444, steps per second:  60, episode reward: 23.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.128 [0.000, 5.000],  loss: 0.014658, mae: 1.447748, mean_q: 1.760993, mean_eps: 0.405112
 298679/600000: episode: 429, duration: 8.506s, episode steps: 513, steps per second:  60, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.015408, mae: 1.437927, mean_q: 1.747275, mean_eps: 0.403156
 299279/600000: episode: 430, duration: 9.871s, episode steps: 600, steps per second:  61, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.014298, mae: 1.458965, mean_q: 1.773708, mean_eps: 0.402044
 299803/600000: episode: 431, duration: 8.683s, episode steps: 524, steps per second:  60, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.011874, mae: 1.436743, mean_q: 1.747762, mean_eps: 0.400920
 300285/600000: episode: 432, duration: 7.938s, episode steps: 482, steps per second:  61, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.012033, mae: 1.492141, mean_q: 1.813411, mean_eps: 0.399912
 301065/600000: episode: 433, duration: 13.011s, episode steps: 780, steps per second:  60, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.013987, mae: 1.497777, mean_q: 1.818833, mean_eps: 0.398648
 301686/600000: episode: 434, duration: 9.897s, episode steps: 621, steps per second:  63, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.011802, mae: 1.482411, mean_q: 1.800103, mean_eps: 0.397248
 302525/600000: episode: 435, duration: 13.634s, episode steps: 839, steps per second:  62, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.012012, mae: 1.480969, mean_q: 1.799703, mean_eps: 0.395788
 303087/600000: episode: 436, duration: 9.323s, episode steps: 562, steps per second:  60, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.012565, mae: 1.490403, mean_q: 1.810592, mean_eps: 0.394388
 303736/600000: episode: 437, duration: 10.974s, episode steps: 649, steps per second:  59, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.013862, mae: 1.495882, mean_q: 1.817539, mean_eps: 0.393180
 304715/600000: episode: 438, duration: 16.489s, episode steps: 979, steps per second:  59, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.936 [0.000, 5.000],  loss: 0.014697, mae: 1.494943, mean_q: 1.816253, mean_eps: 0.391552
 305368/600000: episode: 439, duration: 12.306s, episode steps: 653, steps per second:  53, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.910 [0.000, 5.000],  loss: 0.011945, mae: 1.518712, mean_q: 1.845198, mean_eps: 0.389920
 306082/600000: episode: 440, duration: 13.249s, episode steps: 714, steps per second:  54, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.013929, mae: 1.517878, mean_q: 1.842393, mean_eps: 0.388552
 306920/600000: episode: 441, duration: 17.442s, episode steps: 838, steps per second:  48, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.013001, mae: 1.523132, mean_q: 1.849917, mean_eps: 0.387000
 307771/600000: episode: 442, duration: 16.987s, episode steps: 851, steps per second:  50, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.013993, mae: 1.516820, mean_q: 1.841923, mean_eps: 0.385312
 308542/600000: episode: 443, duration: 13.520s, episode steps: 771, steps per second:  57, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.016339, mae: 1.518008, mean_q: 1.844257, mean_eps: 0.383688
 309391/600000: episode: 444, duration: 14.735s, episode steps: 849, steps per second:  58, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.014078, mae: 1.521100, mean_q: 1.846401, mean_eps: 0.382068
 310518/600000: episode: 445, duration: 20.799s, episode steps: 1127, steps per second:  54, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.012820, mae: 1.524701, mean_q: 1.850850, mean_eps: 0.380092
 311363/600000: episode: 446, duration: 14.937s, episode steps: 845, steps per second:  57, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.013421, mae: 1.535556, mean_q: 1.864838, mean_eps: 0.378120
 311864/600000: episode: 447, duration: 8.547s, episode steps: 501, steps per second:  59, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.013412, mae: 1.528413, mean_q: 1.856477, mean_eps: 0.376776
 312530/600000: episode: 448, duration: 11.552s, episode steps: 666, steps per second:  58, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.014132, mae: 1.526907, mean_q: 1.854154, mean_eps: 0.375608
 313204/600000: episode: 449, duration: 12.351s, episode steps: 674, steps per second:  55, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.013577, mae: 1.522783, mean_q: 1.849016, mean_eps: 0.374268
 313894/600000: episode: 450, duration: 11.901s, episode steps: 690, steps per second:  58, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.013450, mae: 1.530053, mean_q: 1.858318, mean_eps: 0.372904
 314431/600000: episode: 451, duration: 9.311s, episode steps: 537, steps per second:  58, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.013291, mae: 1.525336, mean_q: 1.852737, mean_eps: 0.371676
 315690/600000: episode: 452, duration: 22.117s, episode steps: 1259, steps per second:  57, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.013093, mae: 1.555130, mean_q: 1.887808, mean_eps: 0.369880
 316975/600000: episode: 453, duration: 22.446s, episode steps: 1285, steps per second:  57, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: 0.014536, mae: 1.562402, mean_q: 1.896836, mean_eps: 0.367336
 317486/600000: episode: 454, duration: 9.235s, episode steps: 511, steps per second:  55, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.015589, mae: 1.571848, mean_q: 1.907378, mean_eps: 0.365540
 318429/600000: episode: 455, duration: 15.882s, episode steps: 943, steps per second:  59, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.826 [0.000, 5.000],  loss: 0.012984, mae: 1.541777, mean_q: 1.872490, mean_eps: 0.364084
 319066/600000: episode: 456, duration: 10.468s, episode steps: 637, steps per second:  61, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.014415, mae: 1.553869, mean_q: 1.885427, mean_eps: 0.362504
 319662/600000: episode: 457, duration: 9.963s, episode steps: 596, steps per second:  60, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.918 [0.000, 5.000],  loss: 0.012440, mae: 1.547578, mean_q: 1.880211, mean_eps: 0.361272
 320390/600000: episode: 458, duration: 13.764s, episode steps: 728, steps per second:  53, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.013547, mae: 1.587021, mean_q: 1.928177, mean_eps: 0.359948
 321107/600000: episode: 459, duration: 12.949s, episode steps: 717, steps per second:  55, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.013487, mae: 1.593567, mean_q: 1.936287, mean_eps: 0.358504
 321927/600000: episode: 460, duration: 14.330s, episode steps: 820, steps per second:  57, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.012919, mae: 1.582000, mean_q: 1.920463, mean_eps: 0.356968
 322986/600000: episode: 461, duration: 17.395s, episode steps: 1059, steps per second:  61, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.140 [0.000, 5.000],  loss: 0.015033, mae: 1.593270, mean_q: 1.935693, mean_eps: 0.355088
 323775/600000: episode: 462, duration: 12.844s, episode steps: 789, steps per second:  61, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.639 [0.000, 5.000],  loss: 0.015985, mae: 1.587319, mean_q: 1.926412, mean_eps: 0.353240
 324204/600000: episode: 463, duration: 7.038s, episode steps: 429, steps per second:  61, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.014143, mae: 1.590145, mean_q: 1.929579, mean_eps: 0.352024
 325288/600000: episode: 464, duration: 18.271s, episode steps: 1084, steps per second:  59, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.013682, mae: 1.583302, mean_q: 1.921846, mean_eps: 0.350512
 326921/600000: episode: 465, duration: 30.444s, episode steps: 1633, steps per second:  54, episode reward: 35.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.014220, mae: 1.599881, mean_q: 1.943995, mean_eps: 0.347792
 327873/600000: episode: 466, duration: 18.526s, episode steps: 952, steps per second:  51, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.015631, mae: 1.595010, mean_q: 1.939437, mean_eps: 0.345204
 328784/600000: episode: 467, duration: 17.279s, episode steps: 911, steps per second:  53, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.014425, mae: 1.606949, mean_q: 1.953989, mean_eps: 0.343344
 329565/600000: episode: 468, duration: 14.045s, episode steps: 781, steps per second:  56, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.014300, mae: 1.606979, mean_q: 1.951340, mean_eps: 0.341652
 330347/600000: episode: 469, duration: 13.915s, episode steps: 782, steps per second:  56, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.013629, mae: 1.628974, mean_q: 1.978405, mean_eps: 0.340088
 331343/600000: episode: 470, duration: 17.634s, episode steps: 996, steps per second:  56, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.013244, mae: 1.624602, mean_q: 1.973082, mean_eps: 0.338312
 331815/600000: episode: 471, duration: 7.893s, episode steps: 472, steps per second:  60, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.150 [0.000, 5.000],  loss: 0.014175, mae: 1.641674, mean_q: 1.993735, mean_eps: 0.336844
 332851/600000: episode: 472, duration: 17.536s, episode steps: 1036, steps per second:  59, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.013532, mae: 1.644791, mean_q: 1.999241, mean_eps: 0.335336
 333413/600000: episode: 473, duration: 9.817s, episode steps: 562, steps per second:  57, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.948 [0.000, 5.000],  loss: 0.013922, mae: 1.625911, mean_q: 1.976355, mean_eps: 0.333736
 333989/600000: episode: 474, duration: 11.287s, episode steps: 576, steps per second:  51, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.016557, mae: 1.647960, mean_q: 1.999961, mean_eps: 0.332596
 334692/600000: episode: 475, duration: 13.661s, episode steps: 703, steps per second:  51, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.016402, mae: 1.628484, mean_q: 1.976710, mean_eps: 0.331320
 335432/600000: episode: 476, duration: 13.431s, episode steps: 740, steps per second:  55, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.789 [0.000, 5.000],  loss: 0.012694, mae: 1.637183, mean_q: 1.989104, mean_eps: 0.329880
 336022/600000: episode: 477, duration: 10.436s, episode steps: 590, steps per second:  57, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.785 [0.000, 5.000],  loss: 0.013278, mae: 1.646675, mean_q: 2.003078, mean_eps: 0.328548
 337204/600000: episode: 478, duration: 21.508s, episode steps: 1182, steps per second:  55, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.013754, mae: 1.643431, mean_q: 1.997719, mean_eps: 0.326776
 338297/600000: episode: 479, duration: 19.198s, episode steps: 1093, steps per second:  57, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.016065, mae: 1.664924, mean_q: 2.021768, mean_eps: 0.324500
 339084/600000: episode: 480, duration: 12.610s, episode steps: 787, steps per second:  62, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.015329, mae: 1.651083, mean_q: 2.004145, mean_eps: 0.322620
 340172/600000: episode: 481, duration: 17.579s, episode steps: 1088, steps per second:  62, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.015067, mae: 1.659773, mean_q: 2.015233, mean_eps: 0.320748
 341286/600000: episode: 482, duration: 19.185s, episode steps: 1114, steps per second:  58, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.014472, mae: 1.634921, mean_q: 1.985792, mean_eps: 0.318544
 342231/600000: episode: 483, duration: 16.687s, episode steps: 945, steps per second:  57, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.016560, mae: 1.637157, mean_q: 1.987802, mean_eps: 0.316484
 343157/600000: episode: 484, duration: 15.848s, episode steps: 926, steps per second:  58, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.014845, mae: 1.665524, mean_q: 2.022258, mean_eps: 0.314612
 343719/600000: episode: 485, duration: 9.651s, episode steps: 562, steps per second:  58, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.144 [0.000, 5.000],  loss: 0.014370, mae: 1.654898, mean_q: 2.009421, mean_eps: 0.313124
 344259/600000: episode: 486, duration: 9.337s, episode steps: 540, steps per second:  58, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014712, mae: 1.663696, mean_q: 2.018124, mean_eps: 0.312024
 344799/600000: episode: 487, duration: 8.742s, episode steps: 540, steps per second:  62, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.016138, mae: 1.641549, mean_q: 1.992705, mean_eps: 0.310944
 345140/600000: episode: 488, duration: 5.799s, episode steps: 341, steps per second:  59, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.014396, mae: 1.652773, mean_q: 2.006992, mean_eps: 0.310064
 346029/600000: episode: 489, duration: 15.951s, episode steps: 889, steps per second:  56, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.014553, mae: 1.662057, mean_q: 2.018778, mean_eps: 0.308832
 347063/600000: episode: 490, duration: 18.968s, episode steps: 1034, steps per second:  55, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.231 [0.000, 5.000],  loss: 0.014966, mae: 1.659167, mean_q: 2.013740, mean_eps: 0.306908
 347626/600000: episode: 491, duration: 10.735s, episode steps: 563, steps per second:  52, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.015613, mae: 1.650730, mean_q: 2.003171, mean_eps: 0.305312
 348997/600000: episode: 492, duration: 25.263s, episode steps: 1371, steps per second:  54, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.035 [0.000, 5.000],  loss: 0.015795, mae: 1.658135, mean_q: 2.010879, mean_eps: 0.303376
 349751/600000: episode: 493, duration: 12.755s, episode steps: 754, steps per second:  59, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.032 [0.000, 5.000],  loss: 0.015684, mae: 1.657378, mean_q: 2.011925, mean_eps: 0.301252
 350443/600000: episode: 494, duration: 11.854s, episode steps: 692, steps per second:  58, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.012942, mae: 1.668428, mean_q: 2.025055, mean_eps: 0.299808
 351067/600000: episode: 495, duration: 11.422s, episode steps: 624, steps per second:  55, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.014075, mae: 1.683487, mean_q: 2.043155, mean_eps: 0.298492
 352125/600000: episode: 496, duration: 19.071s, episode steps: 1058, steps per second:  55, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.014037, mae: 1.676282, mean_q: 2.032666, mean_eps: 0.296808
 352856/600000: episode: 497, duration: 12.441s, episode steps: 731, steps per second:  59, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.817 [0.000, 5.000],  loss: 0.013994, mae: 1.673105, mean_q: 2.030655, mean_eps: 0.295020
 353548/600000: episode: 498, duration: 12.165s, episode steps: 692, steps per second:  57, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.015317, mae: 1.671184, mean_q: 2.027568, mean_eps: 0.293600
 354204/600000: episode: 499, duration: 12.072s, episode steps: 656, steps per second:  54, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.078 [0.000, 5.000],  loss: 0.014601, mae: 1.670240, mean_q: 2.028571, mean_eps: 0.292252
 354726/600000: episode: 500, duration: 9.818s, episode steps: 522, steps per second:  53, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.013915, mae: 1.690213, mean_q: 2.053537, mean_eps: 0.291072
 355555/600000: episode: 501, duration: 15.156s, episode steps: 829, steps per second:  55, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.013395, mae: 1.700616, mean_q: 2.065746, mean_eps: 0.289720
 356441/600000: episode: 502, duration: 15.775s, episode steps: 886, steps per second:  56, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.013448, mae: 1.694099, mean_q: 2.056530, mean_eps: 0.288004
 357684/600000: episode: 503, duration: 22.159s, episode steps: 1243, steps per second:  56, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.014984, mae: 1.705678, mean_q: 2.071154, mean_eps: 0.285876
 358463/600000: episode: 504, duration: 13.616s, episode steps: 779, steps per second:  57, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.012999, mae: 1.723297, mean_q: 2.092588, mean_eps: 0.283856
 359454/600000: episode: 505, duration: 16.914s, episode steps: 991, steps per second:  59, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.012687, mae: 1.719499, mean_q: 2.086585, mean_eps: 0.282084
 359914/600000: episode: 506, duration: 7.586s, episode steps: 460, steps per second:  61, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.014499, mae: 1.732334, mean_q: 2.102680, mean_eps: 0.280632
 360511/600000: episode: 507, duration: 9.423s, episode steps: 597, steps per second:  63, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.802 [0.000, 5.000],  loss: 0.013414, mae: 1.703504, mean_q: 2.069183, mean_eps: 0.279576
 361488/600000: episode: 508, duration: 17.792s, episode steps: 977, steps per second:  55, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.031 [0.000, 5.000],  loss: 0.015008, mae: 1.707134, mean_q: 2.072551, mean_eps: 0.278004
 362432/600000: episode: 509, duration: 16.679s, episode steps: 944, steps per second:  57, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.016055, mae: 1.712653, mean_q: 2.078102, mean_eps: 0.276084
 362814/600000: episode: 510, duration: 6.852s, episode steps: 382, steps per second:  56, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.013138, mae: 1.697673, mean_q: 2.061200, mean_eps: 0.274756
 363450/600000: episode: 511, duration: 10.815s, episode steps: 636, steps per second:  59, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.015559, mae: 1.699140, mean_q: 2.061851, mean_eps: 0.273736
 364236/600000: episode: 512, duration: 13.910s, episode steps: 786, steps per second:  57, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.016117, mae: 1.716646, mean_q: 2.083474, mean_eps: 0.272316
 365174/600000: episode: 513, duration: 16.624s, episode steps: 938, steps per second:  56, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.015334, mae: 1.714072, mean_q: 2.080582, mean_eps: 0.270592
 365767/600000: episode: 514, duration: 10.311s, episode steps: 593, steps per second:  58, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.014732, mae: 1.749308, mean_q: 2.124115, mean_eps: 0.269060
 366270/600000: episode: 515, duration: 9.295s, episode steps: 503, steps per second:  54, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.012302, mae: 1.736965, mean_q: 2.108434, mean_eps: 0.267964
 366914/600000: episode: 516, duration: 11.350s, episode steps: 644, steps per second:  57, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.014305, mae: 1.739417, mean_q: 2.110651, mean_eps: 0.266816
 368246/600000: episode: 517, duration: 25.363s, episode steps: 1332, steps per second:  53, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.015453, mae: 1.734790, mean_q: 2.105009, mean_eps: 0.264840
 369034/600000: episode: 518, duration: 15.204s, episode steps: 788, steps per second:  52, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.013622, mae: 1.729075, mean_q: 2.099201, mean_eps: 0.262720
 370030/600000: episode: 519, duration: 17.869s, episode steps: 996, steps per second:  56, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.837 [0.000, 5.000],  loss: 0.015285, mae: 1.726947, mean_q: 2.094798, mean_eps: 0.260936
 371265/600000: episode: 520, duration: 22.153s, episode steps: 1235, steps per second:  56, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.013886, mae: 1.789744, mean_q: 2.172458, mean_eps: 0.258704
 372119/600000: episode: 521, duration: 16.666s, episode steps: 854, steps per second:  51, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.015690, mae: 1.774533, mean_q: 2.153741, mean_eps: 0.256616
 372646/600000: episode: 522, duration: 8.841s, episode steps: 527, steps per second:  60, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.016969, mae: 1.793679, mean_q: 2.175007, mean_eps: 0.255236
 373580/600000: episode: 523, duration: 16.322s, episode steps: 934, steps per second:  57, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.016603, mae: 1.782823, mean_q: 2.161027, mean_eps: 0.253776
 374081/600000: episode: 524, duration: 9.238s, episode steps: 501, steps per second:  54, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.014333, mae: 1.767995, mean_q: 2.144498, mean_eps: 0.252340
 374439/600000: episode: 525, duration: 6.641s, episode steps: 358, steps per second:  54, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.813 [0.000, 5.000],  loss: 0.016702, mae: 1.810783, mean_q: 2.197008, mean_eps: 0.251480
 374975/600000: episode: 526, duration: 9.893s, episode steps: 536, steps per second:  54, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.058 [0.000, 5.000],  loss: 0.015358, mae: 1.796112, mean_q: 2.178339, mean_eps: 0.250588
 375627/600000: episode: 527, duration: 11.190s, episode steps: 652, steps per second:  58, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.853 [0.000, 5.000],  loss: 0.015461, mae: 1.819937, mean_q: 2.206597, mean_eps: 0.249400
 376379/600000: episode: 528, duration: 12.884s, episode steps: 752, steps per second:  58, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.013524, mae: 1.802198, mean_q: 2.185851, mean_eps: 0.247996
 377061/600000: episode: 529, duration: 11.478s, episode steps: 682, steps per second:  59, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.014881, mae: 1.820013, mean_q: 2.206876, mean_eps: 0.246560
 377704/600000: episode: 530, duration: 11.124s, episode steps: 643, steps per second:  58, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.015221, mae: 1.820360, mean_q: 2.207939, mean_eps: 0.245236
 378233/600000: episode: 531, duration: 9.401s, episode steps: 529, steps per second:  56, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.016777, mae: 1.828136, mean_q: 2.218440, mean_eps: 0.244064
 378870/600000: episode: 532, duration: 11.371s, episode steps: 637, steps per second:  56, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.016594, mae: 1.819241, mean_q: 2.206047, mean_eps: 0.242896
 379922/600000: episode: 533, duration: 17.292s, episode steps: 1052, steps per second:  61, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.013755, mae: 1.810965, mean_q: 2.197023, mean_eps: 0.241208
 380533/600000: episode: 534, duration: 10.209s, episode steps: 611, steps per second:  60, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.047 [0.000, 5.000],  loss: 0.013387, mae: 1.863966, mean_q: 2.261078, mean_eps: 0.239544
 381254/600000: episode: 535, duration: 12.184s, episode steps: 721, steps per second:  59, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.014301, mae: 1.836847, mean_q: 2.226537, mean_eps: 0.238212
 382126/600000: episode: 536, duration: 15.653s, episode steps: 872, steps per second:  56, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.014119, mae: 1.855129, mean_q: 2.249902, mean_eps: 0.236620
 383296/600000: episode: 537, duration: 20.172s, episode steps: 1170, steps per second:  58, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.014615, mae: 1.846706, mean_q: 2.239604, mean_eps: 0.234580
 383827/600000: episode: 538, duration: 9.054s, episode steps: 531, steps per second:  59, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.836 [0.000, 5.000],  loss: 0.013619, mae: 1.849766, mean_q: 2.242051, mean_eps: 0.232880
 384217/600000: episode: 539, duration: 6.654s, episode steps: 390, steps per second:  59, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.926 [0.000, 5.000],  loss: 0.015807, mae: 1.839565, mean_q: 2.227833, mean_eps: 0.231956
 385093/600000: episode: 540, duration: 15.155s, episode steps: 876, steps per second:  58, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.014652, mae: 1.843212, mean_q: 2.236250, mean_eps: 0.230688
 385919/600000: episode: 541, duration: 14.128s, episode steps: 826, steps per second:  58, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.015751, mae: 1.882046, mean_q: 2.282754, mean_eps: 0.228988
 386713/600000: episode: 542, duration: 15.814s, episode steps: 794, steps per second:  50, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.015607, mae: 1.882776, mean_q: 2.282373, mean_eps: 0.227368
 387345/600000: episode: 543, duration: 11.598s, episode steps: 632, steps per second:  54, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.014482, mae: 1.879137, mean_q: 2.280125, mean_eps: 0.225940
 388141/600000: episode: 544, duration: 16.619s, episode steps: 796, steps per second:  48, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.014360, mae: 1.882246, mean_q: 2.282467, mean_eps: 0.224512
 389071/600000: episode: 545, duration: 19.223s, episode steps: 930, steps per second:  48, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.015938, mae: 1.886732, mean_q: 2.287162, mean_eps: 0.222788
 389781/600000: episode: 546, duration: 12.963s, episode steps: 710, steps per second:  55, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.028 [0.000, 5.000],  loss: 0.014412, mae: 1.881764, mean_q: 2.279952, mean_eps: 0.221148
 390170/600000: episode: 547, duration: 6.850s, episode steps: 389, steps per second:  57, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.306 [0.000, 5.000],  loss: 0.016238, mae: 1.938906, mean_q: 2.350502, mean_eps: 0.220048
 390816/600000: episode: 548, duration: 11.541s, episode steps: 646, steps per second:  56, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.889 [0.000, 5.000],  loss: 0.014809, mae: 1.956566, mean_q: 2.372067, mean_eps: 0.219016
 391570/600000: episode: 549, duration: 14.237s, episode steps: 754, steps per second:  53, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.018128, mae: 2.004278, mean_q: 2.430053, mean_eps: 0.217616
 392302/600000: episode: 550, duration: 13.372s, episode steps: 732, steps per second:  55, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.014804, mae: 1.952705, mean_q: 2.366141, mean_eps: 0.216128
 393091/600000: episode: 551, duration: 13.916s, episode steps: 789, steps per second:  57, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.815 [0.000, 5.000],  loss: 0.015234, mae: 1.982097, mean_q: 2.401853, mean_eps: 0.214608
 393974/600000: episode: 552, duration: 16.084s, episode steps: 883, steps per second:  55, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.016430, mae: 1.962596, mean_q: 2.377923, mean_eps: 0.212936
 394566/600000: episode: 553, duration: 11.184s, episode steps: 592, steps per second:  53, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.014798, mae: 1.978647, mean_q: 2.398433, mean_eps: 0.211460
 395059/600000: episode: 554, duration: 9.140s, episode steps: 493, steps per second:  54, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.097 [0.000, 5.000],  loss: 0.018315, mae: 1.995993, mean_q: 2.419317, mean_eps: 0.210376
 395926/600000: episode: 555, duration: 15.737s, episode steps: 867, steps per second:  55, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.014713, mae: 1.993687, mean_q: 2.418051, mean_eps: 0.209016
 397034/600000: episode: 556, duration: 19.415s, episode steps: 1108, steps per second:  57, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.015658, mae: 1.982760, mean_q: 2.402820, mean_eps: 0.207040
 397435/600000: episode: 557, duration: 7.047s, episode steps: 401, steps per second:  57, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.013630, mae: 1.982708, mean_q: 2.403582, mean_eps: 0.205532
 398121/600000: episode: 558, duration: 12.140s, episode steps: 686, steps per second:  57, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.016050, mae: 1.959917, mean_q: 2.375796, mean_eps: 0.204444
 398606/600000: episode: 559, duration: 8.722s, episode steps: 485, steps per second:  56, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.893 [0.000, 5.000],  loss: 0.016455, mae: 1.998573, mean_q: 2.424403, mean_eps: 0.203272
 399329/600000: episode: 560, duration: 12.323s, episode steps: 723, steps per second:  59, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.015400, mae: 1.958099, mean_q: 2.371337, mean_eps: 0.202064
 399845/600000: episode: 561, duration: 8.572s, episode steps: 516, steps per second:  60, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.016010, mae: 1.971013, mean_q: 2.386580, mean_eps: 0.200824
 400251/600000: episode: 562, duration: 6.653s, episode steps: 406, steps per second:  61, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.015539, mae: 1.999078, mean_q: 2.424053, mean_eps: 0.199904
 401057/600000: episode: 563, duration: 13.599s, episode steps: 806, steps per second:  59, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.014825, mae: 1.991961, mean_q: 2.414983, mean_eps: 0.198692
 401721/600000: episode: 564, duration: 11.871s, episode steps: 664, steps per second:  56, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.016620, mae: 2.004053, mean_q: 2.428196, mean_eps: 0.197220
 402334/600000: episode: 565, duration: 10.756s, episode steps: 613, steps per second:  57, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.545 [0.000, 5.000],  loss: 0.015962, mae: 1.999283, mean_q: 2.423806, mean_eps: 0.195944
 402964/600000: episode: 566, duration: 10.790s, episode steps: 630, steps per second:  58, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.746 [0.000, 5.000],  loss: 0.014070, mae: 2.002560, mean_q: 2.427183, mean_eps: 0.194704
 403931/600000: episode: 567, duration: 16.571s, episode steps: 967, steps per second:  58, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.971 [0.000, 5.000],  loss: 0.015168, mae: 1.990285, mean_q: 2.411917, mean_eps: 0.193108
 404602/600000: episode: 568, duration: 11.882s, episode steps: 671, steps per second:  56, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.015877, mae: 1.987407, mean_q: 2.409093, mean_eps: 0.191468
 405386/600000: episode: 569, duration: 13.538s, episode steps: 784, steps per second:  58, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.016695, mae: 2.006744, mean_q: 2.431431, mean_eps: 0.190012
 406087/600000: episode: 570, duration: 12.653s, episode steps: 701, steps per second:  55, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.605 [0.000, 5.000],  loss: 0.015940, mae: 2.001731, mean_q: 2.426915, mean_eps: 0.188528
 407525/600000: episode: 571, duration: 25.945s, episode steps: 1438, steps per second:  55, episode reward: 21.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.014539, mae: 2.004492, mean_q: 2.428567, mean_eps: 0.186388
 408124/600000: episode: 572, duration: 11.479s, episode steps: 599, steps per second:  52, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.013961, mae: 2.016829, mean_q: 2.444106, mean_eps: 0.184352
 408788/600000: episode: 573, duration: 13.053s, episode steps: 664, steps per second:  51, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.812 [0.000, 5.000],  loss: 0.015058, mae: 1.994639, mean_q: 2.416872, mean_eps: 0.183092
 410286/600000: episode: 574, duration: 26.266s, episode steps: 1498, steps per second:  57, episode reward: 29.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.014955, mae: 2.015478, mean_q: 2.440421, mean_eps: 0.180928
 411201/600000: episode: 575, duration: 16.572s, episode steps: 915, steps per second:  55, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.015372, mae: 2.037829, mean_q: 2.468267, mean_eps: 0.178512
 412205/600000: episode: 576, duration: 17.858s, episode steps: 1004, steps per second:  56, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.014140, mae: 2.012014, mean_q: 2.436806, mean_eps: 0.176592
 412551/600000: episode: 577, duration: 6.053s, episode steps: 346, steps per second:  57, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.717 [0.000, 5.000],  loss: 0.014568, mae: 2.031735, mean_q: 2.461869, mean_eps: 0.175244
 413219/600000: episode: 578, duration: 11.539s, episode steps: 668, steps per second:  58, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.019481, mae: 2.024376, mean_q: 2.449472, mean_eps: 0.174232
 413856/600000: episode: 579, duration: 10.840s, episode steps: 637, steps per second:  59, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.931 [0.000, 5.000],  loss: 0.014072, mae: 2.042153, mean_q: 2.473220, mean_eps: 0.172928
 414333/600000: episode: 580, duration: 8.739s, episode steps: 477, steps per second:  55, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.013795, mae: 2.004011, mean_q: 2.428311, mean_eps: 0.171812
 414994/600000: episode: 581, duration: 12.645s, episode steps: 661, steps per second:  52, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.017263, mae: 2.031521, mean_q: 2.462218, mean_eps: 0.170672
 415906/600000: episode: 582, duration: 17.254s, episode steps: 912, steps per second:  53, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.015291, mae: 2.039525, mean_q: 2.472401, mean_eps: 0.169100
 416672/600000: episode: 583, duration: 14.128s, episode steps: 766, steps per second:  54, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.020295, mae: 2.060645, mean_q: 2.497102, mean_eps: 0.167424
 417387/600000: episode: 584, duration: 12.881s, episode steps: 715, steps per second:  56, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.016325, mae: 2.037695, mean_q: 2.471413, mean_eps: 0.165944
 418300/600000: episode: 585, duration: 17.218s, episode steps: 913, steps per second:  53, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.014414, mae: 2.040294, mean_q: 2.470877, mean_eps: 0.164316
 419154/600000: episode: 586, duration: 15.460s, episode steps: 854, steps per second:  55, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.907 [0.000, 5.000],  loss: 0.015259, mae: 2.014705, mean_q: 2.439929, mean_eps: 0.162548
 419676/600000: episode: 587, duration: 8.919s, episode steps: 522, steps per second:  59, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.015578, mae: 2.070789, mean_q: 2.506661, mean_eps: 0.161172
 420847/600000: episode: 588, duration: 20.361s, episode steps: 1171, steps per second:  58, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.016704, mae: 2.060016, mean_q: 2.495680, mean_eps: 0.159480
 421708/600000: episode: 589, duration: 14.944s, episode steps: 861, steps per second:  58, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.020054, mae: 2.080332, mean_q: 2.518616, mean_eps: 0.157448
 422396/600000: episode: 590, duration: 12.934s, episode steps: 688, steps per second:  53, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.016845, mae: 2.058135, mean_q: 2.493656, mean_eps: 0.155900
 423854/600000: episode: 591, duration: 25.000s, episode steps: 1458, steps per second:  58, episode reward: 27.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.017150, mae: 2.053560, mean_q: 2.487384, mean_eps: 0.153752
 424801/600000: episode: 592, duration: 16.955s, episode steps: 947, steps per second:  56, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.978 [0.000, 5.000],  loss: 0.015112, mae: 2.051973, mean_q: 2.485192, mean_eps: 0.151344
 426534/600000: episode: 593, duration: 31.021s, episode steps: 1733, steps per second:  56, episode reward: 33.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.017385, mae: 2.078144, mean_q: 2.518426, mean_eps: 0.148664
 427328/600000: episode: 594, duration: 14.228s, episode steps: 794, steps per second:  56, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.015374, mae: 2.082133, mean_q: 2.523812, mean_eps: 0.146140
 428052/600000: episode: 595, duration: 14.409s, episode steps: 724, steps per second:  50, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.844 [0.000, 5.000],  loss: 0.018402, mae: 2.093562, mean_q: 2.535204, mean_eps: 0.144624
 428704/600000: episode: 596, duration: 12.653s, episode steps: 652, steps per second:  52, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.017734, mae: 2.095718, mean_q: 2.538457, mean_eps: 0.143248
 429368/600000: episode: 597, duration: 12.390s, episode steps: 664, steps per second:  54, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.014931, mae: 2.100279, mean_q: 2.545522, mean_eps: 0.141932
 430414/600000: episode: 598, duration: 19.053s, episode steps: 1046, steps per second:  55, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.998 [0.000, 5.000],  loss: 0.014212, mae: 2.081229, mean_q: 2.521475, mean_eps: 0.140220
 431315/600000: episode: 599, duration: 16.201s, episode steps: 901, steps per second:  56, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.745 [0.000, 5.000],  loss: 0.015314, mae: 2.080714, mean_q: 2.519514, mean_eps: 0.138272
 432056/600000: episode: 600, duration: 13.076s, episode steps: 741, steps per second:  57, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.016022, mae: 2.083787, mean_q: 2.522905, mean_eps: 0.136632
 432923/600000: episode: 601, duration: 15.850s, episode steps: 867, steps per second:  55, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.015672, mae: 2.062002, mean_q: 2.495926, mean_eps: 0.135024
 434170/600000: episode: 602, duration: 23.298s, episode steps: 1247, steps per second:  54, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.017630, mae: 2.083407, mean_q: 2.521891, mean_eps: 0.132908
 435115/600000: episode: 603, duration: 19.063s, episode steps: 945, steps per second:  50, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.017074, mae: 2.086386, mean_q: 2.525837, mean_eps: 0.130716
 435886/600000: episode: 604, duration: 14.453s, episode steps: 771, steps per second:  53, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.015089, mae: 2.103788, mean_q: 2.547153, mean_eps: 0.129000
 436653/600000: episode: 605, duration: 14.104s, episode steps: 767, steps per second:  54, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.015764, mae: 2.116937, mean_q: 2.563063, mean_eps: 0.127460
 437700/600000: episode: 606, duration: 19.111s, episode steps: 1047, steps per second:  55, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.016190, mae: 2.105277, mean_q: 2.548906, mean_eps: 0.125648
 438339/600000: episode: 607, duration: 11.669s, episode steps: 639, steps per second:  55, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.019208, mae: 2.118479, mean_q: 2.562031, mean_eps: 0.123964
 439459/600000: episode: 608, duration: 19.391s, episode steps: 1120, steps per second:  58, episode reward: 29.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.957 [0.000, 5.000],  loss: 0.016811, mae: 2.082467, mean_q: 2.520379, mean_eps: 0.122204
 440319/600000: episode: 609, duration: 15.120s, episode steps: 860, steps per second:  57, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.957 [0.000, 5.000],  loss: 0.018449, mae: 2.104607, mean_q: 2.545924, mean_eps: 0.120224
 441137/600000: episode: 610, duration: 14.690s, episode steps: 818, steps per second:  56, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.616 [0.000, 5.000],  loss: 0.016548, mae: 2.111413, mean_q: 2.556867, mean_eps: 0.118544
 442207/600000: episode: 611, duration: 19.499s, episode steps: 1070, steps per second:  55, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.765 [0.000, 5.000],  loss: 0.016515, mae: 2.120201, mean_q: 2.567830, mean_eps: 0.116656
 442858/600000: episode: 612, duration: 11.528s, episode steps: 651, steps per second:  56, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.016614, mae: 2.130687, mean_q: 2.580728, mean_eps: 0.114936
 443703/600000: episode: 613, duration: 14.808s, episode steps: 845, steps per second:  57, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.017879, mae: 2.131356, mean_q: 2.579341, mean_eps: 0.113440
 444812/600000: episode: 614, duration: 19.556s, episode steps: 1109, steps per second:  57, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.017438, mae: 2.125807, mean_q: 2.571833, mean_eps: 0.111488
 446009/600000: episode: 615, duration: 21.211s, episode steps: 1197, steps per second:  56, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.037 [0.000, 5.000],  loss: 0.016941, mae: 2.157851, mean_q: 2.610763, mean_eps: 0.109180
 447491/600000: episode: 616, duration: 27.708s, episode steps: 1482, steps per second:  53, episode reward: 29.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.017434, mae: 2.151563, mean_q: 2.604026, mean_eps: 0.106500
 448720/600000: episode: 617, duration: 24.820s, episode steps: 1229, steps per second:  50, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.016707, mae: 2.173161, mean_q: 2.629711, mean_eps: 0.103792
 449353/600000: episode: 618, duration: 11.219s, episode steps: 633, steps per second:  56, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.017604, mae: 2.167239, mean_q: 2.624443, mean_eps: 0.101928
 450478/600000: episode: 619, duration: 20.869s, episode steps: 1125, steps per second:  54, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.016665, mae: 2.179898, mean_q: 2.637481, mean_eps: 0.100371
 451135/600000: episode: 620, duration: 12.304s, episode steps: 657, steps per second:  53, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.855 [0.000, 5.000],  loss: 0.015050, mae: 2.180938, mean_q: 2.639361, mean_eps: 0.100000
 452302/600000: episode: 621, duration: 22.308s, episode steps: 1167, steps per second:  52, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.682 [0.000, 5.000],  loss: 0.015797, mae: 2.185554, mean_q: 2.645033, mean_eps: 0.100000
 453353/600000: episode: 622, duration: 20.206s, episode steps: 1051, steps per second:  52, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.860 [0.000, 5.000],  loss: 0.018438, mae: 2.197396, mean_q: 2.659818, mean_eps: 0.100000
 453874/600000: episode: 623, duration: 10.110s, episode steps: 521, steps per second:  52, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.019117, mae: 2.189516, mean_q: 2.648101, mean_eps: 0.100000
 454491/600000: episode: 624, duration: 11.990s, episode steps: 617, steps per second:  51, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.015345, mae: 2.182752, mean_q: 2.642176, mean_eps: 0.100000
 455497/600000: episode: 625, duration: 18.663s, episode steps: 1006, steps per second:  54, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.749 [0.000, 5.000],  loss: 0.015100, mae: 2.189138, mean_q: 2.648781, mean_eps: 0.100000
 456041/600000: episode: 626, duration: 9.886s, episode steps: 544, steps per second:  55, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.017922, mae: 2.186040, mean_q: 2.645513, mean_eps: 0.100000
 456683/600000: episode: 627, duration: 11.600s, episode steps: 642, steps per second:  55, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.773 [0.000, 5.000],  loss: 0.013542, mae: 2.192460, mean_q: 2.654592, mean_eps: 0.100000
 457309/600000: episode: 628, duration: 12.032s, episode steps: 626, steps per second:  52, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.016509, mae: 2.159806, mean_q: 2.613397, mean_eps: 0.100000
 457915/600000: episode: 629, duration: 11.414s, episode steps: 606, steps per second:  53, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.092 [0.000, 5.000],  loss: 0.018334, mae: 2.183081, mean_q: 2.639068, mean_eps: 0.100000
 458826/600000: episode: 630, duration: 16.213s, episode steps: 911, steps per second:  56, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.514 [0.000, 5.000],  loss: 0.018452, mae: 2.179606, mean_q: 2.634827, mean_eps: 0.100000
 459698/600000: episode: 631, duration: 15.295s, episode steps: 872, steps per second:  57, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.017313, mae: 2.194908, mean_q: 2.654147, mean_eps: 0.100000
 460563/600000: episode: 632, duration: 16.394s, episode steps: 865, steps per second:  53, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.764 [0.000, 5.000],  loss: 0.015522, mae: 2.201714, mean_q: 2.663405, mean_eps: 0.100000
 461826/600000: episode: 633, duration: 23.677s, episode steps: 1263, steps per second:  53, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.015774, mae: 2.184192, mean_q: 2.640662, mean_eps: 0.100000
 462869/600000: episode: 634, duration: 18.602s, episode steps: 1043, steps per second:  56, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.018845, mae: 2.180177, mean_q: 2.634819, mean_eps: 0.100000
 463641/600000: episode: 635, duration: 13.547s, episode steps: 772, steps per second:  57, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.016434, mae: 2.203709, mean_q: 2.664342, mean_eps: 0.100000
 464445/600000: episode: 636, duration: 14.510s, episode steps: 804, steps per second:  55, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.868 [0.000, 5.000],  loss: 0.015584, mae: 2.171395, mean_q: 2.625127, mean_eps: 0.100000
 464911/600000: episode: 637, duration: 8.509s, episode steps: 466, steps per second:  55, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.015459, mae: 2.176276, mean_q: 2.630452, mean_eps: 0.100000
 466017/600000: episode: 638, duration: 20.226s, episode steps: 1106, steps per second:  55, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.015145, mae: 2.181206, mean_q: 2.637315, mean_eps: 0.100000
 466721/600000: episode: 639, duration: 13.722s, episode steps: 704, steps per second:  51, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.016331, mae: 2.207869, mean_q: 2.668541, mean_eps: 0.100000
 467555/600000: episode: 640, duration: 17.114s, episode steps: 834, steps per second:  49, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.853 [0.000, 5.000],  loss: 0.014622, mae: 2.195434, mean_q: 2.655677, mean_eps: 0.100000
 468208/600000: episode: 641, duration: 12.489s, episode steps: 653, steps per second:  52, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.014977, mae: 2.202003, mean_q: 2.663722, mean_eps: 0.100000
 468615/600000: episode: 642, duration: 7.386s, episode steps: 407, steps per second:  55, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.013496, mae: 2.180610, mean_q: 2.635745, mean_eps: 0.100000
 469562/600000: episode: 643, duration: 17.822s, episode steps: 947, steps per second:  53, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.015927, mae: 2.202277, mean_q: 2.663889, mean_eps: 0.100000
 470000/600000: episode: 644, duration: 8.117s, episode steps: 438, steps per second:  54, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 4.194 [0.000, 5.000],  loss: 0.016772, mae: 2.242090, mean_q: 2.713223, mean_eps: 0.100000
 470790/600000: episode: 645, duration: 14.904s, episode steps: 790, steps per second:  53, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.013499, mae: 2.209544, mean_q: 2.674173, mean_eps: 0.100000
 471357/600000: episode: 646, duration: 10.357s, episode steps: 567, steps per second:  55, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.014965, mae: 2.218687, mean_q: 2.685291, mean_eps: 0.100000
 471915/600000: episode: 647, duration: 10.006s, episode steps: 558, steps per second:  56, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.620 [0.000, 5.000],  loss: 0.016804, mae: 2.222877, mean_q: 2.687743, mean_eps: 0.100000
 472877/600000: episode: 648, duration: 17.122s, episode steps: 962, steps per second:  56, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.837 [0.000, 5.000],  loss: 0.018414, mae: 2.206535, mean_q: 2.667212, mean_eps: 0.100000
 473308/600000: episode: 649, duration: 9.010s, episode steps: 431, steps per second:  48, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.014465, mae: 2.202389, mean_q: 2.661991, mean_eps: 0.100000
 474186/600000: episode: 650, duration: 18.164s, episode steps: 878, steps per second:  48, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.016386, mae: 2.221431, mean_q: 2.687026, mean_eps: 0.100000
 475605/600000: episode: 651, duration: 26.139s, episode steps: 1419, steps per second:  54, episode reward: 28.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.017089, mae: 2.237943, mean_q: 2.708258, mean_eps: 0.100000
 476104/600000: episode: 652, duration: 9.568s, episode steps: 499, steps per second:  52, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.017692, mae: 2.286915, mean_q: 2.766980, mean_eps: 0.100000
 476497/600000: episode: 653, duration: 7.444s, episode steps: 393, steps per second:  53, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.013723, mae: 2.273913, mean_q: 2.752544, mean_eps: 0.100000
 477136/600000: episode: 654, duration: 12.054s, episode steps: 639, steps per second:  53, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.016990, mae: 2.274386, mean_q: 2.750093, mean_eps: 0.100000
 478090/600000: episode: 655, duration: 16.874s, episode steps: 954, steps per second:  57, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.128 [0.000, 5.000],  loss: 0.019120, mae: 2.263062, mean_q: 2.735806, mean_eps: 0.100000
 478634/600000: episode: 656, duration: 9.412s, episode steps: 544, steps per second:  58, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.695 [0.000, 5.000],  loss: 0.017381, mae: 2.285395, mean_q: 2.764260, mean_eps: 0.100000
 479408/600000: episode: 657, duration: 13.388s, episode steps: 774, steps per second:  58, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.556 [0.000, 5.000],  loss: 0.016123, mae: 2.276014, mean_q: 2.752992, mean_eps: 0.100000
 479944/600000: episode: 658, duration: 9.531s, episode steps: 536, steps per second:  56, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.530 [0.000, 5.000],  loss: 0.016311, mae: 2.238731, mean_q: 2.709761, mean_eps: 0.100000
 480583/600000: episode: 659, duration: 11.511s, episode steps: 639, steps per second:  56, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.014787, mae: 2.267873, mean_q: 2.743456, mean_eps: 0.100000
 481257/600000: episode: 660, duration: 11.934s, episode steps: 674, steps per second:  56, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.046 [0.000, 5.000],  loss: 0.015273, mae: 2.264030, mean_q: 2.737962, mean_eps: 0.100000
 482169/600000: episode: 661, duration: 15.973s, episode steps: 912, steps per second:  57, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.014523, mae: 2.281244, mean_q: 2.760471, mean_eps: 0.100000
 483295/600000: episode: 662, duration: 21.365s, episode steps: 1126, steps per second:  53, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.056 [0.000, 5.000],  loss: 0.020140, mae: 2.270225, mean_q: 2.743397, mean_eps: 0.100000
 485133/600000: episode: 663, duration: 35.405s, episode steps: 1838, steps per second:  52, episode reward: 32.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.017279, mae: 2.278186, mean_q: 2.753872, mean_eps: 0.100000
 486111/600000: episode: 664, duration: 21.359s, episode steps: 978, steps per second:  46, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.865 [0.000, 5.000],  loss: 0.016077, mae: 2.293569, mean_q: 2.771936, mean_eps: 0.100000
 486605/600000: episode: 665, duration: 11.471s, episode steps: 494, steps per second:  43, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.015720, mae: 2.340269, mean_q: 2.827546, mean_eps: 0.100000
 487646/600000: episode: 666, duration: 24.744s, episode steps: 1041, steps per second:  42, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.017563, mae: 2.303216, mean_q: 2.784841, mean_eps: 0.100000
 488294/600000: episode: 667, duration: 13.697s, episode steps: 648, steps per second:  47, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.880 [0.000, 5.000],  loss: 0.017828, mae: 2.300073, mean_q: 2.781495, mean_eps: 0.100000
 489127/600000: episode: 668, duration: 17.477s, episode steps: 833, steps per second:  48, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.690 [0.000, 5.000],  loss: 0.015530, mae: 2.309970, mean_q: 2.793342, mean_eps: 0.100000
 489973/600000: episode: 669, duration: 16.863s, episode steps: 846, steps per second:  50, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.015835, mae: 2.305527, mean_q: 2.787221, mean_eps: 0.100000
 490926/600000: episode: 670, duration: 19.467s, episode steps: 953, steps per second:  49, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.016013, mae: 2.363542, mean_q: 2.858676, mean_eps: 0.100000
 491654/600000: episode: 671, duration: 15.461s, episode steps: 728, steps per second:  47, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.016099, mae: 2.369046, mean_q: 2.864567, mean_eps: 0.100000
 492346/600000: episode: 672, duration: 14.052s, episode steps: 692, steps per second:  49, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: 0.016075, mae: 2.339573, mean_q: 2.830840, mean_eps: 0.100000
 493290/600000: episode: 673, duration: 19.347s, episode steps: 944, steps per second:  49, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.015286, mae: 2.335910, mean_q: 2.826013, mean_eps: 0.100000
 494075/600000: episode: 674, duration: 15.662s, episode steps: 785, steps per second:  50, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.017572, mae: 2.344928, mean_q: 2.834842, mean_eps: 0.100000
 494964/600000: episode: 675, duration: 18.862s, episode steps: 889, steps per second:  47, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.924 [0.000, 5.000],  loss: 0.014603, mae: 2.355446, mean_q: 2.848038, mean_eps: 0.100000
 495836/600000: episode: 676, duration: 18.000s, episode steps: 872, steps per second:  48, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.017310, mae: 2.370180, mean_q: 2.865484, mean_eps: 0.100000
 496523/600000: episode: 677, duration: 12.794s, episode steps: 687, steps per second:  54, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.016178, mae: 2.376750, mean_q: 2.874222, mean_eps: 0.100000
 497036/600000: episode: 678, duration: 10.032s, episode steps: 513, steps per second:  51, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.016599, mae: 2.389054, mean_q: 2.886956, mean_eps: 0.100000
 497686/600000: episode: 679, duration: 12.987s, episode steps: 650, steps per second:  50, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.017871, mae: 2.392808, mean_q: 2.893970, mean_eps: 0.100000
 498723/600000: episode: 680, duration: 21.296s, episode steps: 1037, steps per second:  49, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.016364, mae: 2.373410, mean_q: 2.868511, mean_eps: 0.100000
 499352/600000: episode: 681, duration: 12.065s, episode steps: 629, steps per second:  52, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.774 [0.000, 5.000],  loss: 0.019862, mae: 2.365843, mean_q: 2.860428, mean_eps: 0.100000
 500089/600000: episode: 682, duration: 14.038s, episode steps: 737, steps per second:  52, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.016013, mae: 2.372848, mean_q: 2.869834, mean_eps: 0.100000
 500895/600000: episode: 683, duration: 14.537s, episode steps: 806, steps per second:  55, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.017332, mae: 2.390261, mean_q: 2.891294, mean_eps: 0.100000
 501420/600000: episode: 684, duration: 10.857s, episode steps: 525, steps per second:  48, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.827 [0.000, 5.000],  loss: 0.018363, mae: 2.391686, mean_q: 2.891491, mean_eps: 0.100000
 502201/600000: episode: 685, duration: 16.134s, episode steps: 781, steps per second:  48, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.015474, mae: 2.395417, mean_q: 2.896571, mean_eps: 0.100000
 503020/600000: episode: 686, duration: 16.790s, episode steps: 819, steps per second:  49, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.015709, mae: 2.396041, mean_q: 2.897659, mean_eps: 0.100000
 503507/600000: episode: 687, duration: 9.687s, episode steps: 487, steps per second:  50, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.016114, mae: 2.389822, mean_q: 2.890007, mean_eps: 0.100000
 504570/600000: episode: 688, duration: 21.353s, episode steps: 1063, steps per second:  50, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.018027, mae: 2.420778, mean_q: 2.927666, mean_eps: 0.100000
 505438/600000: episode: 689, duration: 16.374s, episode steps: 868, steps per second:  53, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.016532, mae: 2.422027, mean_q: 2.928691, mean_eps: 0.100000
 505823/600000: episode: 690, duration: 7.248s, episode steps: 385, steps per second:  53, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.771 [0.000, 5.000],  loss: 0.015503, mae: 2.459018, mean_q: 2.976797, mean_eps: 0.100000
 506524/600000: episode: 691, duration: 13.216s, episode steps: 701, steps per second:  53, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.015729, mae: 2.475201, mean_q: 2.994537, mean_eps: 0.100000
 507013/600000: episode: 692, duration: 9.686s, episode steps: 489, steps per second:  50, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.933 [0.000, 5.000],  loss: 0.014811, mae: 2.424684, mean_q: 2.930861, mean_eps: 0.100000
 507899/600000: episode: 693, duration: 17.607s, episode steps: 886, steps per second:  50, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.017682, mae: 2.450677, mean_q: 2.962580, mean_eps: 0.100000
 508861/600000: episode: 694, duration: 19.526s, episode steps: 962, steps per second:  49, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.015442, mae: 2.453637, mean_q: 2.964494, mean_eps: 0.100000
 509360/600000: episode: 695, duration: 10.648s, episode steps: 499, steps per second:  47, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.015843, mae: 2.459505, mean_q: 2.973465, mean_eps: 0.100000
 510472/600000: episode: 696, duration: 22.861s, episode steps: 1112, steps per second:  49, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.032 [0.000, 5.000],  loss: 0.015808, mae: 2.440042, mean_q: 2.950116, mean_eps: 0.100000
 511283/600000: episode: 697, duration: 17.315s, episode steps: 811, steps per second:  47, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.748 [0.000, 5.000],  loss: 0.016856, mae: 2.452375, mean_q: 2.966877, mean_eps: 0.100000
 512113/600000: episode: 698, duration: 18.118s, episode steps: 830, steps per second:  46, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.894 [0.000, 5.000],  loss: 0.017351, mae: 2.481616, mean_q: 3.003023, mean_eps: 0.100000
 512692/600000: episode: 699, duration: 12.516s, episode steps: 579, steps per second:  46, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.644 [0.000, 5.000],  loss: 0.017526, mae: 2.474682, mean_q: 2.992511, mean_eps: 0.100000
 513496/600000: episode: 700, duration: 17.542s, episode steps: 804, steps per second:  46, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.017693, mae: 2.474401, mean_q: 2.993202, mean_eps: 0.100000
 514219/600000: episode: 701, duration: 13.718s, episode steps: 723, steps per second:  53, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.018274, mae: 2.480467, mean_q: 2.998921, mean_eps: 0.100000
 515069/600000: episode: 702, duration: 16.140s, episode steps: 850, steps per second:  53, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.018866, mae: 2.482801, mean_q: 3.000854, mean_eps: 0.100000
 516115/600000: episode: 703, duration: 20.432s, episode steps: 1046, steps per second:  51, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.005 [0.000, 5.000],  loss: 0.015789, mae: 2.519934, mean_q: 3.047074, mean_eps: 0.100000
 516747/600000: episode: 704, duration: 12.729s, episode steps: 632, steps per second:  50, episode reward: 17.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.017087, mae: 2.534525, mean_q: 3.065263, mean_eps: 0.100000
 517695/600000: episode: 705, duration: 17.928s, episode steps: 948, steps per second:  53, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.064 [0.000, 5.000],  loss: 0.014786, mae: 2.513422, mean_q: 3.038131, mean_eps: 0.100000
 518383/600000: episode: 706, duration: 12.764s, episode steps: 688, steps per second:  54, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.016792, mae: 2.499245, mean_q: 3.020380, mean_eps: 0.100000
 519352/600000: episode: 707, duration: 18.789s, episode steps: 969, steps per second:  52, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.016026, mae: 2.509865, mean_q: 3.033176, mean_eps: 0.100000
 520157/600000: episode: 708, duration: 17.100s, episode steps: 805, steps per second:  47, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.901 [0.000, 5.000],  loss: 0.015927, mae: 2.509226, mean_q: 3.036244, mean_eps: 0.100000
 521046/600000: episode: 709, duration: 18.089s, episode steps: 889, steps per second:  49, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.018113, mae: 2.516979, mean_q: 3.043690, mean_eps: 0.100000
 521752/600000: episode: 710, duration: 14.565s, episode steps: 706, steps per second:  48, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.014981, mae: 2.512710, mean_q: 3.037210, mean_eps: 0.100000
 522402/600000: episode: 711, duration: 13.383s, episode steps: 650, steps per second:  49, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.886 [0.000, 5.000],  loss: 0.018408, mae: 2.505943, mean_q: 3.024837, mean_eps: 0.100000
 523334/600000: episode: 712, duration: 19.392s, episode steps: 932, steps per second:  48, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.018376, mae: 2.553340, mean_q: 3.086014, mean_eps: 0.100000
 524411/600000: episode: 713, duration: 22.736s, episode steps: 1077, steps per second:  47, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.018355, mae: 2.514697, mean_q: 3.038487, mean_eps: 0.100000
 524965/600000: episode: 714, duration: 11.768s, episode steps: 554, steps per second:  47, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.644 [0.000, 5.000],  loss: 0.016322, mae: 2.531561, mean_q: 3.060084, mean_eps: 0.100000
 525921/600000: episode: 715, duration: 19.326s, episode steps: 956, steps per second:  49, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.802 [0.000, 5.000],  loss: 0.016309, mae: 2.517393, mean_q: 3.044668, mean_eps: 0.100000
 526754/600000: episode: 716, duration: 16.525s, episode steps: 833, steps per second:  50, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.527 [0.000, 5.000],  loss: 0.015223, mae: 2.542972, mean_q: 3.074439, mean_eps: 0.100000
 527687/600000: episode: 717, duration: 21.208s, episode steps: 933, steps per second:  44, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.807 [0.000, 5.000],  loss: 0.015146, mae: 2.517320, mean_q: 3.043271, mean_eps: 0.100000
 528559/600000: episode: 718, duration: 20.524s, episode steps: 872, steps per second:  42, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.401 [0.000, 5.000],  loss: 0.016917, mae: 2.529864, mean_q: 3.057357, mean_eps: 0.100000
 529565/600000: episode: 719, duration: 22.025s, episode steps: 1006, steps per second:  46, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.017021, mae: 2.542468, mean_q: 3.072180, mean_eps: 0.100000
 530301/600000: episode: 720, duration: 16.254s, episode steps: 736, steps per second:  45, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.016669, mae: 2.538811, mean_q: 3.069680, mean_eps: 0.100000
 530966/600000: episode: 721, duration: 14.701s, episode steps: 665, steps per second:  45, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.263 [0.000, 5.000],  loss: 0.014977, mae: 2.536985, mean_q: 3.070054, mean_eps: 0.100000
 531964/600000: episode: 722, duration: 19.965s, episode steps: 998, steps per second:  50, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.987 [0.000, 5.000],  loss: 0.018760, mae: 2.549443, mean_q: 3.082481, mean_eps: 0.100000
 532749/600000: episode: 723, duration: 15.471s, episode steps: 785, steps per second:  51, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.018212, mae: 2.544658, mean_q: 3.077046, mean_eps: 0.100000
 534246/600000: episode: 724, duration: 32.401s, episode steps: 1497, steps per second:  46, episode reward: 30.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.020078, mae: 2.545852, mean_q: 3.077475, mean_eps: 0.100000
 535048/600000: episode: 725, duration: 15.562s, episode steps: 802, steps per second:  52, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.936 [0.000, 5.000],  loss: 0.018401, mae: 2.516373, mean_q: 3.042923, mean_eps: 0.100000
 535769/600000: episode: 726, duration: 14.099s, episode steps: 721, steps per second:  51, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.857 [0.000, 5.000],  loss: 0.018034, mae: 2.551020, mean_q: 3.085109, mean_eps: 0.100000
 536883/600000: episode: 727, duration: 22.353s, episode steps: 1114, steps per second:  50, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.018142, mae: 2.555379, mean_q: 3.089618, mean_eps: 0.100000
 537773/600000: episode: 728, duration: 18.078s, episode steps: 890, steps per second:  49, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.018154, mae: 2.576614, mean_q: 3.117031, mean_eps: 0.100000
 538310/600000: episode: 729, duration: 11.267s, episode steps: 537, steps per second:  48, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.043 [0.000, 5.000],  loss: 0.017089, mae: 2.550180, mean_q: 3.082407, mean_eps: 0.100000
 539425/600000: episode: 730, duration: 24.922s, episode steps: 1115, steps per second:  45, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.015131, mae: 2.563061, mean_q: 3.098874, mean_eps: 0.100000
 540174/600000: episode: 731, duration: 15.720s, episode steps: 749, steps per second:  48, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.017198, mae: 2.563202, mean_q: 3.100071, mean_eps: 0.100000
 540875/600000: episode: 732, duration: 13.928s, episode steps: 701, steps per second:  50, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.019112, mae: 2.560346, mean_q: 3.095050, mean_eps: 0.100000
 541809/600000: episode: 733, duration: 18.791s, episode steps: 934, steps per second:  50, episode reward: 28.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.015523, mae: 2.531258, mean_q: 3.062053, mean_eps: 0.100000
 542802/600000: episode: 734, duration: 20.909s, episode steps: 993, steps per second:  47, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.422 [0.000, 5.000],  loss: 0.018252, mae: 2.578191, mean_q: 3.116696, mean_eps: 0.100000
 543422/600000: episode: 735, duration: 12.623s, episode steps: 620, steps per second:  49, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.017436, mae: 2.573801, mean_q: 3.108478, mean_eps: 0.100000
 544487/600000: episode: 736, duration: 22.626s, episode steps: 1065, steps per second:  47, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.018735, mae: 2.547779, mean_q: 3.080142, mean_eps: 0.100000
 545011/600000: episode: 737, duration: 12.020s, episode steps: 524, steps per second:  44, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.015266, mae: 2.555984, mean_q: 3.088076, mean_eps: 0.100000
 545993/600000: episode: 738, duration: 21.286s, episode steps: 982, steps per second:  46, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.014732, mae: 2.543515, mean_q: 3.074160, mean_eps: 0.100000
 546642/600000: episode: 739, duration: 13.323s, episode steps: 649, steps per second:  49, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.908 [0.000, 5.000],  loss: 0.014988, mae: 2.551075, mean_q: 3.084830, mean_eps: 0.100000
 547335/600000: episode: 740, duration: 15.229s, episode steps: 693, steps per second:  46, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.015875, mae: 2.543240, mean_q: 3.074121, mean_eps: 0.100000
 548308/600000: episode: 741, duration: 21.066s, episode steps: 973, steps per second:  46, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.736 [0.000, 5.000],  loss: 0.017578, mae: 2.540152, mean_q: 3.070269, mean_eps: 0.100000
 549437/600000: episode: 742, duration: 21.554s, episode steps: 1129, steps per second:  52, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.015566, mae: 2.550424, mean_q: 3.080815, mean_eps: 0.100000
 549957/600000: episode: 743, duration: 9.972s, episode steps: 520, steps per second:  52, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.016772, mae: 2.557740, mean_q: 3.090204, mean_eps: 0.100000
 550946/600000: episode: 744, duration: 20.538s, episode steps: 989, steps per second:  48, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.014644, mae: 2.583042, mean_q: 3.121382, mean_eps: 0.100000
 551571/600000: episode: 745, duration: 12.259s, episode steps: 625, steps per second:  51, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.017022, mae: 2.604705, mean_q: 3.147176, mean_eps: 0.100000
 553230/600000: episode: 746, duration: 31.117s, episode steps: 1659, steps per second:  53, episode reward: 35.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.017739, mae: 2.586255, mean_q: 3.125546, mean_eps: 0.100000
 553859/600000: episode: 747, duration: 12.022s, episode steps: 629, steps per second:  52, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.015776, mae: 2.599926, mean_q: 3.141681, mean_eps: 0.100000
 554596/600000: episode: 748, duration: 14.892s, episode steps: 737, steps per second:  49, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.015662, mae: 2.621325, mean_q: 3.169670, mean_eps: 0.100000
 555749/600000: episode: 749, duration: 24.815s, episode steps: 1153, steps per second:  46, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.853 [0.000, 5.000],  loss: 0.016079, mae: 2.612926, mean_q: 3.157069, mean_eps: 0.100000
 556224/600000: episode: 750, duration: 11.731s, episode steps: 475, steps per second:  40, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.017220, mae: 2.625364, mean_q: 3.172372, mean_eps: 0.100000
 557224/600000: episode: 751, duration: 25.519s, episode steps: 1000, steps per second:  39, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.015740, mae: 2.645394, mean_q: 3.199458, mean_eps: 0.100000
 557945/600000: episode: 752, duration: 15.684s, episode steps: 721, steps per second:  46, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.015759, mae: 2.620658, mean_q: 3.167357, mean_eps: 0.100000
 558453/600000: episode: 753, duration: 11.345s, episode steps: 508, steps per second:  45, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.015354, mae: 2.643496, mean_q: 3.194687, mean_eps: 0.100000
 559145/600000: episode: 754, duration: 14.387s, episode steps: 692, steps per second:  48, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.016556, mae: 2.662115, mean_q: 3.218375, mean_eps: 0.100000
 560078/600000: episode: 755, duration: 20.138s, episode steps: 933, steps per second:  46, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.014165, mae: 2.634510, mean_q: 3.183532, mean_eps: 0.100000
 560643/600000: episode: 756, duration: 11.747s, episode steps: 565, steps per second:  48, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.805 [0.000, 5.000],  loss: 0.014513, mae: 2.592071, mean_q: 3.133231, mean_eps: 0.100000
 561669/600000: episode: 757, duration: 21.905s, episode steps: 1026, steps per second:  47, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.914 [0.000, 5.000],  loss: 0.016065, mae: 2.618335, mean_q: 3.163737, mean_eps: 0.100000
 562241/600000: episode: 758, duration: 12.452s, episode steps: 572, steps per second:  46, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.015735, mae: 2.610182, mean_q: 3.154278, mean_eps: 0.100000
 563120/600000: episode: 759, duration: 19.308s, episode steps: 879, steps per second:  46, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.015870, mae: 2.608578, mean_q: 3.151795, mean_eps: 0.100000
 563776/600000: episode: 760, duration: 14.678s, episode steps: 656, steps per second:  45, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.018576, mae: 2.635192, mean_q: 3.184337, mean_eps: 0.100000
 564754/600000: episode: 761, duration: 21.911s, episode steps: 978, steps per second:  45, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.016886, mae: 2.628197, mean_q: 3.173488, mean_eps: 0.100000
 565855/600000: episode: 762, duration: 22.878s, episode steps: 1101, steps per second:  48, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.084 [0.000, 5.000],  loss: 0.016029, mae: 2.607958, mean_q: 3.152196, mean_eps: 0.100000
 566654/600000: episode: 763, duration: 15.735s, episode steps: 799, steps per second:  51, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.861 [0.000, 5.000],  loss: 0.016053, mae: 2.625890, mean_q: 3.172864, mean_eps: 0.100000
 567530/600000: episode: 764, duration: 19.510s, episode steps: 876, steps per second:  45, episode reward: 25.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.016653, mae: 2.651011, mean_q: 3.203497, mean_eps: 0.100000
 568209/600000: episode: 765, duration: 14.416s, episode steps: 679, steps per second:  47, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.017883, mae: 2.637302, mean_q: 3.185269, mean_eps: 0.100000
 569036/600000: episode: 766, duration: 16.702s, episode steps: 827, steps per second:  50, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.017021, mae: 2.622391, mean_q: 3.168886, mean_eps: 0.100000
 569543/600000: episode: 767, duration: 10.129s, episode steps: 507, steps per second:  50, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.909 [0.000, 5.000],  loss: 0.015833, mae: 2.639935, mean_q: 3.191486, mean_eps: 0.100000
 570731/600000: episode: 768, duration: 24.899s, episode steps: 1188, steps per second:  48, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.015244, mae: 2.606716, mean_q: 3.149434, mean_eps: 0.100000
 571353/600000: episode: 769, duration: 12.595s, episode steps: 622, steps per second:  49, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.032 [0.000, 5.000],  loss: 0.014187, mae: 2.627600, mean_q: 3.175738, mean_eps: 0.100000
 572326/600000: episode: 770, duration: 20.157s, episode steps: 973, steps per second:  48, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.018427, mae: 2.611131, mean_q: 3.154456, mean_eps: 0.100000
 573107/600000: episode: 771, duration: 17.087s, episode steps: 781, steps per second:  46, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.786 [0.000, 5.000],  loss: 0.016609, mae: 2.603640, mean_q: 3.143364, mean_eps: 0.100000
 574030/600000: episode: 772, duration: 20.425s, episode steps: 923, steps per second:  45, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.015598, mae: 2.608388, mean_q: 3.150517, mean_eps: 0.100000
 574808/600000: episode: 773, duration: 15.349s, episode steps: 778, steps per second:  51, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.018474, mae: 2.620531, mean_q: 3.164943, mean_eps: 0.100000
 575573/600000: episode: 774, duration: 15.606s, episode steps: 765, steps per second:  49, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.014911, mae: 2.635615, mean_q: 3.185835, mean_eps: 0.100000
 576450/600000: episode: 775, duration: 19.523s, episode steps: 877, steps per second:  45, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.019066, mae: 2.634134, mean_q: 3.181843, mean_eps: 0.100000
 577383/600000: episode: 776, duration: 19.889s, episode steps: 933, steps per second:  47, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.017339, mae: 2.630515, mean_q: 3.176912, mean_eps: 0.100000
 578340/600000: episode: 777, duration: 20.380s, episode steps: 957, steps per second:  47, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.010 [0.000, 5.000],  loss: 0.014710, mae: 2.626635, mean_q: 3.172913, mean_eps: 0.100000
 578956/600000: episode: 778, duration: 13.711s, episode steps: 616, steps per second:  45, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.136 [0.000, 5.000],  loss: 0.014978, mae: 2.613042, mean_q: 3.158432, mean_eps: 0.100000
 579543/600000: episode: 779, duration: 13.111s, episode steps: 587, steps per second:  45, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.014663, mae: 2.635932, mean_q: 3.184771, mean_eps: 0.100000
 580301/600000: episode: 780, duration: 16.340s, episode steps: 758, steps per second:  46, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.797 [0.000, 5.000],  loss: 0.015664, mae: 2.637058, mean_q: 3.185471, mean_eps: 0.100000
 581514/600000: episode: 781, duration: 27.321s, episode steps: 1213, steps per second:  44, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.016015, mae: 2.606128, mean_q: 3.149108, mean_eps: 0.100000
 581988/600000: episode: 782, duration: 10.711s, episode steps: 474, steps per second:  44, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: 0.016206, mae: 2.576007, mean_q: 3.113038, mean_eps: 0.100000
 582928/600000: episode: 783, duration: 18.998s, episode steps: 940, steps per second:  49, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.017026, mae: 2.620795, mean_q: 3.167343, mean_eps: 0.100000
 583742/600000: episode: 784, duration: 16.285s, episode steps: 814, steps per second:  50, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.018152, mae: 2.639006, mean_q: 3.186989, mean_eps: 0.100000
 584396/600000: episode: 785, duration: 15.185s, episode steps: 654, steps per second:  43, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.047 [0.000, 5.000],  loss: 0.015968, mae: 2.614586, mean_q: 3.158797, mean_eps: 0.100000
 585319/600000: episode: 786, duration: 20.314s, episode steps: 923, steps per second:  45, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.015157, mae: 2.624615, mean_q: 3.172470, mean_eps: 0.100000
 585967/600000: episode: 787, duration: 12.727s, episode steps: 648, steps per second:  51, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.867 [0.000, 5.000],  loss: 0.014228, mae: 2.649516, mean_q: 3.203839, mean_eps: 0.100000
 586878/600000: episode: 788, duration: 17.706s, episode steps: 911, steps per second:  51, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.018518, mae: 2.636896, mean_q: 3.185180, mean_eps: 0.100000
 587420/600000: episode: 789, duration: 11.061s, episode steps: 542, steps per second:  49, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.015150, mae: 2.637483, mean_q: 3.189101, mean_eps: 0.100000
 588052/600000: episode: 790, duration: 13.003s, episode steps: 632, steps per second:  49, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.015460, mae: 2.662921, mean_q: 3.218330, mean_eps: 0.100000
 589061/600000: episode: 791, duration: 22.394s, episode steps: 1009, steps per second:  45, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.016204, mae: 2.632526, mean_q: 3.182948, mean_eps: 0.100000
 590120/600000: episode: 792, duration: 22.801s, episode steps: 1059, steps per second:  46, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.017425, mae: 2.637670, mean_q: 3.187170, mean_eps: 0.100000
 591329/600000: episode: 793, duration: 27.395s, episode steps: 1209, steps per second:  44, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.017005, mae: 2.626013, mean_q: 3.173376, mean_eps: 0.100000
 592009/600000: episode: 794, duration: 14.977s, episode steps: 680, steps per second:  45, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.938 [0.000, 5.000],  loss: 0.019233, mae: 2.651098, mean_q: 3.201759, mean_eps: 0.100000
 592957/600000: episode: 795, duration: 23.839s, episode steps: 948, steps per second:  40, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.016173, mae: 2.627742, mean_q: 3.171280, mean_eps: 0.100000
 593653/600000: episode: 796, duration: 16.890s, episode steps: 696, steps per second:  41, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.352 [0.000, 5.000],  loss: 0.017474, mae: 2.620431, mean_q: 3.164167, mean_eps: 0.100000
 594612/600000: episode: 797, duration: 22.290s, episode steps: 959, steps per second:  43, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.030 [0.000, 5.000],  loss: 0.015872, mae: 2.654708, mean_q: 3.205164, mean_eps: 0.100000
 595366/600000: episode: 798, duration: 18.147s, episode steps: 754, steps per second:  42, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.069 [0.000, 5.000],  loss: 0.016659, mae: 2.639015, mean_q: 3.186213, mean_eps: 0.100000
 596268/600000: episode: 799, duration: 19.766s, episode steps: 902, steps per second:  46, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.015665, mae: 2.655263, mean_q: 3.207172, mean_eps: 0.100000
 597322/600000: episode: 800, duration: 23.318s, episode steps: 1054, steps per second:  45, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.137 [0.000, 5.000],  loss: 0.017405, mae: 2.642827, mean_q: 3.191184, mean_eps: 0.100000
 598184/600000: episode: 801, duration: 19.810s, episode steps: 862, steps per second:  44, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.015329, mae: 2.650457, mean_q: 3.199947, mean_eps: 0.100000
 599331/600000: episode: 802, duration: 23.615s, episode steps: 1147, steps per second:  49, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.038 [0.000, 5.000],  loss: 0.017109, mae: 2.638572, mean_q: 3.186309, mean_eps: 0.100000
 599973/600000: episode: 803, duration: 12.588s, episode steps: 642, steps per second:  51, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.016206, mae: 2.646848, mean_q: 3.193941, mean_eps: 0.100000
done, took 12395.770 seconds

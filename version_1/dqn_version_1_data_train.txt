  25503/600000: episode: 38, duration: 15.486s, episode steps: 716, steps per second:  46, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007130, mae: 0.049164, mean_q: 0.072816, mean_eps: 0.954546
  26148/600000: episode: 39, duration: 17.560s, episode steps: 645, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.006725, mae: 0.047785, mean_q: 0.064070, mean_eps: 0.953517
  26887/600000: episode: 40, duration: 21.202s, episode steps: 739, steps per second:  35, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.008195, mae: 0.051590, mean_q: 0.072036, mean_eps: 0.952271
  28064/600000: episode: 41, duration: 31.870s, episode steps: 1177, steps per second:  37, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006249, mae: 0.046665, mean_q: 0.061475, mean_eps: 0.950547
  28668/600000: episode: 42, duration: 15.995s, episode steps: 604, steps per second:  38, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006051, mae: 0.046729, mean_q: 0.065017, mean_eps: 0.948945
  29281/600000: episode: 43, duration: 15.437s, episode steps: 613, steps per second:  40, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006068, mae: 0.046881, mean_q: 0.062340, mean_eps: 0.947847
  29825/600000: episode: 44, duration: 14.149s, episode steps: 544, steps per second:  38, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.008692, mae: 0.052178, mean_q: 0.070124, mean_eps: 0.946803
  30484/600000: episode: 45, duration: 14.964s, episode steps: 659, steps per second:  44, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.005958, mae: 0.062105, mean_q: 0.084126, mean_eps: 0.945723
  31115/600000: episode: 46, duration: 12.904s, episode steps: 631, steps per second:  49, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006589, mae: 0.068893, mean_q: 0.093050, mean_eps: 0.944564
  31975/600000: episode: 47, duration: 15.405s, episode steps: 860, steps per second:  56, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006740, mae: 0.070075, mean_q: 0.091275, mean_eps: 0.943221
  32302/600000: episode: 48, duration: 5.142s, episode steps: 327, steps per second:  64, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006875, mae: 0.070339, mean_q: 0.089966, mean_eps: 0.942152
  32909/600000: episode: 49, duration: 10.086s, episode steps: 607, steps per second:  60, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007857, mae: 0.072760, mean_q: 0.100708, mean_eps: 0.941309
  33295/600000: episode: 50, duration: 6.635s, episode steps: 386, steps per second:  58, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007576, mae: 0.072296, mean_q: 0.096608, mean_eps: 0.940416
  34138/600000: episode: 51, duration: 13.225s, episode steps: 843, steps per second:  64, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.007075, mae: 0.071547, mean_q: 0.095002, mean_eps: 0.939311
  34670/600000: episode: 52, duration: 8.304s, episode steps: 532, steps per second:  64, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.005670, mae: 0.067304, mean_q: 0.089758, mean_eps: 0.938073
  35269/600000: episode: 53, duration: 9.266s, episode steps: 599, steps per second:  65, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006217, mae: 0.069363, mean_q: 0.093792, mean_eps: 0.937054
  35913/600000: episode: 54, duration: 10.255s, episode steps: 644, steps per second:  63, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006977, mae: 0.071152, mean_q: 0.094905, mean_eps: 0.935934
  36709/600000: episode: 55, duration: 12.345s, episode steps: 796, steps per second:  64, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006811, mae: 0.069756, mean_q: 0.092253, mean_eps: 0.934638
  37314/600000: episode: 56, duration: 9.653s, episode steps: 605, steps per second:  63, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007020, mae: 0.071198, mean_q: 0.095045, mean_eps: 0.933378
  38120/600000: episode: 57, duration: 12.407s, episode steps: 806, steps per second:  65, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.004981, mae: 0.066634, mean_q: 0.089920, mean_eps: 0.932111
  39061/600000: episode: 58, duration: 14.008s, episode steps: 941, steps per second:  67, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.005963, mae: 0.067732, mean_q: 0.091494, mean_eps: 0.930538
  40046/600000: episode: 59, duration: 15.883s, episode steps: 985, steps per second:  62, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.007046, mae: 0.070731, mean_q: 0.094898, mean_eps: 0.928803
  40743/600000: episode: 60, duration: 10.953s, episode steps: 697, steps per second:  64, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006686, mae: 0.087129, mean_q: 0.117058, mean_eps: 0.927291
  41420/600000: episode: 61, duration: 11.411s, episode steps: 677, steps per second:  59, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.005226, mae: 0.083421, mean_q: 0.111116, mean_eps: 0.926056
  41808/600000: episode: 62, duration: 6.450s, episode steps: 388, steps per second:  60, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.007039, mae: 0.087317, mean_q: 0.122563, mean_eps: 0.925098
  43010/600000: episode: 63, duration: 18.783s, episode steps: 1202, steps per second:  64, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.006734, mae: 0.087925, mean_q: 0.115998, mean_eps: 0.923666
  43639/600000: episode: 64, duration: 10.398s, episode steps: 629, steps per second:  60, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.005932, mae: 0.086345, mean_q: 0.115025, mean_eps: 0.922017
  44227/600000: episode: 65, duration: 9.083s, episode steps: 588, steps per second:  65, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.004519, mae: 0.082013, mean_q: 0.107974, mean_eps: 0.920922
  45125/600000: episode: 66, duration: 14.453s, episode steps: 898, steps per second:  62, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006192, mae: 0.086865, mean_q: 0.116493, mean_eps: 0.919583
  46106/600000: episode: 67, duration: 16.216s, episode steps: 981, steps per second:  60, episode reward: 25.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.006876, mae: 0.087027, mean_q: 0.117190, mean_eps: 0.917891
  46740/600000: episode: 68, duration: 10.439s, episode steps: 634, steps per second:  61, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007265, mae: 0.090120, mean_q: 0.120002, mean_eps: 0.916440
  47636/600000: episode: 69, duration: 23.577s, episode steps: 896, steps per second:  38, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.006328, mae: 0.085852, mean_q: 0.115443, mean_eps: 0.915065
  48269/600000: episode: 70, duration: 30.593s, episode steps: 633, steps per second:  21, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005348, mae: 0.084797, mean_q: 0.112666, mean_eps: 0.913686
  49275/600000: episode: 71, duration: 47.177s, episode steps: 1006, steps per second:  21, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.007606, mae: 0.089969, mean_q: 0.120240, mean_eps: 0.912210
  50078/600000: episode: 72, duration: 37.111s, episode steps: 803, steps per second:  22, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.006456, mae: 0.088281, mean_q: 0.119200, mean_eps: 0.910583
  50874/600000: episode: 73, duration: 13.619s, episode steps: 796, steps per second:  58, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.005969, mae: 0.104484, mean_q: 0.139414, mean_eps: 0.909143
  51545/600000: episode: 74, duration: 11.132s, episode steps: 671, steps per second:  60, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.005196, mae: 0.100991, mean_q: 0.132551, mean_eps: 0.907822
  52192/600000: episode: 75, duration: 10.366s, episode steps: 647, steps per second:  62, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.007645, mae: 0.108744, mean_q: 0.142444, mean_eps: 0.906638
  52710/600000: episode: 76, duration: 8.176s, episode steps: 518, steps per second:  63, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008314, mae: 0.110231, mean_q: 0.145516, mean_eps: 0.905590
  53148/600000: episode: 77, duration: 7.174s, episode steps: 438, steps per second:  61, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.006844, mae: 0.106431, mean_q: 0.141502, mean_eps: 0.904730
  53987/600000: episode: 78, duration: 13.449s, episode steps: 839, steps per second:  62, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006854, mae: 0.107424, mean_q: 0.141729, mean_eps: 0.903581
  55198/600000: episode: 79, duration: 18.983s, episode steps: 1211, steps per second:  64, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.006248, mae: 0.105462, mean_q: 0.139973, mean_eps: 0.901734
  55901/600000: episode: 80, duration: 10.699s, episode steps: 703, steps per second:  66, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005960, mae: 0.105434, mean_q: 0.139010, mean_eps: 0.900010
  56587/600000: episode: 81, duration: 23.654s, episode steps: 686, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006313, mae: 0.104286, mean_q: 0.138014, mean_eps: 0.898761
  57129/600000: episode: 82, duration: 12.247s, episode steps: 542, steps per second:  44, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006947, mae: 0.108417, mean_q: 0.144941, mean_eps: 0.897656
  58042/600000: episode: 83, duration: 15.473s, episode steps: 913, steps per second:  59, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007099, mae: 0.106881, mean_q: 0.144719, mean_eps: 0.896345
  59078/600000: episode: 84, duration: 16.269s, episode steps: 1036, steps per second:  64, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.005720, mae: 0.105102, mean_q: 0.141712, mean_eps: 0.894592
  60008/600000: episode: 85, duration: 14.693s, episode steps: 930, steps per second:  63, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006557, mae: 0.106496, mean_q: 0.140926, mean_eps: 0.892824
  60596/600000: episode: 86, duration: 8.900s, episode steps: 588, steps per second:  66, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006265, mae: 0.127603, mean_q: 0.165967, mean_eps: 0.891460
  61288/600000: episode: 87, duration: 10.777s, episode steps: 692, steps per second:  64, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006170, mae: 0.127910, mean_q: 0.167370, mean_eps: 0.890308
  61774/600000: episode: 88, duration: 7.907s, episode steps: 486, steps per second:  61, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006492, mae: 0.129598, mean_q: 0.169216, mean_eps: 0.889246
  62349/600000: episode: 89, duration: 9.586s, episode steps: 575, steps per second:  60, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.006443, mae: 0.130562, mean_q: 0.170531, mean_eps: 0.888288
  63013/600000: episode: 90, duration: 11.489s, episode steps: 664, steps per second:  58, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006748, mae: 0.128130, mean_q: 0.168051, mean_eps: 0.887172
  64140/600000: episode: 91, duration: 20.706s, episode steps: 1127, steps per second:  54, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.007198, mae: 0.131616, mean_q: 0.170275, mean_eps: 0.885563
  64745/600000: episode: 92, duration: 10.447s, episode steps: 605, steps per second:  58, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.006829, mae: 0.128867, mean_q: 0.168959, mean_eps: 0.884004
  65457/600000: episode: 93, duration: 12.256s, episode steps: 712, steps per second:  58, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.005636, mae: 0.127583, mean_q: 0.168865, mean_eps: 0.882816
  66684/600000: episode: 94, duration: 20.987s, episode steps: 1227, steps per second:  58, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006427, mae: 0.128964, mean_q: 0.170769, mean_eps: 0.881074
  68059/600000: episode: 95, duration: 22.913s, episode steps: 1375, steps per second:  60, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006019, mae: 0.127857, mean_q: 0.166580, mean_eps: 0.878734
  68768/600000: episode: 96, duration: 11.080s, episode steps: 709, steps per second:  64, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006444, mae: 0.128598, mean_q: 0.167323, mean_eps: 0.876858
  69391/600000: episode: 97, duration: 9.795s, episode steps: 623, steps per second:  64, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006655, mae: 0.129171, mean_q: 0.169601, mean_eps: 0.875660
  70154/600000: episode: 98, duration: 12.966s, episode steps: 763, steps per second:  59, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006238, mae: 0.138472, mean_q: 0.181795, mean_eps: 0.874410
  70756/600000: episode: 99, duration: 10.011s, episode steps: 602, steps per second:  60, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006664, mae: 0.175290, mean_q: 0.227036, mean_eps: 0.873183
  72083/600000: episode: 100, duration: 22.476s, episode steps: 1327, steps per second:  59, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006646, mae: 0.175105, mean_q: 0.225156, mean_eps: 0.871448
  72461/600000: episode: 101, duration: 6.218s, episode steps: 378, steps per second:  61, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.006520, mae: 0.175103, mean_q: 0.222769, mean_eps: 0.869910
  73237/600000: episode: 102, duration: 13.173s, episode steps: 776, steps per second:  59, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.006580, mae: 0.175347, mean_q: 0.224605, mean_eps: 0.868870
  74013/600000: episode: 103, duration: 12.840s, episode steps: 776, steps per second:  60, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007273, mae: 0.177506, mean_q: 0.227891, mean_eps: 0.867473
  75111/600000: episode: 104, duration: 18.025s, episode steps: 1098, steps per second:  61, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.005981, mae: 0.173364, mean_q: 0.222963, mean_eps: 0.865788
  75733/600000: episode: 105, duration: 9.682s, episode steps: 622, steps per second:  64, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.005817, mae: 0.176132, mean_q: 0.227314, mean_eps: 0.864240
  76255/600000: episode: 106, duration: 7.837s, episode steps: 522, steps per second:  67, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.006297, mae: 0.173419, mean_q: 0.221484, mean_eps: 0.863211
  76997/600000: episode: 107, duration: 11.478s, episode steps: 742, steps per second:  65, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006947, mae: 0.178111, mean_q: 0.228721, mean_eps: 0.862073
  77630/600000: episode: 108, duration: 10.256s, episode steps: 633, steps per second:  62, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007355, mae: 0.177863, mean_q: 0.230706, mean_eps: 0.860835
  77985/600000: episode: 109, duration: 6.076s, episode steps: 355, steps per second:  58, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006742, mae: 0.174892, mean_q: 0.226292, mean_eps: 0.859946
  78655/600000: episode: 110, duration: 11.521s, episode steps: 670, steps per second:  58, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006866, mae: 0.177662, mean_q: 0.229018, mean_eps: 0.859024
  79147/600000: episode: 111, duration: 7.800s, episode steps: 492, steps per second:  63, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.007089, mae: 0.176668, mean_q: 0.227373, mean_eps: 0.857980
  79736/600000: episode: 112, duration: 9.505s, episode steps: 589, steps per second:  62, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006901, mae: 0.176084, mean_q: 0.227673, mean_eps: 0.857008
  80370/600000: episode: 113, duration: 23.956s, episode steps: 634, steps per second:  26, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006902, mae: 0.194896, mean_q: 0.253709, mean_eps: 0.855906
  80884/600000: episode: 114, duration: 23.263s, episode steps: 514, steps per second:  22, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.007118, mae: 0.209003, mean_q: 0.269547, mean_eps: 0.854873
  81430/600000: episode: 115, duration: 19.613s, episode steps: 546, steps per second:  28, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006603, mae: 0.205124, mean_q: 0.263221, mean_eps: 0.853919
  82067/600000: episode: 116, duration: 29.857s, episode steps: 637, steps per second:  21, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005926, mae: 0.205728, mean_q: 0.264207, mean_eps: 0.852854
  82541/600000: episode: 117, duration: 23.609s, episode steps: 474, steps per second:  20, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.006860, mae: 0.208485, mean_q: 0.264108, mean_eps: 0.851853
  83423/600000: episode: 118, duration: 42.442s, episode steps: 882, steps per second:  21, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.007626, mae: 0.209390, mean_q: 0.266003, mean_eps: 0.850632
  83991/600000: episode: 119, duration: 28.504s, episode steps: 568, steps per second:  20, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.007038, mae: 0.207840, mean_q: 0.265521, mean_eps: 0.849329
  84503/600000: episode: 120, duration: 24.109s, episode steps: 512, steps per second:  21, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.007669, mae: 0.211022, mean_q: 0.269984, mean_eps: 0.848357
  85018/600000: episode: 121, duration: 26.302s, episode steps: 515, steps per second:  20, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.006841, mae: 0.205905, mean_q: 0.265082, mean_eps: 0.847432
  85646/600000: episode: 122, duration: 32.294s, episode steps: 628, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007255, mae: 0.209045, mean_q: 0.267733, mean_eps: 0.846402
  86358/600000: episode: 123, duration: 36.562s, episode steps: 712, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005866, mae: 0.202994, mean_q: 0.261149, mean_eps: 0.845196
  87006/600000: episode: 124, duration: 32.821s, episode steps: 648, steps per second:  20, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.005361, mae: 0.200515, mean_q: 0.256824, mean_eps: 0.843972
  87393/600000: episode: 125, duration: 19.649s, episode steps: 387, steps per second:  20, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.010102, mae: 0.219376, mean_q: 0.277556, mean_eps: 0.843040
  88369/600000: episode: 126, duration: 48.599s, episode steps: 976, steps per second:  20, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006510, mae: 0.206518, mean_q: 0.264397, mean_eps: 0.841812
  89058/600000: episode: 127, duration: 34.529s, episode steps: 689, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007315, mae: 0.208064, mean_q: 0.266129, mean_eps: 0.840315
  89687/600000: episode: 128, duration: 32.776s, episode steps: 629, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.007167, mae: 0.210479, mean_q: 0.268412, mean_eps: 0.839130
  90915/600000: episode: 129, duration: 63.774s, episode steps: 1228, steps per second:  19, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.007319, mae: 0.230468, mean_q: 0.293275, mean_eps: 0.837460
  91471/600000: episode: 130, duration: 28.462s, episode steps: 556, steps per second:  20, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006409, mae: 0.237038, mean_q: 0.300506, mean_eps: 0.835854
  92615/600000: episode: 131, duration: 56.336s, episode steps: 1144, steps per second:  20, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.006847, mae: 0.238364, mean_q: 0.302089, mean_eps: 0.834324
  93149/600000: episode: 132, duration: 26.234s, episode steps: 534, steps per second:  20, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.006642, mae: 0.237671, mean_q: 0.299935, mean_eps: 0.832812
  94245/600000: episode: 133, duration: 46.116s, episode steps: 1096, steps per second:  24, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006716, mae: 0.237811, mean_q: 0.299406, mean_eps: 0.831344
  94894/600000: episode: 134, duration: 11.872s, episode steps: 649, steps per second:  55, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007331, mae: 0.240042, mean_q: 0.304024, mean_eps: 0.829774
  96442/600000: episode: 135, duration: 24.959s, episode steps: 1548, steps per second:  62, episode reward: 17.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.005938, mae: 0.237819, mean_q: 0.302322, mean_eps: 0.827798
  97262/600000: episode: 136, duration: 15.154s, episode steps: 820, steps per second:  54, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006744, mae: 0.238116, mean_q: 0.300945, mean_eps: 0.825666
  98453/600000: episode: 137, duration: 21.811s, episode steps: 1191, steps per second:  55, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006999, mae: 0.240680, mean_q: 0.304661, mean_eps: 0.823856
  99164/600000: episode: 138, duration: 13.188s, episode steps: 711, steps per second:  54, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.007259, mae: 0.240622, mean_q: 0.306938, mean_eps: 0.822146
  99827/600000: episode: 139, duration: 12.510s, episode steps: 663, steps per second:  53, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.008065, mae: 0.241541, mean_q: 0.307820, mean_eps: 0.820911
 100863/600000: episode: 140, duration: 19.076s, episode steps: 1036, steps per second:  54, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007163, mae: 0.257336, mean_q: 0.327460, mean_eps: 0.819381
 101388/600000: episode: 141, duration: 9.661s, episode steps: 525, steps per second:  54, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007179, mae: 0.267620, mean_q: 0.340202, mean_eps: 0.817977
 101947/600000: episode: 142, duration: 9.790s, episode steps: 559, steps per second:  57, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.006942, mae: 0.255079, mean_q: 0.324959, mean_eps: 0.817001
 103117/600000: episode: 143, duration: 21.819s, episode steps: 1170, steps per second:  54, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007240, mae: 0.264257, mean_q: 0.335120, mean_eps: 0.815442
 103911/600000: episode: 144, duration: 14.068s, episode steps: 794, steps per second:  56, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.006863, mae: 0.263581, mean_q: 0.335769, mean_eps: 0.813675
 104259/600000: episode: 145, duration: 6.127s, episode steps: 348, steps per second:  57, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.210 [0.000, 5.000],  loss: 0.006065, mae: 0.258014, mean_q: 0.327535, mean_eps: 0.812649
 105097/600000: episode: 146, duration: 13.968s, episode steps: 838, steps per second:  60, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.007434, mae: 0.265664, mean_q: 0.336231, mean_eps: 0.811580
 105482/600000: episode: 147, duration: 6.281s, episode steps: 385, steps per second:  61, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007458, mae: 0.271099, mean_q: 0.344434, mean_eps: 0.810478
 106296/600000: episode: 148, duration: 13.351s, episode steps: 814, steps per second:  61, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.006373, mae: 0.258622, mean_q: 0.328260, mean_eps: 0.809402
 106964/600000: episode: 149, duration: 11.488s, episode steps: 668, steps per second:  58, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007654, mae: 0.264429, mean_q: 0.332281, mean_eps: 0.808070
 107636/600000: episode: 150, duration: 11.092s, episode steps: 672, steps per second:  61, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.006580, mae: 0.263761, mean_q: 0.333140, mean_eps: 0.806864
 108325/600000: episode: 151, duration: 11.235s, episode steps: 689, steps per second:  61, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.007085, mae: 0.268238, mean_q: 0.341593, mean_eps: 0.805636
 109240/600000: episode: 152, duration: 17.598s, episode steps: 915, steps per second:  52, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006395, mae: 0.261095, mean_q: 0.329132, mean_eps: 0.804192
 110190/600000: episode: 153, duration: 16.609s, episode steps: 950, steps per second:  57, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.006545, mae: 0.276670, mean_q: 0.350005, mean_eps: 0.802515
 110807/600000: episode: 154, duration: 10.620s, episode steps: 617, steps per second:  58, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.007904, mae: 0.316167, mean_q: 0.396958, mean_eps: 0.801104
 111600/600000: episode: 155, duration: 14.543s, episode steps: 793, steps per second:  55, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007305, mae: 0.312786, mean_q: 0.392761, mean_eps: 0.799836
 112480/600000: episode: 156, duration: 16.211s, episode steps: 880, steps per second:  54, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008560, mae: 0.317594, mean_q: 0.398569, mean_eps: 0.798332
 113066/600000: episode: 157, duration: 9.963s, episode steps: 586, steps per second:  59, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.008764, mae: 0.318028, mean_q: 0.396614, mean_eps: 0.797010
 113992/600000: episode: 158, duration: 18.704s, episode steps: 926, steps per second:  50, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.008965, mae: 0.321407, mean_q: 0.401274, mean_eps: 0.795650
 114512/600000: episode: 159, duration: 9.658s, episode steps: 520, steps per second:  54, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.007607, mae: 0.310880, mean_q: 0.390430, mean_eps: 0.794350
 115316/600000: episode: 160, duration: 15.054s, episode steps: 804, steps per second:  53, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007733, mae: 0.314790, mean_q: 0.393488, mean_eps: 0.793158
 115954/600000: episode: 161, duration: 11.271s, episode steps: 638, steps per second:  57, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.006540, mae: 0.314967, mean_q: 0.394113, mean_eps: 0.791859
 116437/600000: episode: 162, duration: 9.489s, episode steps: 483, steps per second:  51, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.007134, mae: 0.308029, mean_q: 0.385702, mean_eps: 0.790847
 117451/600000: episode: 163, duration: 23.876s, episode steps: 1014, steps per second:  42, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.007421, mae: 0.316435, mean_q: 0.395992, mean_eps: 0.789501
 118354/600000: episode: 164, duration: 18.449s, episode steps: 903, steps per second:  49, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007118, mae: 0.321589, mean_q: 0.400812, mean_eps: 0.787776
 119219/600000: episode: 165, duration: 17.213s, episode steps: 865, steps per second:  50, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.008685, mae: 0.317725, mean_q: 0.396893, mean_eps: 0.786185
 119865/600000: episode: 166, duration: 12.650s, episode steps: 646, steps per second:  51, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006807, mae: 0.309959, mean_q: 0.388482, mean_eps: 0.784824
 120618/600000: episode: 167, duration: 14.313s, episode steps: 753, steps per second:  53, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008427, mae: 0.342309, mean_q: 0.427886, mean_eps: 0.783564
 121554/600000: episode: 168, duration: 21.097s, episode steps: 936, steps per second:  44, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007522, mae: 0.347499, mean_q: 0.433698, mean_eps: 0.782045
 122404/600000: episode: 169, duration: 17.223s, episode steps: 850, steps per second:  49, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.008312, mae: 0.347030, mean_q: 0.434586, mean_eps: 0.780440
 123929/600000: episode: 170, duration: 28.080s, episode steps: 1525, steps per second:  54, episode reward: 17.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007053, mae: 0.341171, mean_q: 0.426657, mean_eps: 0.778301
 124489/600000: episode: 171, duration: 9.149s, episode steps: 560, steps per second:  61, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.006839, mae: 0.342679, mean_q: 0.427795, mean_eps: 0.776422
 125274/600000: episode: 172, duration: 12.793s, episode steps: 785, steps per second:  61, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007749, mae: 0.345370, mean_q: 0.432693, mean_eps: 0.775212
 125790/600000: episode: 173, duration: 9.743s, episode steps: 516, steps per second:  53, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.006768, mae: 0.334897, mean_q: 0.418905, mean_eps: 0.774042
 126748/600000: episode: 174, duration: 17.817s, episode steps: 958, steps per second:  54, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.007579, mae: 0.342655, mean_q: 0.427380, mean_eps: 0.772718
 127400/600000: episode: 175, duration: 12.084s, episode steps: 652, steps per second:  54, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.007413, mae: 0.347001, mean_q: 0.432110, mean_eps: 0.771270
 128829/600000: episode: 176, duration: 23.785s, episode steps: 1429, steps per second:  60, episode reward: 15.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006926, mae: 0.342982, mean_q: 0.426720, mean_eps: 0.769395
 129800/600000: episode: 177, duration: 16.373s, episode steps: 971, steps per second:  59, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007323, mae: 0.344327, mean_q: 0.428376, mean_eps: 0.767235
 130434/600000: episode: 178, duration: 10.645s, episode steps: 634, steps per second:  60, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.007334, mae: 0.374632, mean_q: 0.465440, mean_eps: 0.765791
 131003/600000: episode: 179, duration: 9.258s, episode steps: 569, steps per second:  61, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.008704, mae: 0.397636, mean_q: 0.494056, mean_eps: 0.764708
 131664/600000: episode: 180, duration: 10.951s, episode steps: 661, steps per second:  60, episode reward: 18.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.008413, mae: 0.398667, mean_q: 0.498056, mean_eps: 0.763602
 132704/600000: episode: 181, duration: 17.202s, episode steps: 1040, steps per second:  60, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.007683, mae: 0.398782, mean_q: 0.494771, mean_eps: 0.762072
 133432/600000: episode: 182, duration: 13.546s, episode steps: 728, steps per second:  54, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.008134, mae: 0.396301, mean_q: 0.490974, mean_eps: 0.760481
 134416/600000: episode: 183, duration: 17.450s, episode steps: 984, steps per second:  56, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.008129, mae: 0.398921, mean_q: 0.495166, mean_eps: 0.758940
 134983/600000: episode: 184, duration: 9.319s, episode steps: 567, steps per second:  61, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.007182, mae: 0.393290, mean_q: 0.489044, mean_eps: 0.757544
 135630/600000: episode: 185, duration: 10.656s, episode steps: 647, steps per second:  61, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.008200, mae: 0.397151, mean_q: 0.492616, mean_eps: 0.756449
 136359/600000: episode: 186, duration: 12.180s, episode steps: 729, steps per second:  60, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.008185, mae: 0.396654, mean_q: 0.491190, mean_eps: 0.755211
 137003/600000: episode: 187, duration: 11.045s, episode steps: 644, steps per second:  58, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006494, mae: 0.394082, mean_q: 0.488058, mean_eps: 0.753976
 137651/600000: episode: 188, duration: 11.183s, episode steps: 648, steps per second:  58, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007755, mae: 0.390797, mean_q: 0.483608, mean_eps: 0.752813
 138385/600000: episode: 189, duration: 12.985s, episode steps: 734, steps per second:  57, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.008129, mae: 0.399003, mean_q: 0.492147, mean_eps: 0.751568
 139230/600000: episode: 190, duration: 14.811s, episode steps: 845, steps per second:  57, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.008270, mae: 0.395821, mean_q: 0.488639, mean_eps: 0.750146
 139745/600000: episode: 191, duration: 9.765s, episode steps: 515, steps per second:  53, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.008524, mae: 0.395822, mean_q: 0.489827, mean_eps: 0.748922
 140093/600000: episode: 192, duration: 6.470s, episode steps: 348, steps per second:  54, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007353, mae: 0.399953, mean_q: 0.496341, mean_eps: 0.748144
 140465/600000: episode: 193, duration: 7.162s, episode steps: 372, steps per second:  52, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.007496, mae: 0.417572, mean_q: 0.519016, mean_eps: 0.747496
 140903/600000: episode: 194, duration: 8.111s, episode steps: 438, steps per second:  54, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.008266, mae: 0.407879, mean_q: 0.506072, mean_eps: 0.746769
 141440/600000: episode: 195, duration: 9.180s, episode steps: 537, steps per second:  58, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007304, mae: 0.412956, mean_q: 0.512293, mean_eps: 0.745894
 142218/600000: episode: 196, duration: 13.677s, episode steps: 778, steps per second:  57, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.009396, mae: 0.418046, mean_q: 0.518776, mean_eps: 0.744710
 143078/600000: episode: 197, duration: 15.075s, episode steps: 860, steps per second:  57, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007171, mae: 0.408417, mean_q: 0.506480, mean_eps: 0.743234
 143600/600000: episode: 198, duration: 9.381s, episode steps: 522, steps per second:  56, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.008407, mae: 0.416587, mean_q: 0.517216, mean_eps: 0.741992
 144480/600000: episode: 199, duration: 15.411s, episode steps: 880, steps per second:  57, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.007772, mae: 0.410681, mean_q: 0.510210, mean_eps: 0.740732
 144854/600000: episode: 200, duration: 6.572s, episode steps: 374, steps per second:  57, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007708, mae: 0.410977, mean_q: 0.510954, mean_eps: 0.739601
 145410/600000: episode: 201, duration: 9.734s, episode steps: 556, steps per second:  57, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.007904, mae: 0.408538, mean_q: 0.507704, mean_eps: 0.738762
 146049/600000: episode: 202, duration: 10.821s, episode steps: 639, steps per second:  59, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.008544, mae: 0.419974, mean_q: 0.520531, mean_eps: 0.737686
 146521/600000: episode: 203, duration: 8.217s, episode steps: 472, steps per second:  57, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.007258, mae: 0.419750, mean_q: 0.521302, mean_eps: 0.736685
 147318/600000: episode: 204, duration: 13.584s, episode steps: 797, steps per second:  59, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.007892, mae: 0.410988, mean_q: 0.509537, mean_eps: 0.735544
 147838/600000: episode: 205, duration: 9.385s, episode steps: 520, steps per second:  55, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008217, mae: 0.419747, mean_q: 0.520979, mean_eps: 0.734360
 148307/600000: episode: 206, duration: 8.065s, episode steps: 469, steps per second:  58, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.009369, mae: 0.422343, mean_q: 0.522965, mean_eps: 0.733470
 148921/600000: episode: 207, duration: 10.793s, episode steps: 614, steps per second:  57, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007426, mae: 0.414200, mean_q: 0.513636, mean_eps: 0.732495
 149457/600000: episode: 208, duration: 9.087s, episode steps: 536, steps per second:  59, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.007291, mae: 0.411658, mean_q: 0.509235, mean_eps: 0.731458
 150421/600000: episode: 209, duration: 16.471s, episode steps: 964, steps per second:  59, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006760, mae: 0.414925, mean_q: 0.514658, mean_eps: 0.730108
 151003/600000: episode: 210, duration: 10.223s, episode steps: 582, steps per second:  57, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.008123, mae: 0.433403, mean_q: 0.536963, mean_eps: 0.728718
 151534/600000: episode: 211, duration: 9.001s, episode steps: 531, steps per second:  59, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.009035, mae: 0.435352, mean_q: 0.537819, mean_eps: 0.727718
 151956/600000: episode: 212, duration: 6.926s, episode steps: 422, steps per second:  61, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006810, mae: 0.429892, mean_q: 0.531768, mean_eps: 0.726861
 152610/600000: episode: 213, duration: 10.887s, episode steps: 654, steps per second:  60, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.008060, mae: 0.432685, mean_q: 0.536502, mean_eps: 0.725892
 153091/600000: episode: 214, duration: 7.888s, episode steps: 481, steps per second:  61, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.008425, mae: 0.437594, mean_q: 0.542435, mean_eps: 0.724870
 153719/600000: episode: 215, duration: 10.757s, episode steps: 628, steps per second:  58, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.008889, mae: 0.434875, mean_q: 0.539391, mean_eps: 0.723873
 154309/600000: episode: 216, duration: 11.525s, episode steps: 590, steps per second:  51, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.007208, mae: 0.432891, mean_q: 0.536386, mean_eps: 0.722775
 155090/600000: episode: 217, duration: 13.261s, episode steps: 781, steps per second:  59, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.006502, mae: 0.425671, mean_q: 0.526241, mean_eps: 0.721540
 155725/600000: episode: 218, duration: 10.787s, episode steps: 635, steps per second:  59, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007601, mae: 0.444726, mean_q: 0.549657, mean_eps: 0.720266
 156848/600000: episode: 219, duration: 19.003s, episode steps: 1123, steps per second:  59, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.008657, mae: 0.434817, mean_q: 0.537424, mean_eps: 0.718685
 157379/600000: episode: 220, duration: 9.339s, episode steps: 531, steps per second:  57, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.008360, mae: 0.430304, mean_q: 0.534611, mean_eps: 0.717198
 157773/600000: episode: 221, duration: 6.901s, episode steps: 394, steps per second:  57, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.006487, mae: 0.427570, mean_q: 0.532713, mean_eps: 0.716363
 158350/600000: episode: 222, duration: 10.053s, episode steps: 577, steps per second:  57, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.007149, mae: 0.433235, mean_q: 0.535956, mean_eps: 0.715488
 158982/600000: episode: 223, duration: 11.953s, episode steps: 632, steps per second:  53, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.008741, mae: 0.438533, mean_q: 0.541542, mean_eps: 0.714401
 159624/600000: episode: 224, duration: 11.845s, episode steps: 642, steps per second:  54, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.006366, mae: 0.418570, mean_q: 0.518652, mean_eps: 0.713256
 160036/600000: episode: 225, duration: 8.388s, episode steps: 412, steps per second:  49, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.008990, mae: 0.442014, mean_q: 0.547399, mean_eps: 0.712310
 160619/600000: episode: 226, duration: 10.623s, episode steps: 583, steps per second:  55, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.007149, mae: 0.446506, mean_q: 0.553359, mean_eps: 0.711413
 161254/600000: episode: 227, duration: 12.766s, episode steps: 635, steps per second:  50, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.009269, mae: 0.452149, mean_q: 0.558497, mean_eps: 0.710315
 162039/600000: episode: 228, duration: 14.083s, episode steps: 785, steps per second:  56, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.008566, mae: 0.449086, mean_q: 0.554488, mean_eps: 0.709037
 162711/600000: episode: 229, duration: 12.350s, episode steps: 672, steps per second:  54, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.008011, mae: 0.448206, mean_q: 0.554771, mean_eps: 0.707727
 163351/600000: episode: 230, duration: 11.234s, episode steps: 640, steps per second:  57, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.008095, mae: 0.453628, mean_q: 0.560634, mean_eps: 0.706546
 164526/600000: episode: 231, duration: 21.088s, episode steps: 1175, steps per second:  56, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.009084, mae: 0.457553, mean_q: 0.567910, mean_eps: 0.704912
 164965/600000: episode: 232, duration: 7.619s, episode steps: 439, steps per second:  58, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007937, mae: 0.454209, mean_q: 0.563753, mean_eps: 0.703457
 165557/600000: episode: 233, duration: 9.894s, episode steps: 592, steps per second:  60, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.008445, mae: 0.452130, mean_q: 0.560494, mean_eps: 0.702528
 166194/600000: episode: 234, duration: 10.552s, episode steps: 637, steps per second:  60, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.008634, mae: 0.456789, mean_q: 0.565289, mean_eps: 0.701423
 167295/600000: episode: 235, duration: 19.204s, episode steps: 1101, steps per second:  57, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.008439, mae: 0.456852, mean_q: 0.565516, mean_eps: 0.699861
 168329/600000: episode: 236, duration: 19.031s, episode steps: 1034, steps per second:  54, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.007625, mae: 0.447020, mean_q: 0.554475, mean_eps: 0.697938
 168950/600000: episode: 237, duration: 11.242s, episode steps: 621, steps per second:  55, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.010335, mae: 0.451870, mean_q: 0.561214, mean_eps: 0.696448
 170137/600000: episode: 238, duration: 20.174s, episode steps: 1187, steps per second:  59, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.008226, mae: 0.454668, mean_q: 0.564421, mean_eps: 0.694821
 170717/600000: episode: 239, duration: 9.908s, episode steps: 580, steps per second:  59, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.008552, mae: 0.473386, mean_q: 0.588328, mean_eps: 0.693230
 171368/600000: episode: 240, duration: 11.486s, episode steps: 651, steps per second:  57, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008959, mae: 0.482653, mean_q: 0.597595, mean_eps: 0.692124
 172118/600000: episode: 241, duration: 12.612s, episode steps: 750, steps per second:  59, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008336, mae: 0.472833, mean_q: 0.585874, mean_eps: 0.690864
 172867/600000: episode: 242, duration: 12.775s, episode steps: 749, steps per second:  59, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.009327, mae: 0.477803, mean_q: 0.590991, mean_eps: 0.689514
 173374/600000: episode: 243, duration: 8.990s, episode steps: 507, steps per second:  56, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007774, mae: 0.471176, mean_q: 0.582745, mean_eps: 0.688384
 173760/600000: episode: 244, duration: 6.616s, episode steps: 386, steps per second:  58, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.008649, mae: 0.471654, mean_q: 0.581707, mean_eps: 0.687581
 174632/600000: episode: 245, duration: 15.315s, episode steps: 872, steps per second:  57, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.008081, mae: 0.473436, mean_q: 0.585574, mean_eps: 0.686451
 175164/600000: episode: 246, duration: 9.493s, episode steps: 532, steps per second:  56, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.009035, mae: 0.476572, mean_q: 0.590553, mean_eps: 0.685187
 175671/600000: episode: 247, duration: 8.468s, episode steps: 507, steps per second:  60, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.007569, mae: 0.465490, mean_q: 0.577724, mean_eps: 0.684251
 176399/600000: episode: 248, duration: 12.324s, episode steps: 728, steps per second:  59, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.008144, mae: 0.466665, mean_q: 0.577725, mean_eps: 0.683139
 177215/600000: episode: 249, duration: 13.696s, episode steps: 816, steps per second:  60, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.010521, mae: 0.480723, mean_q: 0.593691, mean_eps: 0.681749
 178448/600000: episode: 250, duration: 21.464s, episode steps: 1233, steps per second:  57, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.008930, mae: 0.478565, mean_q: 0.589758, mean_eps: 0.679906
 179072/600000: episode: 251, duration: 10.726s, episode steps: 624, steps per second:  58, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009205, mae: 0.487115, mean_q: 0.600806, mean_eps: 0.678236
 180080/600000: episode: 252, duration: 18.373s, episode steps: 1008, steps per second:  55, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.008852, mae: 0.485640, mean_q: 0.600487, mean_eps: 0.676767
 180440/600000: episode: 253, duration: 6.193s, episode steps: 360, steps per second:  58, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.009198, mae: 0.524341, mean_q: 0.648874, mean_eps: 0.675536
 181091/600000: episode: 254, duration: 12.711s, episode steps: 651, steps per second:  51, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.008859, mae: 0.517989, mean_q: 0.641886, mean_eps: 0.674625
 181473/600000: episode: 255, duration: 6.996s, episode steps: 382, steps per second:  55, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.009239, mae: 0.516574, mean_q: 0.638865, mean_eps: 0.673692
 182131/600000: episode: 256, duration: 12.951s, episode steps: 658, steps per second:  51, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.009592, mae: 0.528096, mean_q: 0.654210, mean_eps: 0.672756
 182598/600000: episode: 257, duration: 7.888s, episode steps: 467, steps per second:  59, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.008528, mae: 0.513130, mean_q: 0.634302, mean_eps: 0.671745
 183201/600000: episode: 258, duration: 10.450s, episode steps: 603, steps per second:  58, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.008641, mae: 0.522361, mean_q: 0.645849, mean_eps: 0.670780
 183646/600000: episode: 259, duration: 8.085s, episode steps: 445, steps per second:  55, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.009093, mae: 0.533464, mean_q: 0.659003, mean_eps: 0.669837
 184163/600000: episode: 260, duration: 8.840s, episode steps: 517, steps per second:  58, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.009205, mae: 0.518111, mean_q: 0.639163, mean_eps: 0.668973
 184816/600000: episode: 261, duration: 11.737s, episode steps: 653, steps per second:  56, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.010337, mae: 0.531372, mean_q: 0.656400, mean_eps: 0.667922
 185250/600000: episode: 262, duration: 8.267s, episode steps: 434, steps per second:  53, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.816 [0.000, 5.000],  loss: 0.009899, mae: 0.533506, mean_q: 0.659629, mean_eps: 0.666942
 185873/600000: episode: 263, duration: 11.033s, episode steps: 623, steps per second:  56, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.009551, mae: 0.519577, mean_q: 0.642099, mean_eps: 0.665988
 186874/600000: episode: 264, duration: 16.900s, episode steps: 1001, steps per second:  59, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.010191, mae: 0.523584, mean_q: 0.648972, mean_eps: 0.664527
 187546/600000: episode: 265, duration: 12.802s, episode steps: 672, steps per second:  52, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.009210, mae: 0.525060, mean_q: 0.649064, mean_eps: 0.663022
 188038/600000: episode: 266, duration: 8.692s, episode steps: 492, steps per second:  57, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008837, mae: 0.526206, mean_q: 0.650502, mean_eps: 0.661974
 188423/600000: episode: 267, duration: 7.031s, episode steps: 385, steps per second:  55, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.009286, mae: 0.525642, mean_q: 0.650932, mean_eps: 0.661186
 189324/600000: episode: 268, duration: 15.714s, episode steps: 901, steps per second:  57, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.009810, mae: 0.527922, mean_q: 0.651589, mean_eps: 0.660030
 190101/600000: episode: 269, duration: 13.694s, episode steps: 777, steps per second:  57, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.009487, mae: 0.521048, mean_q: 0.642865, mean_eps: 0.658518
 190835/600000: episode: 270, duration: 12.528s, episode steps: 734, steps per second:  59, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.166 [0.000, 5.000],  loss: 0.009413, mae: 0.537566, mean_q: 0.664916, mean_eps: 0.657158
 191213/600000: episode: 271, duration: 6.516s, episode steps: 378, steps per second:  58, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.009523, mae: 0.543109, mean_q: 0.672225, mean_eps: 0.656157
 191779/600000: episode: 272, duration: 9.997s, episode steps: 566, steps per second:  57, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.008329, mae: 0.545689, mean_q: 0.675644, mean_eps: 0.655307
 192608/600000: episode: 273, duration: 13.837s, episode steps: 829, steps per second:  60, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.009668, mae: 0.541673, mean_q: 0.668602, mean_eps: 0.654054
 193091/600000: episode: 274, duration: 8.690s, episode steps: 483, steps per second:  56, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.009613, mae: 0.537547, mean_q: 0.661188, mean_eps: 0.652874
 193979/600000: episode: 275, duration: 14.253s, episode steps: 888, steps per second:  62, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.009156, mae: 0.534906, mean_q: 0.659706, mean_eps: 0.651639
 195085/600000: episode: 276, duration: 19.324s, episode steps: 1106, steps per second:  57, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.008715, mae: 0.540290, mean_q: 0.665791, mean_eps: 0.649842
 195660/600000: episode: 277, duration: 10.000s, episode steps: 575, steps per second:  57, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.009124, mae: 0.534619, mean_q: 0.658420, mean_eps: 0.648330
 196290/600000: episode: 278, duration: 11.084s, episode steps: 630, steps per second:  57, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.009704, mae: 0.551038, mean_q: 0.679399, mean_eps: 0.647247
 196781/600000: episode: 279, duration: 8.231s, episode steps: 491, steps per second:  60, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.009118, mae: 0.537254, mean_q: 0.662793, mean_eps: 0.646235
 198075/600000: episode: 280, duration: 22.221s, episode steps: 1294, steps per second:  58, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.009603, mae: 0.541619, mean_q: 0.669097, mean_eps: 0.644630
 198591/600000: episode: 281, duration: 9.233s, episode steps: 516, steps per second:  56, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.010895, mae: 0.552625, mean_q: 0.682710, mean_eps: 0.643002
 199033/600000: episode: 282, duration: 8.247s, episode steps: 442, steps per second:  54, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.009284, mae: 0.527887, mean_q: 0.653589, mean_eps: 0.642138
 199492/600000: episode: 283, duration: 7.869s, episode steps: 459, steps per second:  58, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.009173, mae: 0.544933, mean_q: 0.673074, mean_eps: 0.641328
 200365/600000: episode: 284, duration: 15.825s, episode steps: 873, steps per second:  55, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.007861, mae: 0.552108, mean_q: 0.681209, mean_eps: 0.640130
 200745/600000: episode: 285, duration: 7.263s, episode steps: 380, steps per second:  52, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.195 [0.000, 5.000],  loss: 0.009407, mae: 0.583272, mean_q: 0.718778, mean_eps: 0.638999
 201363/600000: episode: 286, duration: 11.828s, episode steps: 618, steps per second:  52, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.009534, mae: 0.584133, mean_q: 0.719391, mean_eps: 0.638103
 202132/600000: episode: 287, duration: 15.054s, episode steps: 769, steps per second:  51, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.009534, mae: 0.585593, mean_q: 0.721317, mean_eps: 0.636857
 202765/600000: episode: 288, duration: 11.474s, episode steps: 633, steps per second:  55, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.009672, mae: 0.580668, mean_q: 0.714376, mean_eps: 0.635594
 204113/600000: episode: 289, duration: 23.534s, episode steps: 1348, steps per second:  57, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.009726, mae: 0.582106, mean_q: 0.716655, mean_eps: 0.633808
 204742/600000: episode: 290, duration: 11.661s, episode steps: 629, steps per second:  54, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.008669, mae: 0.584265, mean_q: 0.719312, mean_eps: 0.632030
 205391/600000: episode: 291, duration: 12.024s, episode steps: 649, steps per second:  54, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.010560, mae: 0.586145, mean_q: 0.719302, mean_eps: 0.630881
 206127/600000: episode: 292, duration: 12.409s, episode steps: 736, steps per second:  59, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008335, mae: 0.590430, mean_q: 0.726757, mean_eps: 0.629636
 206875/600000: episode: 293, duration: 12.789s, episode steps: 748, steps per second:  58, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.008008, mae: 0.569806, mean_q: 0.700049, mean_eps: 0.628300
 207301/600000: episode: 294, duration: 7.217s, episode steps: 426, steps per second:  59, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: 0.010029, mae: 0.585374, mean_q: 0.721578, mean_eps: 0.627242
 208488/600000: episode: 295, duration: 21.729s, episode steps: 1187, steps per second:  55, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.009830, mae: 0.583278, mean_q: 0.719497, mean_eps: 0.625791
 209767/600000: episode: 296, duration: 22.827s, episode steps: 1279, steps per second:  56, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.008969, mae: 0.589968, mean_q: 0.724965, mean_eps: 0.623573
 210634/600000: episode: 297, duration: 15.144s, episode steps: 867, steps per second:  57, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.009857, mae: 0.618137, mean_q: 0.759524, mean_eps: 0.621640
 211032/600000: episode: 298, duration: 6.860s, episode steps: 398, steps per second:  58, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.009835, mae: 0.630174, mean_q: 0.774169, mean_eps: 0.620502
 211728/600000: episode: 299, duration: 12.130s, episode steps: 696, steps per second:  57, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.011728, mae: 0.633689, mean_q: 0.779081, mean_eps: 0.619520
 212637/600000: episode: 300, duration: 16.097s, episode steps: 909, steps per second:  56, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.009421, mae: 0.642814, mean_q: 0.791131, mean_eps: 0.618072
 213414/600000: episode: 301, duration: 13.074s, episode steps: 777, steps per second:  59, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.009742, mae: 0.628066, mean_q: 0.772178, mean_eps: 0.616553
 213944/600000: episode: 302, duration: 8.808s, episode steps: 530, steps per second:  60, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.010679, mae: 0.639011, mean_q: 0.786521, mean_eps: 0.615380
 214995/600000: episode: 303, duration: 19.666s, episode steps: 1051, steps per second:  53, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.009824, mae: 0.635050, mean_q: 0.782378, mean_eps: 0.613958
 215720/600000: episode: 304, duration: 13.605s, episode steps: 725, steps per second:  53, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.010384, mae: 0.620742, mean_q: 0.764102, mean_eps: 0.612359
 216203/600000: episode: 305, duration: 7.984s, episode steps: 483, steps per second:  60, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.009355, mae: 0.626525, mean_q: 0.772094, mean_eps: 0.611272
 216731/600000: episode: 306, duration: 9.446s, episode steps: 528, steps per second:  56, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.843 [0.000, 5.000],  loss: 0.010247, mae: 0.635306, mean_q: 0.784223, mean_eps: 0.610361
 217301/600000: episode: 307, duration: 9.812s, episode steps: 570, steps per second:  58, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.011040, mae: 0.642978, mean_q: 0.791674, mean_eps: 0.609371
 218240/600000: episode: 308, duration: 15.841s, episode steps: 939, steps per second:  59, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.009607, mae: 0.633269, mean_q: 0.780565, mean_eps: 0.608014
 218834/600000: episode: 309, duration: 10.287s, episode steps: 594, steps per second:  58, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.010253, mae: 0.633773, mean_q: 0.779526, mean_eps: 0.606635
 219867/600000: episode: 310, duration: 18.047s, episode steps: 1033, steps per second:  57, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.010438, mae: 0.628823, mean_q: 0.772955, mean_eps: 0.605170
 221036/600000: episode: 311, duration: 20.760s, episode steps: 1169, steps per second:  56, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010063, mae: 0.653510, mean_q: 0.802928, mean_eps: 0.603190
 221576/600000: episode: 312, duration: 9.917s, episode steps: 540, steps per second:  54, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.009847, mae: 0.650046, mean_q: 0.800998, mean_eps: 0.601653
 222327/600000: episode: 313, duration: 14.504s, episode steps: 751, steps per second:  52, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.010200, mae: 0.652902, mean_q: 0.803945, mean_eps: 0.600490
 222908/600000: episode: 314, duration: 10.619s, episode steps: 581, steps per second:  55, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.010339, mae: 0.652614, mean_q: 0.804022, mean_eps: 0.599291
 223387/600000: episode: 315, duration: 9.288s, episode steps: 479, steps per second:  52, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.009077, mae: 0.647529, mean_q: 0.798613, mean_eps: 0.598337
 223962/600000: episode: 316, duration: 11.142s, episode steps: 575, steps per second:  52, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.009736, mae: 0.657958, mean_q: 0.809832, mean_eps: 0.597387
 224825/600000: episode: 317, duration: 14.945s, episode steps: 863, steps per second:  58, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.009694, mae: 0.652498, mean_q: 0.803440, mean_eps: 0.596091
 225320/600000: episode: 318, duration: 9.020s, episode steps: 495, steps per second:  55, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.010007, mae: 0.654057, mean_q: 0.806231, mean_eps: 0.594870
 225827/600000: episode: 319, duration: 8.829s, episode steps: 507, steps per second:  57, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.009327, mae: 0.661146, mean_q: 0.813142, mean_eps: 0.593970
 226604/600000: episode: 320, duration: 12.948s, episode steps: 777, steps per second:  60, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.011438, mae: 0.663353, mean_q: 0.814848, mean_eps: 0.592815
 227286/600000: episode: 321, duration: 11.455s, episode steps: 682, steps per second:  60, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.009360, mae: 0.655163, mean_q: 0.805491, mean_eps: 0.591501
 228235/600000: episode: 322, duration: 16.971s, episode steps: 949, steps per second:  56, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.009080, mae: 0.657511, mean_q: 0.809191, mean_eps: 0.590032
 229306/600000: episode: 323, duration: 19.339s, episode steps: 1071, steps per second:  55, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.009645, mae: 0.646837, mean_q: 0.795350, mean_eps: 0.588214
 230121/600000: episode: 324, duration: 14.445s, episode steps: 815, steps per second:  56, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.010293, mae: 0.664543, mean_q: 0.816341, mean_eps: 0.586515
 230510/600000: episode: 325, duration: 6.794s, episode steps: 389, steps per second:  57, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.009723, mae: 0.685941, mean_q: 0.843747, mean_eps: 0.585431
 231655/600000: episode: 326, duration: 20.822s, episode steps: 1145, steps per second:  55, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.009949, mae: 0.688007, mean_q: 0.844813, mean_eps: 0.584052
 232671/600000: episode: 327, duration: 18.445s, episode steps: 1016, steps per second:  55, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010143, mae: 0.687456, mean_q: 0.844499, mean_eps: 0.582108
 233983/600000: episode: 328, duration: 21.677s, episode steps: 1312, steps per second:  61, episode reward: 32.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.010312, mae: 0.692767, mean_q: 0.849128, mean_eps: 0.580013
 234449/600000: episode: 329, duration: 7.471s, episode steps: 466, steps per second:  62, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.009875, mae: 0.686665, mean_q: 0.841265, mean_eps: 0.578411
 235252/600000: episode: 330, duration: 13.726s, episode steps: 803, steps per second:  59, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.011030, mae: 0.694311, mean_q: 0.850936, mean_eps: 0.577270
 235918/600000: episode: 331, duration: 11.194s, episode steps: 666, steps per second:  59, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.010461, mae: 0.682955, mean_q: 0.837803, mean_eps: 0.575949
 236366/600000: episode: 332, duration: 7.619s, episode steps: 448, steps per second:  59, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.009307, mae: 0.680291, mean_q: 0.836995, mean_eps: 0.574944
 237147/600000: episode: 333, duration: 12.752s, episode steps: 781, steps per second:  61, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.006 [0.000, 5.000],  loss: 0.009955, mae: 0.695560, mean_q: 0.855098, mean_eps: 0.573839
 237688/600000: episode: 334, duration: 9.473s, episode steps: 541, steps per second:  57, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.011725, mae: 0.688273, mean_q: 0.845266, mean_eps: 0.572651
 238206/600000: episode: 335, duration: 8.885s, episode steps: 518, steps per second:  58, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.010341, mae: 0.695527, mean_q: 0.854395, mean_eps: 0.571697
 238853/600000: episode: 336, duration: 10.345s, episode steps: 647, steps per second:  63, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.010272, mae: 0.691553, mean_q: 0.849080, mean_eps: 0.570646
 239419/600000: episode: 337, duration: 9.766s, episode steps: 566, steps per second:  58, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.011468, mae: 0.689772, mean_q: 0.846465, mean_eps: 0.569555
 240038/600000: episode: 338, duration: 10.566s, episode steps: 619, steps per second:  59, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.011875, mae: 0.680787, mean_q: 0.835208, mean_eps: 0.568490
 240529/600000: episode: 339, duration: 8.924s, episode steps: 491, steps per second:  55, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.010356, mae: 0.732422, mean_q: 0.897945, mean_eps: 0.567489
 241162/600000: episode: 340, duration: 11.158s, episode steps: 633, steps per second:  57, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.011727, mae: 0.734993, mean_q: 0.901851, mean_eps: 0.566477
 241767/600000: episode: 341, duration: 9.978s, episode steps: 605, steps per second:  61, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.010292, mae: 0.739926, mean_q: 0.908397, mean_eps: 0.565365
 242662/600000: episode: 342, duration: 16.440s, episode steps: 895, steps per second:  54, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.010377, mae: 0.737862, mean_q: 0.906465, mean_eps: 0.564015
 243605/600000: episode: 343, duration: 17.059s, episode steps: 943, steps per second:  55, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.012258, mae: 0.746455, mean_q: 0.915280, mean_eps: 0.562359
 244730/600000: episode: 344, duration: 20.076s, episode steps: 1125, steps per second:  56, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.011531, mae: 0.728351, mean_q: 0.892699, mean_eps: 0.560498
 245427/600000: episode: 345, duration: 12.199s, episode steps: 697, steps per second:  57, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.012623, mae: 0.735571, mean_q: 0.902061, mean_eps: 0.558860
 246472/600000: episode: 346, duration: 18.792s, episode steps: 1045, steps per second:  56, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.009953, mae: 0.732519, mean_q: 0.900823, mean_eps: 0.557294
 247090/600000: episode: 347, duration: 10.626s, episode steps: 618, steps per second:  58, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.136 [0.000, 5.000],  loss: 0.010952, mae: 0.744110, mean_q: 0.914625, mean_eps: 0.555796
 248146/600000: episode: 348, duration: 18.160s, episode steps: 1056, steps per second:  58, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.009959, mae: 0.729526, mean_q: 0.897353, mean_eps: 0.554288
 249131/600000: episode: 349, duration: 19.111s, episode steps: 985, steps per second:  52, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.010419, mae: 0.736934, mean_q: 0.904944, mean_eps: 0.552452
 249484/600000: episode: 350, duration: 7.197s, episode steps: 353, steps per second:  49, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.011565, mae: 0.729742, mean_q: 0.897158, mean_eps: 0.551249
 250108/600000: episode: 351, duration: 11.102s, episode steps: 624, steps per second:  56, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.009989, mae: 0.739774, mean_q: 0.910276, mean_eps: 0.550371
 250496/600000: episode: 352, duration: 7.519s, episode steps: 388, steps per second:  52, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.930 [0.000, 5.000],  loss: 0.011106, mae: 0.749698, mean_q: 0.919298, mean_eps: 0.549460
 251935/600000: episode: 353, duration: 25.195s, episode steps: 1439, steps per second:  57, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.150 [0.000, 5.000],  loss: 0.010870, mae: 0.746597, mean_q: 0.916564, mean_eps: 0.547815
 252815/600000: episode: 354, duration: 15.706s, episode steps: 880, steps per second:  56, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.010665, mae: 0.763723, mean_q: 0.939983, mean_eps: 0.545727
 253690/600000: episode: 355, duration: 14.673s, episode steps: 875, steps per second:  60, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.010269, mae: 0.744123, mean_q: 0.914317, mean_eps: 0.544146
 254202/600000: episode: 356, duration: 8.921s, episode steps: 512, steps per second:  57, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.010747, mae: 0.755018, mean_q: 0.927971, mean_eps: 0.542897
 254743/600000: episode: 357, duration: 9.275s, episode steps: 541, steps per second:  58, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.011515, mae: 0.752820, mean_q: 0.925417, mean_eps: 0.541950
 255452/600000: episode: 358, duration: 12.851s, episode steps: 709, steps per second:  55, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.011221, mae: 0.735577, mean_q: 0.901802, mean_eps: 0.540827
 256417/600000: episode: 359, duration: 17.372s, episode steps: 965, steps per second:  56, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.010926, mae: 0.746422, mean_q: 0.915346, mean_eps: 0.539319
 256945/600000: episode: 360, duration: 8.949s, episode steps: 528, steps per second:  59, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.799 [0.000, 5.000],  loss: 0.011050, mae: 0.755408, mean_q: 0.925837, mean_eps: 0.537972
 257463/600000: episode: 361, duration: 9.011s, episode steps: 518, steps per second:  57, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.011095, mae: 0.761377, mean_q: 0.934287, mean_eps: 0.537033
 258336/600000: episode: 362, duration: 15.031s, episode steps: 873, steps per second:  58, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.010352, mae: 0.740657, mean_q: 0.908507, mean_eps: 0.535784
 258973/600000: episode: 363, duration: 11.682s, episode steps: 637, steps per second:  55, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.011775, mae: 0.752775, mean_q: 0.922076, mean_eps: 0.534423
 259638/600000: episode: 364, duration: 11.364s, episode steps: 665, steps per second:  59, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.010402, mae: 0.743502, mean_q: 0.912877, mean_eps: 0.533249
 260149/600000: episode: 365, duration: 8.884s, episode steps: 511, steps per second:  58, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.779 [0.000, 5.000],  loss: 0.010510, mae: 0.757983, mean_q: 0.930146, mean_eps: 0.532191
 260826/600000: episode: 366, duration: 12.342s, episode steps: 677, steps per second:  55, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.010385, mae: 0.775304, mean_q: 0.950715, mean_eps: 0.531122
 261408/600000: episode: 367, duration: 10.924s, episode steps: 582, steps per second:  53, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.011751, mae: 0.776307, mean_q: 0.950190, mean_eps: 0.529991
 262149/600000: episode: 368, duration: 14.485s, episode steps: 741, steps per second:  51, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.010891, mae: 0.759996, mean_q: 0.930432, mean_eps: 0.528800
 263066/600000: episode: 369, duration: 17.738s, episode steps: 917, steps per second:  52, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011207, mae: 0.771457, mean_q: 0.944879, mean_eps: 0.527306
 263592/600000: episode: 370, duration: 10.409s, episode steps: 526, steps per second:  51, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.009657, mae: 0.758756, mean_q: 0.929536, mean_eps: 0.526010
 264379/600000: episode: 371, duration: 15.246s, episode steps: 787, steps per second:  52, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.010820, mae: 0.781667, mean_q: 0.957834, mean_eps: 0.524829
 265038/600000: episode: 372, duration: 11.890s, episode steps: 659, steps per second:  55, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.011025, mae: 0.774372, mean_q: 0.948264, mean_eps: 0.523526
 265698/600000: episode: 373, duration: 12.648s, episode steps: 660, steps per second:  52, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.011076, mae: 0.768546, mean_q: 0.941838, mean_eps: 0.522338
 266648/600000: episode: 374, duration: 17.240s, episode steps: 950, steps per second:  55, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010807, mae: 0.766961, mean_q: 0.942063, mean_eps: 0.520890
 267452/600000: episode: 375, duration: 15.088s, episode steps: 804, steps per second:  53, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.010234, mae: 0.759911, mean_q: 0.932918, mean_eps: 0.519314
 268087/600000: episode: 376, duration: 12.010s, episode steps: 635, steps per second:  53, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.012816, mae: 0.763687, mean_q: 0.936656, mean_eps: 0.518018
 268993/600000: episode: 377, duration: 17.453s, episode steps: 906, steps per second:  52, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.011923, mae: 0.765557, mean_q: 0.939878, mean_eps: 0.516628
 269786/600000: episode: 378, duration: 14.637s, episode steps: 793, steps per second:  54, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: 0.010833, mae: 0.768318, mean_q: 0.943888, mean_eps: 0.515098
 270758/600000: episode: 379, duration: 17.381s, episode steps: 972, steps per second:  56, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.011711, mae: 0.805081, mean_q: 0.987760, mean_eps: 0.513510
 271814/600000: episode: 380, duration: 19.127s, episode steps: 1056, steps per second:  55, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.010788, mae: 0.818240, mean_q: 1.004032, mean_eps: 0.511685
 272540/600000: episode: 381, duration: 14.540s, episode steps: 726, steps per second:  50, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.011615, mae: 0.818743, mean_q: 1.004571, mean_eps: 0.510083
 273195/600000: episode: 382, duration: 11.553s, episode steps: 655, steps per second:  57, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.010601, mae: 0.819829, mean_q: 1.006888, mean_eps: 0.508841
 274109/600000: episode: 383, duration: 16.256s, episode steps: 914, steps per second:  56, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.010657, mae: 0.815202, mean_q: 0.999454, mean_eps: 0.507426
 274721/600000: episode: 384, duration: 11.301s, episode steps: 612, steps per second:  54, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.009590, mae: 0.812381, mean_q: 0.996564, mean_eps: 0.506051
 275654/600000: episode: 385, duration: 17.787s, episode steps: 933, steps per second:  52, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.013212, mae: 0.824256, mean_q: 1.008731, mean_eps: 0.504662
 276233/600000: episode: 386, duration: 10.679s, episode steps: 579, steps per second:  54, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.009950, mae: 0.808066, mean_q: 0.987633, mean_eps: 0.503301
 276874/600000: episode: 387, duration: 12.131s, episode steps: 641, steps per second:  53, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.009669, mae: 0.814998, mean_q: 0.996902, mean_eps: 0.502203
 277483/600000: episode: 388, duration: 11.236s, episode steps: 609, steps per second:  54, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.010912, mae: 0.819316, mean_q: 1.004107, mean_eps: 0.501080
 278010/600000: episode: 389, duration: 9.332s, episode steps: 527, steps per second:  56, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.011933, mae: 0.828662, mean_q: 1.015078, mean_eps: 0.500057
 278769/600000: episode: 390, duration: 13.177s, episode steps: 759, steps per second:  58, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.010665, mae: 0.810754, mean_q: 0.993486, mean_eps: 0.498898
 279429/600000: episode: 391, duration: 12.736s, episode steps: 660, steps per second:  52, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.011427, mae: 0.808803, mean_q: 0.990559, mean_eps: 0.497620
 280594/600000: episode: 392, duration: 24.497s, episode steps: 1165, steps per second:  48, episode reward: 30.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010624, mae: 0.822477, mean_q: 1.008576, mean_eps: 0.495978
 281065/600000: episode: 393, duration: 10.298s, episode steps: 471, steps per second:  46, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.010726, mae: 0.841905, mean_q: 1.032010, mean_eps: 0.494506
 281594/600000: episode: 394, duration: 11.220s, episode steps: 529, steps per second:  47, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.011845, mae: 0.815576, mean_q: 0.999280, mean_eps: 0.493606
 282150/600000: episode: 395, duration: 11.950s, episode steps: 556, steps per second:  47, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.012220, mae: 0.850489, mean_q: 1.041392, mean_eps: 0.492630
 282785/600000: episode: 396, duration: 11.976s, episode steps: 635, steps per second:  53, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.012048, mae: 0.836850, mean_q: 1.024501, mean_eps: 0.491558
 283357/600000: episode: 397, duration: 10.202s, episode steps: 572, steps per second:  56, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.911 [0.000, 5.000],  loss: 0.011935, mae: 0.826720, mean_q: 1.012193, mean_eps: 0.490470
 284066/600000: episode: 398, duration: 13.876s, episode steps: 709, steps per second:  51, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.013497, mae: 0.847466, mean_q: 1.035572, mean_eps: 0.489318
 285078/600000: episode: 399, duration: 20.149s, episode steps: 1012, steps per second:  50, episode reward: 27.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.743 [0.000, 5.000],  loss: 0.013089, mae: 0.840732, mean_q: 1.029446, mean_eps: 0.487770
 285769/600000: episode: 400, duration: 12.684s, episode steps: 691, steps per second:  54, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.011740, mae: 0.848651, mean_q: 1.038726, mean_eps: 0.486237
 286689/600000: episode: 401, duration: 16.259s, episode steps: 920, steps per second:  57, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.011278, mae: 0.836062, mean_q: 1.022002, mean_eps: 0.484786
 287329/600000: episode: 402, duration: 11.771s, episode steps: 640, steps per second:  54, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.010894, mae: 0.828080, mean_q: 1.012538, mean_eps: 0.483382
 288268/600000: episode: 403, duration: 18.066s, episode steps: 939, steps per second:  52, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.012480, mae: 0.842177, mean_q: 1.031324, mean_eps: 0.481964
 288751/600000: episode: 404, duration: 9.076s, episode steps: 483, steps per second:  53, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.012349, mae: 0.860810, mean_q: 1.055733, mean_eps: 0.480686
 289425/600000: episode: 405, duration: 11.766s, episode steps: 674, steps per second:  57, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.012304, mae: 0.837651, mean_q: 1.027347, mean_eps: 0.479642
 290506/600000: episode: 406, duration: 19.635s, episode steps: 1081, steps per second:  55, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.011601, mae: 0.860227, mean_q: 1.054888, mean_eps: 0.478061
 291244/600000: episode: 407, duration: 13.422s, episode steps: 738, steps per second:  55, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011870, mae: 0.901125, mean_q: 1.105574, mean_eps: 0.476427
 291838/600000: episode: 408, duration: 10.851s, episode steps: 594, steps per second:  55, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.009981, mae: 0.869054, mean_q: 1.065075, mean_eps: 0.475228
 292478/600000: episode: 409, duration: 10.793s, episode steps: 640, steps per second:  59, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.011799, mae: 0.883629, mean_q: 1.081073, mean_eps: 0.474116
 293211/600000: episode: 410, duration: 12.232s, episode steps: 733, steps per second:  60, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.011770, mae: 0.874190, mean_q: 1.071781, mean_eps: 0.472881
 293918/600000: episode: 411, duration: 13.248s, episode steps: 707, steps per second:  53, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.938 [0.000, 5.000],  loss: 0.011953, mae: 0.886450, mean_q: 1.086461, mean_eps: 0.471585
 294421/600000: episode: 412, duration: 9.653s, episode steps: 503, steps per second:  52, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.011456, mae: 0.891209, mean_q: 1.092784, mean_eps: 0.470494
 294832/600000: episode: 413, duration: 7.649s, episode steps: 411, steps per second:  54, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.156 [0.000, 5.000],  loss: 0.011615, mae: 0.900985, mean_q: 1.103560, mean_eps: 0.469673
 295171/600000: episode: 414, duration: 6.511s, episode steps: 339, steps per second:  52, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.011237, mae: 0.893453, mean_q: 1.093804, mean_eps: 0.469000
 296217/600000: episode: 415, duration: 18.762s, episode steps: 1046, steps per second:  56, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.011292, mae: 0.890578, mean_q: 1.090604, mean_eps: 0.467751
 296856/600000: episode: 416, duration: 11.755s, episode steps: 639, steps per second:  54, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.011941, mae: 0.892836, mean_q: 1.091737, mean_eps: 0.466235
 297633/600000: episode: 417, duration: 13.732s, episode steps: 777, steps per second:  57, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.012689, mae: 0.901393, mean_q: 1.101025, mean_eps: 0.464961
 298775/600000: episode: 418, duration: 20.083s, episode steps: 1142, steps per second:  57, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.012443, mae: 0.880477, mean_q: 1.076641, mean_eps: 0.463233
 299447/600000: episode: 419, duration: 13.004s, episode steps: 672, steps per second:  52, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.010600, mae: 0.877203, mean_q: 1.074807, mean_eps: 0.461602
 300185/600000: episode: 420, duration: 13.582s, episode steps: 738, steps per second:  54, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.013457, mae: 0.904696, mean_q: 1.106813, mean_eps: 0.460331
 300742/600000: episode: 421, duration: 11.399s, episode steps: 557, steps per second:  49, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.011083, mae: 0.924188, mean_q: 1.133035, mean_eps: 0.459165
 301676/600000: episode: 422, duration: 19.366s, episode steps: 934, steps per second:  48, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.012241, mae: 0.912971, mean_q: 1.117949, mean_eps: 0.457826
 302379/600000: episode: 423, duration: 12.397s, episode steps: 703, steps per second:  57, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.011819, mae: 0.928699, mean_q: 1.136576, mean_eps: 0.456353
 304294/600000: episode: 424, duration: 36.409s, episode steps: 1915, steps per second:  53, episode reward: 13.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.012238, mae: 0.925177, mean_q: 1.132030, mean_eps: 0.453995
 304902/600000: episode: 425, duration: 11.278s, episode steps: 608, steps per second:  54, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.012875, mae: 0.924568, mean_q: 1.130492, mean_eps: 0.451724
 306501/600000: episode: 426, duration: 28.563s, episode steps: 1599, steps per second:  56, episode reward: 30.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.012581, mae: 0.921655, mean_q: 1.127220, mean_eps: 0.449736
 307392/600000: episode: 427, duration: 17.380s, episode steps: 891, steps per second:  51, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.012568, mae: 0.933018, mean_q: 1.142301, mean_eps: 0.447497
 308302/600000: episode: 428, duration: 17.784s, episode steps: 910, steps per second:  51, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.012221, mae: 0.912016, mean_q: 1.118162, mean_eps: 0.445877
 309166/600000: episode: 429, duration: 15.995s, episode steps: 864, steps per second:  54, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.012863, mae: 0.921821, mean_q: 1.127734, mean_eps: 0.444279
 310048/600000: episode: 430, duration: 16.423s, episode steps: 882, steps per second:  54, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.011564, mae: 0.920290, mean_q: 1.126084, mean_eps: 0.442709
 310733/600000: episode: 431, duration: 12.926s, episode steps: 685, steps per second:  53, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.011015, mae: 0.970374, mean_q: 1.187076, mean_eps: 0.441298
 311304/600000: episode: 432, duration: 11.160s, episode steps: 571, steps per second:  51, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.013696, mae: 0.965902, mean_q: 1.180714, mean_eps: 0.440168
 312082/600000: episode: 433, duration: 13.793s, episode steps: 778, steps per second:  56, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.012204, mae: 0.970816, mean_q: 1.187636, mean_eps: 0.438954
 313076/600000: episode: 434, duration: 19.138s, episode steps: 994, steps per second:  52, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.011624, mae: 0.957363, mean_q: 1.170996, mean_eps: 0.437360
 313924/600000: episode: 435, duration: 16.989s, episode steps: 848, steps per second:  50, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.011547, mae: 0.956172, mean_q: 1.168587, mean_eps: 0.435704
 314501/600000: episode: 436, duration: 11.675s, episode steps: 577, steps per second:  49, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.012645, mae: 0.961432, mean_q: 1.173781, mean_eps: 0.434418
 315410/600000: episode: 437, duration: 15.948s, episode steps: 909, steps per second:  57, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.012939, mae: 0.978276, mean_q: 1.195501, mean_eps: 0.433079
 316618/600000: episode: 438, duration: 24.178s, episode steps: 1208, steps per second:  50, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.012658, mae: 0.970299, mean_q: 1.187848, mean_eps: 0.431175
 317280/600000: episode: 439, duration: 12.031s, episode steps: 662, steps per second:  55, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.012663, mae: 0.965164, mean_q: 1.181726, mean_eps: 0.429494
 317906/600000: episode: 440, duration: 11.872s, episode steps: 626, steps per second:  53, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.085 [0.000, 5.000],  loss: 0.011113, mae: 0.949501, mean_q: 1.162258, mean_eps: 0.428334
 319023/600000: episode: 441, duration: 21.505s, episode steps: 1117, steps per second:  52, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.011363, mae: 0.972277, mean_q: 1.189869, mean_eps: 0.426765
 319813/600000: episode: 442, duration: 17.542s, episode steps: 790, steps per second:  45, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.011265, mae: 0.961737, mean_q: 1.176220, mean_eps: 0.425048
 320628/600000: episode: 443, duration: 18.029s, episode steps: 815, steps per second:  45, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.011596, mae: 0.985138, mean_q: 1.205829, mean_eps: 0.423604
 322184/600000: episode: 444, duration: 29.486s, episode steps: 1556, steps per second:  53, episode reward: 33.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.011609, mae: 1.004476, mean_q: 1.228634, mean_eps: 0.421473
 322988/600000: episode: 445, duration: 14.795s, episode steps: 804, steps per second:  54, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.013706, mae: 1.013136, mean_q: 1.236308, mean_eps: 0.419349
 323726/600000: episode: 446, duration: 14.551s, episode steps: 738, steps per second:  51, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.013564, mae: 1.021292, mean_q: 1.247355, mean_eps: 0.417959
 324272/600000: episode: 447, duration: 10.934s, episode steps: 546, steps per second:  50, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.012302, mae: 0.988341, mean_q: 1.207446, mean_eps: 0.416804
 324840/600000: episode: 448, duration: 10.330s, episode steps: 568, steps per second:  55, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.014838, mae: 1.010151, mean_q: 1.235941, mean_eps: 0.415803
 325460/600000: episode: 449, duration: 12.267s, episode steps: 620, steps per second:  51, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.013279, mae: 1.000609, mean_q: 1.225282, mean_eps: 0.414734
 326217/600000: episode: 450, duration: 15.204s, episode steps: 757, steps per second:  50, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.013233, mae: 1.010124, mean_q: 1.235224, mean_eps: 0.413492
 326599/600000: episode: 451, duration: 7.834s, episode steps: 382, steps per second:  49, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.011194, mae: 0.997658, mean_q: 1.221145, mean_eps: 0.412466
 327296/600000: episode: 452, duration: 14.354s, episode steps: 697, steps per second:  49, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.012436, mae: 1.001045, mean_q: 1.223840, mean_eps: 0.411497
 327895/600000: episode: 453, duration: 11.996s, episode steps: 599, steps per second:  50, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.011010, mae: 0.991549, mean_q: 1.214235, mean_eps: 0.410331
 328667/600000: episode: 454, duration: 15.175s, episode steps: 772, steps per second:  51, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.096 [0.000, 5.000],  loss: 0.013124, mae: 0.999969, mean_q: 1.222401, mean_eps: 0.409096
 329063/600000: episode: 455, duration: 8.037s, episode steps: 396, steps per second:  49, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.014641, mae: 1.005848, mean_q: 1.230417, mean_eps: 0.408045
 329924/600000: episode: 456, duration: 16.651s, episode steps: 861, steps per second:  52, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.011133, mae: 1.004697, mean_q: 1.228765, mean_eps: 0.406914
 330497/600000: episode: 457, duration: 11.019s, episode steps: 573, steps per second:  52, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.013846, mae: 1.075511, mean_q: 1.315112, mean_eps: 0.405622
 331512/600000: episode: 458, duration: 18.770s, episode steps: 1015, steps per second:  54, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.012934, mae: 1.078090, mean_q: 1.316713, mean_eps: 0.404193
 332281/600000: episode: 459, duration: 15.054s, episode steps: 769, steps per second:  51, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.013613, mae: 1.070645, mean_q: 1.306989, mean_eps: 0.402587
 333291/600000: episode: 460, duration: 20.302s, episode steps: 1010, steps per second:  50, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.015418, mae: 1.078480, mean_q: 1.316652, mean_eps: 0.400985
 333667/600000: episode: 461, duration: 7.191s, episode steps: 376, steps per second:  52, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.012988, mae: 1.075434, mean_q: 1.314890, mean_eps: 0.399740
 334171/600000: episode: 462, duration: 9.528s, episode steps: 504, steps per second:  53, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.016787, mae: 1.079991, mean_q: 1.319514, mean_eps: 0.398948
 334692/600000: episode: 463, duration: 10.156s, episode steps: 521, steps per second:  51, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.014709, mae: 1.076789, mean_q: 1.315562, mean_eps: 0.398026
 335068/600000: episode: 464, duration: 7.779s, episode steps: 376, steps per second:  48, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.069 [0.000, 5.000],  loss: 0.011096, mae: 1.080821, mean_q: 1.321194, mean_eps: 0.397220
 335685/600000: episode: 465, duration: 11.294s, episode steps: 617, steps per second:  55, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.012830, mae: 1.073976, mean_q: 1.312595, mean_eps: 0.396323
 336267/600000: episode: 466, duration: 11.821s, episode steps: 582, steps per second:  49, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.013759, mae: 1.069646, mean_q: 1.306296, mean_eps: 0.395243
 337067/600000: episode: 467, duration: 16.044s, episode steps: 800, steps per second:  50, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.962 [0.000, 5.000],  loss: 0.012745, mae: 1.067155, mean_q: 1.303168, mean_eps: 0.394001
 338328/600000: episode: 468, duration: 27.477s, episode steps: 1261, steps per second:  46, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.011757, mae: 1.069710, mean_q: 1.306414, mean_eps: 0.392147
 339345/600000: episode: 469, duration: 21.466s, episode steps: 1017, steps per second:  47, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.012670, mae: 1.083621, mean_q: 1.323886, mean_eps: 0.390095
 340312/600000: episode: 470, duration: 21.187s, episode steps: 967, steps per second:  46, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.011277, mae: 1.091395, mean_q: 1.333907, mean_eps: 0.388310
 341104/600000: episode: 471, duration: 16.880s, episode steps: 792, steps per second:  47, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.012899, mae: 1.121842, mean_q: 1.369435, mean_eps: 0.386729
 341851/600000: episode: 472, duration: 16.032s, episode steps: 747, steps per second:  47, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.013132, mae: 1.140245, mean_q: 1.392569, mean_eps: 0.385343
 342542/600000: episode: 473, duration: 15.065s, episode steps: 691, steps per second:  46, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.013362, mae: 1.129229, mean_q: 1.378997, mean_eps: 0.384047
 343381/600000: episode: 474, duration: 17.231s, episode steps: 839, steps per second:  49, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.014331, mae: 1.131767, mean_q: 1.382122, mean_eps: 0.382668
 344029/600000: episode: 475, duration: 13.927s, episode steps: 648, steps per second:  47, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.013350, mae: 1.125103, mean_q: 1.374694, mean_eps: 0.381329
 345164/600000: episode: 476, duration: 21.727s, episode steps: 1135, steps per second:  52, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.012802, mae: 1.124661, mean_q: 1.371612, mean_eps: 0.379727
 345964/600000: episode: 477, duration: 14.651s, episode steps: 800, steps per second:  55, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.013300, mae: 1.139711, mean_q: 1.390691, mean_eps: 0.377988
 346643/600000: episode: 478, duration: 13.003s, episode steps: 679, steps per second:  52, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.014218, mae: 1.111826, mean_q: 1.355475, mean_eps: 0.376656
 347011/600000: episode: 479, duration: 7.294s, episode steps: 368, steps per second:  50, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.012594, mae: 1.137417, mean_q: 1.388722, mean_eps: 0.375713
 347794/600000: episode: 480, duration: 15.454s, episode steps: 783, steps per second:  51, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.011892, mae: 1.120185, mean_q: 1.369144, mean_eps: 0.374676
 348477/600000: episode: 481, duration: 12.494s, episode steps: 683, steps per second:  55, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.908 [0.000, 5.000],  loss: 0.012839, mae: 1.123013, mean_q: 1.370972, mean_eps: 0.373355
 349386/600000: episode: 482, duration: 17.984s, episode steps: 909, steps per second:  51, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.012409, mae: 1.121002, mean_q: 1.366991, mean_eps: 0.371922
 349877/600000: episode: 483, duration: 9.933s, episode steps: 491, steps per second:  49, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.011135, mae: 1.132835, mean_q: 1.382516, mean_eps: 0.370662
 350580/600000: episode: 484, duration: 13.125s, episode steps: 703, steps per second:  54, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.013668, mae: 1.179747, mean_q: 1.440171, mean_eps: 0.369590
 351233/600000: episode: 485, duration: 12.296s, episode steps: 653, steps per second:  53, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.012390, mae: 1.173432, mean_q: 1.431325, mean_eps: 0.368369
 351864/600000: episode: 486, duration: 11.924s, episode steps: 631, steps per second:  53, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.816 [0.000, 5.000],  loss: 0.012683, mae: 1.178945, mean_q: 1.439640, mean_eps: 0.367214
 352953/600000: episode: 487, duration: 22.261s, episode steps: 1089, steps per second:  49, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.013178, mae: 1.193086, mean_q: 1.455773, mean_eps: 0.365666
 353896/600000: episode: 488, duration: 18.834s, episode steps: 943, steps per second:  50, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.012509, mae: 1.181254, mean_q: 1.440336, mean_eps: 0.363837
 354765/600000: episode: 489, duration: 17.584s, episode steps: 869, steps per second:  49, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.015372, mae: 1.192224, mean_q: 1.453310, mean_eps: 0.362206
 355399/600000: episode: 490, duration: 12.611s, episode steps: 634, steps per second:  50, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012932, mae: 1.188350, mean_q: 1.449257, mean_eps: 0.360852
 356075/600000: episode: 491, duration: 13.841s, episode steps: 676, steps per second:  49, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.873 [0.000, 5.000],  loss: 0.012500, mae: 1.190862, mean_q: 1.453085, mean_eps: 0.359675
 356778/600000: episode: 492, duration: 14.999s, episode steps: 703, steps per second:  47, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.013587, mae: 1.200268, mean_q: 1.466513, mean_eps: 0.358433
 358278/600000: episode: 493, duration: 29.618s, episode steps: 1500, steps per second:  51, episode reward: 22.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.013409, mae: 1.184402, mean_q: 1.445380, mean_eps: 0.356450
 359102/600000: episode: 494, duration: 16.065s, episode steps: 824, steps per second:  51, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.014487, mae: 1.187233, mean_q: 1.449733, mean_eps: 0.354358
 359662/600000: episode: 495, duration: 11.318s, episode steps: 560, steps per second:  49, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.014872, mae: 1.187088, mean_q: 1.449457, mean_eps: 0.353112
 360350/600000: episode: 496, duration: 13.786s, episode steps: 688, steps per second:  50, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.013226, mae: 1.199162, mean_q: 1.463051, mean_eps: 0.351989
 361022/600000: episode: 497, duration: 12.777s, episode steps: 672, steps per second:  53, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.012626, mae: 1.211655, mean_q: 1.476880, mean_eps: 0.350765
 361835/600000: episode: 498, duration: 17.223s, episode steps: 813, steps per second:  47, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.014463, mae: 1.207475, mean_q: 1.471447, mean_eps: 0.349430
 362495/600000: episode: 499, duration: 13.841s, episode steps: 660, steps per second:  48, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.932 [0.000, 5.000],  loss: 0.013983, mae: 1.199419, mean_q: 1.462743, mean_eps: 0.348105
 363810/600000: episode: 500, duration: 25.597s, episode steps: 1315, steps per second:  51, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.014069, mae: 1.201401, mean_q: 1.465084, mean_eps: 0.346326
 364495/600000: episode: 501, duration: 12.971s, episode steps: 685, steps per second:  53, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.016662, mae: 1.179363, mean_q: 1.438205, mean_eps: 0.344526
 365304/600000: episode: 502, duration: 16.503s, episode steps: 809, steps per second:  49, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.820 [0.000, 5.000],  loss: 0.011573, mae: 1.194665, mean_q: 1.457436, mean_eps: 0.343184
 366157/600000: episode: 503, duration: 15.981s, episode steps: 853, steps per second:  53, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.155 [0.000, 5.000],  loss: 0.013841, mae: 1.196735, mean_q: 1.459261, mean_eps: 0.341686
 367078/600000: episode: 504, duration: 17.561s, episode steps: 921, steps per second:  52, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.016335, mae: 1.213179, mean_q: 1.479847, mean_eps: 0.340088
 367924/600000: episode: 505, duration: 16.509s, episode steps: 846, steps per second:  51, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.014445, mae: 1.195784, mean_q: 1.456625, mean_eps: 0.338500
 368495/600000: episode: 506, duration: 10.677s, episode steps: 571, steps per second:  53, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.012577, mae: 1.197701, mean_q: 1.457553, mean_eps: 0.337226
 369104/600000: episode: 507, duration: 11.828s, episode steps: 609, steps per second:  51, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.013757, mae: 1.203498, mean_q: 1.467061, mean_eps: 0.336164
 369868/600000: episode: 508, duration: 15.316s, episode steps: 764, steps per second:  50, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.014276, mae: 1.199644, mean_q: 1.464394, mean_eps: 0.334929
 370237/600000: episode: 509, duration: 7.328s, episode steps: 369, steps per second:  50, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.015341, mae: 1.237035, mean_q: 1.510609, mean_eps: 0.333906
 371546/600000: episode: 510, duration: 26.881s, episode steps: 1309, steps per second:  49, episode reward: 29.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.014839, mae: 1.248178, mean_q: 1.523938, mean_eps: 0.332394
 372306/600000: episode: 511, duration: 15.764s, episode steps: 760, steps per second:  48, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.014381, mae: 1.247094, mean_q: 1.522705, mean_eps: 0.330533
 373185/600000: episode: 512, duration: 17.996s, episode steps: 879, steps per second:  49, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.015110, mae: 1.243978, mean_q: 1.517963, mean_eps: 0.329057
 373690/600000: episode: 513, duration: 10.526s, episode steps: 505, steps per second:  48, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.855 [0.000, 5.000],  loss: 0.013053, mae: 1.244920, mean_q: 1.519301, mean_eps: 0.327812
 374479/600000: episode: 514, duration: 16.130s, episode steps: 789, steps per second:  49, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.210 [0.000, 5.000],  loss: 0.013982, mae: 1.235181, mean_q: 1.507482, mean_eps: 0.326649
 375119/600000: episode: 515, duration: 13.252s, episode steps: 640, steps per second:  48, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.013349, mae: 1.232134, mean_q: 1.504381, mean_eps: 0.325364
 376090/600000: episode: 516, duration: 20.567s, episode steps: 971, steps per second:  47, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.015369, mae: 1.240064, mean_q: 1.511287, mean_eps: 0.323913
 376544/600000: episode: 517, duration: 9.798s, episode steps: 454, steps per second:  46, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.919 [0.000, 5.000],  loss: 0.014840, mae: 1.244925, mean_q: 1.518195, mean_eps: 0.322631
 377243/600000: episode: 518, duration: 14.236s, episode steps: 699, steps per second:  49, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.219 [0.000, 5.000],  loss: 0.014656, mae: 1.241134, mean_q: 1.513581, mean_eps: 0.321594
 378403/600000: episode: 519, duration: 23.359s, episode steps: 1160, steps per second:  50, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.014615, mae: 1.257692, mean_q: 1.534881, mean_eps: 0.319920
 379053/600000: episode: 520, duration: 12.867s, episode steps: 650, steps per second:  51, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.120 [0.000, 5.000],  loss: 0.015867, mae: 1.254726, mean_q: 1.531529, mean_eps: 0.318290
 379680/600000: episode: 521, duration: 12.945s, episode steps: 627, steps per second:  48, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.014451, mae: 1.259745, mean_q: 1.537349, mean_eps: 0.317141
 380789/600000: episode: 522, duration: 20.606s, episode steps: 1109, steps per second:  54, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.013187, mae: 1.270069, mean_q: 1.551105, mean_eps: 0.315579
 381490/600000: episode: 523, duration: 12.748s, episode steps: 701, steps per second:  55, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.012721, mae: 1.272893, mean_q: 1.553896, mean_eps: 0.313948
 382145/600000: episode: 524, duration: 12.204s, episode steps: 655, steps per second:  54, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.968 [0.000, 5.000],  loss: 0.014002, mae: 1.291121, mean_q: 1.574499, mean_eps: 0.312728
 382657/600000: episode: 525, duration: 10.178s, episode steps: 512, steps per second:  50, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.014478, mae: 1.269385, mean_q: 1.548995, mean_eps: 0.311676
 383327/600000: episode: 526, duration: 12.303s, episode steps: 670, steps per second:  54, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.016479, mae: 1.269455, mean_q: 1.547586, mean_eps: 0.310614
 384116/600000: episode: 527, duration: 14.894s, episode steps: 789, steps per second:  53, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.978 [0.000, 5.000],  loss: 0.014957, mae: 1.284211, mean_q: 1.566438, mean_eps: 0.309304
 384997/600000: episode: 528, duration: 16.754s, episode steps: 881, steps per second:  53, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013305, mae: 1.277332, mean_q: 1.558033, mean_eps: 0.307799
 385622/600000: episode: 529, duration: 13.258s, episode steps: 625, steps per second:  47, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.012395, mae: 1.286483, mean_q: 1.568609, mean_eps: 0.306442
 386430/600000: episode: 530, duration: 18.328s, episode steps: 808, steps per second:  44, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.012 [0.000, 5.000],  loss: 0.015444, mae: 1.279754, mean_q: 1.560842, mean_eps: 0.305153
 387508/600000: episode: 531, duration: 21.552s, episode steps: 1078, steps per second:  50, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.012544, mae: 1.262895, mean_q: 1.539761, mean_eps: 0.303458
 388531/600000: episode: 532, duration: 19.441s, episode steps: 1023, steps per second:  53, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.014904, mae: 1.291767, mean_q: 1.572371, mean_eps: 0.301568
 389424/600000: episode: 533, duration: 17.052s, episode steps: 893, steps per second:  52, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.015818, mae: 1.275695, mean_q: 1.552714, mean_eps: 0.299843
 390191/600000: episode: 534, duration: 15.864s, episode steps: 767, steps per second:  48, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.014732, mae: 1.273601, mean_q: 1.551916, mean_eps: 0.298349
 391094/600000: episode: 535, duration: 17.928s, episode steps: 903, steps per second:  50, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.014289, mae: 1.314895, mean_q: 1.601523, mean_eps: 0.296844
 392443/600000: episode: 536, duration: 26.813s, episode steps: 1349, steps per second:  50, episode reward: 27.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.015172, mae: 1.313589, mean_q: 1.599486, mean_eps: 0.294818
 392982/600000: episode: 537, duration: 10.793s, episode steps: 539, steps per second:  50, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.012767, mae: 1.313037, mean_q: 1.599582, mean_eps: 0.293118
 393493/600000: episode: 538, duration: 10.225s, episode steps: 511, steps per second:  50, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.951 [0.000, 5.000],  loss: 0.014512, mae: 1.308130, mean_q: 1.594224, mean_eps: 0.292172
 394525/600000: episode: 539, duration: 19.028s, episode steps: 1032, steps per second:  54, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: 0.014082, mae: 1.326891, mean_q: 1.616116, mean_eps: 0.290782
 395163/600000: episode: 540, duration: 12.205s, episode steps: 638, steps per second:  52, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.053 [0.000, 5.000],  loss: 0.014885, mae: 1.310491, mean_q: 1.595634, mean_eps: 0.289281
 395807/600000: episode: 541, duration: 12.907s, episode steps: 644, steps per second:  50, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.014035, mae: 1.336160, mean_q: 1.625740, mean_eps: 0.288129
 397444/600000: episode: 542, duration: 30.132s, episode steps: 1637, steps per second:  54, episode reward: 29.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.013998, mae: 1.300984, mean_q: 1.582688, mean_eps: 0.286077
 397987/600000: episode: 543, duration: 10.314s, episode steps: 543, steps per second:  53, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.015734, mae: 1.321664, mean_q: 1.608454, mean_eps: 0.284115
 398360/600000: episode: 544, duration: 7.438s, episode steps: 373, steps per second:  50, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.013125, mae: 1.292888, mean_q: 1.571735, mean_eps: 0.283290
 399141/600000: episode: 545, duration: 15.008s, episode steps: 781, steps per second:  52, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.014587, mae: 1.308525, mean_q: 1.591845, mean_eps: 0.282250
 400312/600000: episode: 546, duration: 22.006s, episode steps: 1171, steps per second:  53, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.013782, mae: 1.339556, mean_q: 1.632303, mean_eps: 0.280493
 400713/600000: episode: 547, duration: 7.363s, episode steps: 401, steps per second:  54, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.713 [0.000, 5.000],  loss: 0.014798, mae: 1.351671, mean_q: 1.647494, mean_eps: 0.279078
 401099/600000: episode: 548, duration: 6.706s, episode steps: 386, steps per second:  58, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.044 [0.000, 5.000],  loss: 0.013986, mae: 1.376045, mean_q: 1.676203, mean_eps: 0.278369
 402007/600000: episode: 549, duration: 16.250s, episode steps: 908, steps per second:  56, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.661 [0.000, 5.000],  loss: 0.013563, mae: 1.358810, mean_q: 1.653936, mean_eps: 0.277206
 402532/600000: episode: 550, duration: 9.254s, episode steps: 525, steps per second:  57, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.013644, mae: 1.345459, mean_q: 1.636918, mean_eps: 0.275918
 403348/600000: episode: 551, duration: 14.165s, episode steps: 816, steps per second:  58, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.012494, mae: 1.341860, mean_q: 1.635091, mean_eps: 0.274712
 403847/600000: episode: 552, duration: 8.814s, episode steps: 499, steps per second:  57, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.856 [0.000, 5.000],  loss: 0.015883, mae: 1.361435, mean_q: 1.655016, mean_eps: 0.273527
 404594/600000: episode: 553, duration: 13.250s, episode steps: 747, steps per second:  56, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.013282, mae: 1.345948, mean_q: 1.638557, mean_eps: 0.272404
 405870/600000: episode: 554, duration: 23.131s, episode steps: 1276, steps per second:  55, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.014823, mae: 1.365244, mean_q: 1.660816, mean_eps: 0.270582
 406595/600000: episode: 555, duration: 13.472s, episode steps: 725, steps per second:  54, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.779 [0.000, 5.000],  loss: 0.015472, mae: 1.359262, mean_q: 1.653070, mean_eps: 0.268782
 407115/600000: episode: 556, duration: 9.825s, episode steps: 520, steps per second:  53, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.012677, mae: 1.339314, mean_q: 1.628897, mean_eps: 0.267663
 407598/600000: episode: 557, duration: 8.797s, episode steps: 483, steps per second:  55, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.013247, mae: 1.348457, mean_q: 1.638693, mean_eps: 0.266759
 408802/600000: episode: 558, duration: 23.140s, episode steps: 1204, steps per second:  52, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.968 [0.000, 5.000],  loss: 0.012796, mae: 1.351668, mean_q: 1.644637, mean_eps: 0.265240
 409392/600000: episode: 559, duration: 12.243s, episode steps: 590, steps per second:  48, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.015857, mae: 1.347852, mean_q: 1.641398, mean_eps: 0.263627
 409949/600000: episode: 560, duration: 12.276s, episode steps: 557, steps per second:  45, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.156 [0.000, 5.000],  loss: 0.013219, mae: 1.373929, mean_q: 1.673849, mean_eps: 0.262594
 410525/600000: episode: 561, duration: 12.683s, episode steps: 576, steps per second:  45, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.012162, mae: 1.353521, mean_q: 1.649738, mean_eps: 0.261572
 411125/600000: episode: 562, duration: 13.065s, episode steps: 600, steps per second:  46, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.012604, mae: 1.373474, mean_q: 1.673734, mean_eps: 0.260513
 412342/600000: episode: 563, duration: 25.094s, episode steps: 1217, steps per second:  48, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.039 [0.000, 5.000],  loss: 0.012893, mae: 1.367893, mean_q: 1.665729, mean_eps: 0.258879
 413731/600000: episode: 564, duration: 26.106s, episode steps: 1389, steps per second:  53, episode reward: 26.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.014472, mae: 1.365715, mean_q: 1.661074, mean_eps: 0.256535
 414410/600000: episode: 565, duration: 13.567s, episode steps: 679, steps per second:  50, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.013571, mae: 1.365453, mean_q: 1.663000, mean_eps: 0.254674
 415367/600000: episode: 566, duration: 17.733s, episode steps: 957, steps per second:  54, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.011 [0.000, 5.000],  loss: 0.014444, mae: 1.361692, mean_q: 1.655121, mean_eps: 0.253202
 415875/600000: episode: 567, duration: 9.322s, episode steps: 508, steps per second:  54, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.085 [0.000, 5.000],  loss: 0.012648, mae: 1.369371, mean_q: 1.667351, mean_eps: 0.251884
 416403/600000: episode: 568, duration: 9.370s, episode steps: 528, steps per second:  56, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.012075, mae: 1.370486, mean_q: 1.667883, mean_eps: 0.250952
 417350/600000: episode: 569, duration: 17.249s, episode steps: 947, steps per second:  55, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.078 [0.000, 5.000],  loss: 0.014659, mae: 1.364173, mean_q: 1.659807, mean_eps: 0.249623
 418393/600000: episode: 570, duration: 20.089s, episode steps: 1043, steps per second:  52, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.014183, mae: 1.362919, mean_q: 1.660070, mean_eps: 0.247830
 419089/600000: episode: 571, duration: 13.563s, episode steps: 696, steps per second:  51, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.014904, mae: 1.363272, mean_q: 1.658300, mean_eps: 0.246264
 419764/600000: episode: 572, duration: 12.002s, episode steps: 675, steps per second:  56, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.018 [0.000, 5.000],  loss: 0.013318, mae: 1.366686, mean_q: 1.662851, mean_eps: 0.245033
 420811/600000: episode: 573, duration: 18.723s, episode steps: 1047, steps per second:  56, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.013175, mae: 1.378547, mean_q: 1.677509, mean_eps: 0.243485
 421483/600000: episode: 574, duration: 12.444s, episode steps: 672, steps per second:  54, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.013332, mae: 1.396318, mean_q: 1.699230, mean_eps: 0.241937
 422172/600000: episode: 575, duration: 12.189s, episode steps: 689, steps per second:  57, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.013177, mae: 1.384224, mean_q: 1.685449, mean_eps: 0.240713
 422673/600000: episode: 576, duration: 9.145s, episode steps: 501, steps per second:  55, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.013793, mae: 1.376369, mean_q: 1.677227, mean_eps: 0.239640
 423415/600000: episode: 577, duration: 12.954s, episode steps: 742, steps per second:  57, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.941 [0.000, 5.000],  loss: 0.016602, mae: 1.385163, mean_q: 1.686582, mean_eps: 0.238521
 424121/600000: episode: 578, duration: 12.947s, episode steps: 706, steps per second:  55, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.786 [0.000, 5.000],  loss: 0.014575, mae: 1.365016, mean_q: 1.662382, mean_eps: 0.237218
 424701/600000: episode: 579, duration: 11.346s, episode steps: 580, steps per second:  51, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.014231, mae: 1.372884, mean_q: 1.671622, mean_eps: 0.236058
 425538/600000: episode: 580, duration: 15.371s, episode steps: 837, steps per second:  54, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.866 [0.000, 5.000],  loss: 0.015393, mae: 1.379140, mean_q: 1.679178, mean_eps: 0.234784
 426414/600000: episode: 581, duration: 15.696s, episode steps: 876, steps per second:  56, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.952 [0.000, 5.000],  loss: 0.013762, mae: 1.372809, mean_q: 1.672141, mean_eps: 0.233243
 427370/600000: episode: 582, duration: 17.630s, episode steps: 956, steps per second:  54, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.818 [0.000, 5.000],  loss: 0.015199, mae: 1.397632, mean_q: 1.700073, mean_eps: 0.231594
 428024/600000: episode: 583, duration: 11.546s, episode steps: 654, steps per second:  57, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.015029, mae: 1.397215, mean_q: 1.701820, mean_eps: 0.230147
 428621/600000: episode: 584, duration: 11.367s, episode steps: 597, steps per second:  53, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.013547, mae: 1.374994, mean_q: 1.675219, mean_eps: 0.229020
 429292/600000: episode: 585, duration: 12.276s, episode steps: 671, steps per second:  55, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.013290, mae: 1.381173, mean_q: 1.681532, mean_eps: 0.227879
 430095/600000: episode: 586, duration: 15.569s, episode steps: 803, steps per second:  52, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.782 [0.000, 5.000],  loss: 0.013262, mae: 1.395591, mean_q: 1.700110, mean_eps: 0.226554
 430481/600000: episode: 587, duration: 7.954s, episode steps: 386, steps per second:  49, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.019215, mae: 1.465175, mean_q: 1.783084, mean_eps: 0.225482
 431328/600000: episode: 588, duration: 17.287s, episode steps: 847, steps per second:  49, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.015952, mae: 1.446278, mean_q: 1.760120, mean_eps: 0.224373
 432180/600000: episode: 589, duration: 15.945s, episode steps: 852, steps per second:  53, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.015184, mae: 1.445090, mean_q: 1.757841, mean_eps: 0.222846
 433347/600000: episode: 590, duration: 20.985s, episode steps: 1167, steps per second:  56, episode reward: 33.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.149 [0.000, 5.000],  loss: 0.015551, mae: 1.439640, mean_q: 1.750626, mean_eps: 0.221028
 434128/600000: episode: 591, duration: 14.953s, episode steps: 781, steps per second:  52, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.013224, mae: 1.436194, mean_q: 1.746967, mean_eps: 0.219275
 434805/600000: episode: 592, duration: 12.209s, episode steps: 677, steps per second:  55, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.012899, mae: 1.436312, mean_q: 1.749480, mean_eps: 0.217961
 435519/600000: episode: 593, duration: 12.675s, episode steps: 714, steps per second:  56, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.014878, mae: 1.437150, mean_q: 1.747836, mean_eps: 0.216708
 436125/600000: episode: 594, duration: 16.474s, episode steps: 606, steps per second:  37, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.715 [0.000, 5.000],  loss: 0.013482, mae: 1.426381, mean_q: 1.736757, mean_eps: 0.215520
 437282/600000: episode: 595, duration: 21.126s, episode steps: 1157, steps per second:  55, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.015698, mae: 1.431423, mean_q: 1.740656, mean_eps: 0.213933
 438201/600000: episode: 596, duration: 16.274s, episode steps: 919, steps per second:  56, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.014977, mae: 1.451599, mean_q: 1.764225, mean_eps: 0.212064
 438845/600000: episode: 597, duration: 11.273s, episode steps: 644, steps per second:  57, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.581 [0.000, 5.000],  loss: 0.014245, mae: 1.437767, mean_q: 1.749845, mean_eps: 0.210657
 439397/600000: episode: 598, duration: 9.731s, episode steps: 552, steps per second:  57, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.015263, mae: 1.444732, mean_q: 1.758932, mean_eps: 0.209580
 440224/600000: episode: 599, duration: 14.826s, episode steps: 827, steps per second:  56, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.015748, mae: 1.431080, mean_q: 1.738565, mean_eps: 0.208342
 441100/600000: episode: 600, duration: 15.095s, episode steps: 876, steps per second:  58, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.798 [0.000, 5.000],  loss: 0.015566, mae: 1.478134, mean_q: 1.798803, mean_eps: 0.206812
 441874/600000: episode: 601, duration: 12.945s, episode steps: 774, steps per second:  60, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.015330, mae: 1.470310, mean_q: 1.790459, mean_eps: 0.205325
 442945/600000: episode: 602, duration: 18.880s, episode steps: 1071, steps per second:  57, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.014114, mae: 1.474778, mean_q: 1.794248, mean_eps: 0.203662
 443654/600000: episode: 603, duration: 13.134s, episode steps: 709, steps per second:  54, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.013153, mae: 1.475241, mean_q: 1.794300, mean_eps: 0.202060
 444452/600000: episode: 604, duration: 14.645s, episode steps: 798, steps per second:  54, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.015205, mae: 1.469052, mean_q: 1.785191, mean_eps: 0.200706
 444937/600000: episode: 605, duration: 8.963s, episode steps: 485, steps per second:  54, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.016286, mae: 1.458525, mean_q: 1.771599, mean_eps: 0.199551
 445731/600000: episode: 606, duration: 14.186s, episode steps: 794, steps per second:  56, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.012615, mae: 1.472240, mean_q: 1.790038, mean_eps: 0.198399
 446618/600000: episode: 607, duration: 16.126s, episode steps: 887, steps per second:  55, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.947 [0.000, 5.000],  loss: 0.016399, mae: 1.477549, mean_q: 1.795662, mean_eps: 0.196887
 447168/600000: episode: 608, duration: 10.017s, episode steps: 550, steps per second:  55, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.076 [0.000, 5.000],  loss: 0.014827, mae: 1.468603, mean_q: 1.784694, mean_eps: 0.195594
 447873/600000: episode: 609, duration: 13.105s, episode steps: 705, steps per second:  54, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.012607, mae: 1.480544, mean_q: 1.799790, mean_eps: 0.194464
 448445/600000: episode: 610, duration: 10.970s, episode steps: 572, steps per second:  52, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.804 [0.000, 5.000],  loss: 0.014022, mae: 1.452614, mean_q: 1.765803, mean_eps: 0.193312
 449508/600000: episode: 611, duration: 20.917s, episode steps: 1063, steps per second:  51, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.049 [0.000, 5.000],  loss: 0.015775, mae: 1.467822, mean_q: 1.783273, mean_eps: 0.191843
 450143/600000: episode: 612, duration: 13.438s, episode steps: 635, steps per second:  47, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.894 [0.000, 5.000],  loss: 0.014179, mae: 1.467260, mean_q: 1.782515, mean_eps: 0.190317
 450814/600000: episode: 613, duration: 13.848s, episode steps: 671, steps per second:  48, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.602 [0.000, 5.000],  loss: 0.015283, mae: 1.515364, mean_q: 1.840479, mean_eps: 0.189140
 451396/600000: episode: 614, duration: 10.893s, episode steps: 582, steps per second:  53, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.727 [0.000, 5.000],  loss: 0.014372, mae: 1.517717, mean_q: 1.845233, mean_eps: 0.188013
 452235/600000: episode: 615, duration: 15.647s, episode steps: 839, steps per second:  54, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.103 [0.000, 5.000],  loss: 0.013453, mae: 1.506133, mean_q: 1.830729, mean_eps: 0.186735
 453535/600000: episode: 616, duration: 25.326s, episode steps: 1300, steps per second:  51, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.015547, mae: 1.510233, mean_q: 1.833870, mean_eps: 0.184809
 454096/600000: episode: 617, duration: 10.401s, episode steps: 561, steps per second:  54, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.014522, mae: 1.534748, mean_q: 1.863049, mean_eps: 0.183135
 455426/600000: episode: 618, duration: 24.861s, episode steps: 1330, steps per second:  53, episode reward: 27.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.016554, mae: 1.527903, mean_q: 1.857340, mean_eps: 0.181432
 455978/600000: episode: 619, duration: 10.945s, episode steps: 552, steps per second:  50, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.015629, mae: 1.529744, mean_q: 1.859585, mean_eps: 0.179736
 456833/600000: episode: 620, duration: 16.784s, episode steps: 855, steps per second:  51, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.013973, mae: 1.534426, mean_q: 1.866325, mean_eps: 0.178469
 457699/600000: episode: 621, duration: 17.928s, episode steps: 866, steps per second:  48, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.013949, mae: 1.525166, mean_q: 1.853512, mean_eps: 0.176921
 458793/600000: episode: 622, duration: 22.685s, episode steps: 1094, steps per second:  48, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.014208, mae: 1.540866, mean_q: 1.872658, mean_eps: 0.175157
 459887/600000: episode: 623, duration: 21.928s, episode steps: 1094, steps per second:  50, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.014913, mae: 1.521548, mean_q: 1.848633, mean_eps: 0.173188
 460544/600000: episode: 624, duration: 12.269s, episode steps: 657, steps per second:  54, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.067 [0.000, 5.000],  loss: 0.013299, mae: 1.551183, mean_q: 1.886597, mean_eps: 0.171615
 461161/600000: episode: 625, duration: 11.382s, episode steps: 617, steps per second:  54, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.156 [0.000, 5.000],  loss: 0.016833, mae: 1.558401, mean_q: 1.894037, mean_eps: 0.170466
 462057/600000: episode: 626, duration: 17.461s, episode steps: 896, steps per second:  51, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.014122, mae: 1.544796, mean_q: 1.877322, mean_eps: 0.169102
 462734/600000: episode: 627, duration: 12.891s, episode steps: 677, steps per second:  53, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.858 [0.000, 5.000],  loss: 0.016420, mae: 1.548040, mean_q: 1.881363, mean_eps: 0.167687
 463540/600000: episode: 628, duration: 14.752s, episode steps: 806, steps per second:  55, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.014656, mae: 1.574814, mean_q: 1.916502, mean_eps: 0.166355
 464540/600000: episode: 629, duration: 18.267s, episode steps: 1000, steps per second:  55, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.042 [0.000, 5.000],  loss: 0.014739, mae: 1.562597, mean_q: 1.899857, mean_eps: 0.164732
 465072/600000: episode: 630, duration: 9.652s, episode steps: 532, steps per second:  55, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.013547, mae: 1.537607, mean_q: 1.865872, mean_eps: 0.163353
 466273/600000: episode: 631, duration: 22.387s, episode steps: 1201, steps per second:  54, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.014232, mae: 1.551273, mean_q: 1.883876, mean_eps: 0.161790
 467333/600000: episode: 632, duration: 19.861s, episode steps: 1060, steps per second:  53, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.014751, mae: 1.564580, mean_q: 1.899563, mean_eps: 0.159753
 468394/600000: episode: 633, duration: 22.629s, episode steps: 1061, steps per second:  47, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.934 [0.000, 5.000],  loss: 0.015872, mae: 1.556963, mean_q: 1.891400, mean_eps: 0.157845
 469074/600000: episode: 634, duration: 14.612s, episode steps: 680, steps per second:  47, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.014773, mae: 1.569096, mean_q: 1.905999, mean_eps: 0.156279
 469691/600000: episode: 635, duration: 11.803s, episode steps: 617, steps per second:  52, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.028 [0.000, 5.000],  loss: 0.016394, mae: 1.545041, mean_q: 1.875573, mean_eps: 0.155112
 470323/600000: episode: 636, duration: 12.184s, episode steps: 632, steps per second:  52, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.532 [0.000, 5.000],  loss: 0.016954, mae: 1.590710, mean_q: 1.932037, mean_eps: 0.153989
 470840/600000: episode: 637, duration: 10.050s, episode steps: 517, steps per second:  51, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.845 [0.000, 5.000],  loss: 0.016702, mae: 1.590693, mean_q: 1.931765, mean_eps: 0.152956
 471228/600000: episode: 638, duration: 7.414s, episode steps: 388, steps per second:  52, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.015573, mae: 1.617377, mean_q: 1.964821, mean_eps: 0.152142
 471718/600000: episode: 639, duration: 9.381s, episode steps: 490, steps per second:  52, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.015006, mae: 1.572155, mean_q: 1.910348, mean_eps: 0.151350
 472656/600000: episode: 640, duration: 18.664s, episode steps: 938, steps per second:  50, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.839 [0.000, 5.000],  loss: 0.014929, mae: 1.593645, mean_q: 1.934210, mean_eps: 0.150065
 473646/600000: episode: 641, duration: 18.663s, episode steps: 990, steps per second:  53, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.014991, mae: 1.600264, mean_q: 1.943004, mean_eps: 0.148330
 474476/600000: episode: 642, duration: 16.252s, episode steps: 830, steps per second:  51, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.017093, mae: 1.585462, mean_q: 1.923515, mean_eps: 0.146692
 475491/600000: episode: 643, duration: 20.799s, episode steps: 1015, steps per second:  49, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.015373, mae: 1.595295, mean_q: 1.935829, mean_eps: 0.145032
 476293/600000: episode: 644, duration: 16.703s, episode steps: 802, steps per second:  48, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.016034, mae: 1.606398, mean_q: 1.949614, mean_eps: 0.143394
 477015/600000: episode: 645, duration: 14.991s, episode steps: 722, steps per second:  48, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.016339, mae: 1.616052, mean_q: 1.960122, mean_eps: 0.142023
 477969/600000: episode: 646, duration: 20.527s, episode steps: 954, steps per second:  46, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.017495, mae: 1.593255, mean_q: 1.931818, mean_eps: 0.140514
 478500/600000: episode: 647, duration: 10.221s, episode steps: 531, steps per second:  52, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.017222, mae: 1.608396, mean_q: 1.950391, mean_eps: 0.139179
 479254/600000: episode: 648, duration: 14.404s, episode steps: 754, steps per second:  52, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.017095, mae: 1.589260, mean_q: 1.928240, mean_eps: 0.138023
 480719/600000: episode: 649, duration: 28.539s, episode steps: 1465, steps per second:  51, episode reward: 32.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.015978, mae: 1.619488, mean_q: 1.965449, mean_eps: 0.136025
 481615/600000: episode: 650, duration: 18.154s, episode steps: 896, steps per second:  49, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.015424, mae: 1.655749, mean_q: 2.009912, mean_eps: 0.133901
 482260/600000: episode: 651, duration: 12.272s, episode steps: 645, steps per second:  53, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.008 [0.000, 5.000],  loss: 0.015804, mae: 1.647319, mean_q: 2.001211, mean_eps: 0.132515
 483264/600000: episode: 652, duration: 18.916s, episode steps: 1004, steps per second:  53, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.844 [0.000, 5.000],  loss: 0.016114, mae: 1.626297, mean_q: 1.974627, mean_eps: 0.131032
 484066/600000: episode: 653, duration: 15.676s, episode steps: 802, steps per second:  51, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.703 [0.000, 5.000],  loss: 0.014783, mae: 1.657852, mean_q: 2.012768, mean_eps: 0.129405
 484859/600000: episode: 654, duration: 15.470s, episode steps: 793, steps per second:  51, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.842 [0.000, 5.000],  loss: 0.016353, mae: 1.627718, mean_q: 1.976139, mean_eps: 0.127968
 485701/600000: episode: 655, duration: 16.871s, episode steps: 842, steps per second:  50, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.676 [0.000, 5.000],  loss: 0.015808, mae: 1.654096, mean_q: 2.007669, mean_eps: 0.126496
 486671/600000: episode: 656, duration: 18.350s, episode steps: 970, steps per second:  53, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.015918, mae: 1.631732, mean_q: 1.979074, mean_eps: 0.124865
 487501/600000: episode: 657, duration: 15.713s, episode steps: 830, steps per second:  53, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.902 [0.000, 5.000],  loss: 0.014836, mae: 1.633398, mean_q: 1.983381, mean_eps: 0.123245
 488034/600000: episode: 658, duration: 9.666s, episode steps: 533, steps per second:  55, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.016263, mae: 1.648949, mean_q: 1.999501, mean_eps: 0.122018
 488765/600000: episode: 659, duration: 14.300s, episode steps: 731, steps per second:  51, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.870 [0.000, 5.000],  loss: 0.014028, mae: 1.636443, mean_q: 1.985322, mean_eps: 0.120880
 489383/600000: episode: 660, duration: 11.872s, episode steps: 618, steps per second:  52, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.015308, mae: 1.665357, mean_q: 2.021837, mean_eps: 0.119667
 490032/600000: episode: 661, duration: 13.396s, episode steps: 649, steps per second:  48, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.014326, mae: 1.650551, mean_q: 2.002167, mean_eps: 0.118529
 490699/600000: episode: 662, duration: 13.955s, episode steps: 667, steps per second:  48, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.012833, mae: 1.657520, mean_q: 2.011861, mean_eps: 0.117345
 491502/600000: episode: 663, duration: 17.468s, episode steps: 803, steps per second:  46, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.518 [0.000, 5.000],  loss: 0.014615, mae: 1.660434, mean_q: 2.015176, mean_eps: 0.116020
 492311/600000: episode: 664, duration: 17.586s, episode steps: 809, steps per second:  46, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.593 [0.000, 5.000],  loss: 0.016101, mae: 1.633573, mean_q: 1.982829, mean_eps: 0.114569
 493295/600000: episode: 665, duration: 21.181s, episode steps: 984, steps per second:  46, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.014879, mae: 1.630302, mean_q: 1.979680, mean_eps: 0.112956
 494388/600000: episode: 666, duration: 22.895s, episode steps: 1093, steps per second:  48, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.089 [0.000, 5.000],  loss: 0.015164, mae: 1.646446, mean_q: 1.997437, mean_eps: 0.111088
 495134/600000: episode: 667, duration: 16.682s, episode steps: 746, steps per second:  45, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.015946, mae: 1.637201, mean_q: 1.984918, mean_eps: 0.109432
 495655/600000: episode: 668, duration: 11.689s, episode steps: 521, steps per second:  45, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.096 [0.000, 5.000],  loss: 0.016655, mae: 1.654144, mean_q: 2.007359, mean_eps: 0.108291
 496265/600000: episode: 669, duration: 12.308s, episode steps: 610, steps per second:  50, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.972 [0.000, 5.000],  loss: 0.014867, mae: 1.657126, mean_q: 2.011812, mean_eps: 0.107272
 497093/600000: episode: 670, duration: 16.449s, episode steps: 828, steps per second:  50, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.789 [0.000, 5.000],  loss: 0.015187, mae: 1.647613, mean_q: 2.000501, mean_eps: 0.105976
 497779/600000: episode: 671, duration: 13.002s, episode steps: 686, steps per second:  53, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.603 [0.000, 5.000],  loss: 0.015359, mae: 1.647269, mean_q: 2.000006, mean_eps: 0.104615
 498432/600000: episode: 672, duration: 13.984s, episode steps: 653, steps per second:  47, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.016279, mae: 1.660186, mean_q: 2.014907, mean_eps: 0.103413
 499104/600000: episode: 673, duration: 13.199s, episode steps: 672, steps per second:  51, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.253 [0.000, 5.000],  loss: 0.015703, mae: 1.664308, mean_q: 2.019447, mean_eps: 0.102221
 499746/600000: episode: 674, duration: 11.978s, episode steps: 642, steps per second:  54, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.972 [0.000, 5.000],  loss: 0.016353, mae: 1.648515, mean_q: 1.999719, mean_eps: 0.101037
 500682/600000: episode: 675, duration: 17.633s, episode steps: 936, steps per second:  53, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.016352, mae: 1.662054, mean_q: 2.016577, mean_eps: 0.100062
 501376/600000: episode: 676, duration: 13.309s, episode steps: 694, steps per second:  52, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.013721, mae: 1.675208, mean_q: 2.033159, mean_eps: 0.100000
 502283/600000: episode: 677, duration: 17.942s, episode steps: 907, steps per second:  51, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.016015, mae: 1.665761, mean_q: 2.019546, mean_eps: 0.100000
 503289/600000: episode: 678, duration: 19.091s, episode steps: 1006, steps per second:  53, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.016066, mae: 1.650494, mean_q: 2.003306, mean_eps: 0.100000
 504658/600000: episode: 679, duration: 28.980s, episode steps: 1369, steps per second:  47, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.016020, mae: 1.676786, mean_q: 2.034579, mean_eps: 0.100000
 505615/600000: episode: 680, duration: 20.008s, episode steps: 957, steps per second:  48, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.101 [0.000, 5.000],  loss: 0.015213, mae: 1.660073, mean_q: 2.014172, mean_eps: 0.100000
 507336/600000: episode: 681, duration: 34.547s, episode steps: 1721, steps per second:  50, episode reward: 30.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.015752, mae: 1.658466, mean_q: 2.011385, mean_eps: 0.100000
 508061/600000: episode: 682, duration: 15.007s, episode steps: 725, steps per second:  48, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.014742, mae: 1.667072, mean_q: 2.022690, mean_eps: 0.100000
 508770/600000: episode: 683, duration: 13.579s, episode steps: 709, steps per second:  52, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.014804, mae: 1.654026, mean_q: 2.005966, mean_eps: 0.100000
 509442/600000: episode: 684, duration: 13.291s, episode steps: 672, steps per second:  51, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.016608, mae: 1.661833, mean_q: 2.015070, mean_eps: 0.100000
 510965/600000: episode: 685, duration: 32.168s, episode steps: 1523, steps per second:  47, episode reward: 30.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.015127, mae: 1.664912, mean_q: 2.020505, mean_eps: 0.100000
 511799/600000: episode: 686, duration: 16.732s, episode steps: 834, steps per second:  50, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.015655, mae: 1.685849, mean_q: 2.046530, mean_eps: 0.100000
 512675/600000: episode: 687, duration: 17.641s, episode steps: 876, steps per second:  50, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.016243, mae: 1.686601, mean_q: 2.046734, mean_eps: 0.100000
 513480/600000: episode: 688, duration: 16.524s, episode steps: 805, steps per second:  49, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.016143, mae: 1.690139, mean_q: 2.050927, mean_eps: 0.100000
 514350/600000: episode: 689, duration: 16.865s, episode steps: 870, steps per second:  52, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: 0.016400, mae: 1.687069, mean_q: 2.046707, mean_eps: 0.100000
 514984/600000: episode: 690, duration: 11.648s, episode steps: 634, steps per second:  54, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.016016, mae: 1.679802, mean_q: 2.037150, mean_eps: 0.100000
 515603/600000: episode: 691, duration: 11.456s, episode steps: 619, steps per second:  54, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.016881, mae: 1.707821, mean_q: 2.074558, mean_eps: 0.100000
 516799/600000: episode: 692, duration: 23.288s, episode steps: 1196, steps per second:  51, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.016396, mae: 1.668500, mean_q: 2.025136, mean_eps: 0.100000
 517705/600000: episode: 693, duration: 16.551s, episode steps: 906, steps per second:  55, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.017616, mae: 1.689331, mean_q: 2.050168, mean_eps: 0.100000
 518371/600000: episode: 694, duration: 12.490s, episode steps: 666, steps per second:  53, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.015299, mae: 1.650002, mean_q: 2.002375, mean_eps: 0.100000
 519484/600000: episode: 695, duration: 20.031s, episode steps: 1113, steps per second:  56, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.016254, mae: 1.696668, mean_q: 2.059294, mean_eps: 0.100000
 520423/600000: episode: 696, duration: 17.309s, episode steps: 939, steps per second:  54, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.875 [0.000, 5.000],  loss: 0.015432, mae: 1.677965, mean_q: 2.037125, mean_eps: 0.100000
 520824/600000: episode: 697, duration: 7.409s, episode steps: 401, steps per second:  54, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.016241, mae: 1.677709, mean_q: 2.035248, mean_eps: 0.100000
 521666/600000: episode: 698, duration: 15.893s, episode steps: 842, steps per second:  53, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.015296, mae: 1.641031, mean_q: 1.991201, mean_eps: 0.100000
 522373/600000: episode: 699, duration: 13.292s, episode steps: 707, steps per second:  53, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.014692, mae: 1.667134, mean_q: 2.023107, mean_eps: 0.100000
 523304/600000: episode: 700, duration: 19.409s, episode steps: 931, steps per second:  48, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.016300, mae: 1.679960, mean_q: 2.038379, mean_eps: 0.100000
 523822/600000: episode: 701, duration: 9.938s, episode steps: 518, steps per second:  52, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.014146, mae: 1.646532, mean_q: 1.997889, mean_eps: 0.100000
 524843/600000: episode: 702, duration: 19.715s, episode steps: 1021, steps per second:  52, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.073 [0.000, 5.000],  loss: 0.016523, mae: 1.683362, mean_q: 2.042470, mean_eps: 0.100000
 525891/600000: episode: 703, duration: 21.093s, episode steps: 1048, steps per second:  50, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.022 [0.000, 5.000],  loss: 0.015768, mae: 1.663776, mean_q: 2.017002, mean_eps: 0.100000
 527533/600000: episode: 704, duration: 32.998s, episode steps: 1642, steps per second:  50, episode reward: 32.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.016495, mae: 1.661213, mean_q: 2.014760, mean_eps: 0.100000
 528059/600000: episode: 705, duration: 10.868s, episode steps: 526, steps per second:  48, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.014534, mae: 1.666526, mean_q: 2.023396, mean_eps: 0.100000
 529020/600000: episode: 706, duration: 19.120s, episode steps: 961, steps per second:  50, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.043 [0.000, 5.000],  loss: 0.014419, mae: 1.654272, mean_q: 2.008108, mean_eps: 0.100000
 529810/600000: episode: 707, duration: 16.010s, episode steps: 790, steps per second:  49, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.016078, mae: 1.676633, mean_q: 2.033810, mean_eps: 0.100000
 530485/600000: episode: 708, duration: 14.368s, episode steps: 675, steps per second:  47, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.015155, mae: 1.652402, mean_q: 2.004696, mean_eps: 0.100000
 531260/600000: episode: 709, duration: 16.280s, episode steps: 775, steps per second:  48, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.014515, mae: 1.700204, mean_q: 2.061497, mean_eps: 0.100000
 532007/600000: episode: 710, duration: 16.277s, episode steps: 747, steps per second:  46, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.015628, mae: 1.686322, mean_q: 2.043792, mean_eps: 0.100000
 532618/600000: episode: 711, duration: 12.361s, episode steps: 611, steps per second:  49, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.016427, mae: 1.675572, mean_q: 2.031088, mean_eps: 0.100000
 533244/600000: episode: 712, duration: 11.727s, episode steps: 626, steps per second:  53, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.013626, mae: 1.681575, mean_q: 2.038650, mean_eps: 0.100000
 534225/600000: episode: 713, duration: 18.213s, episode steps: 981, steps per second:  54, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.015581, mae: 1.692553, mean_q: 2.052349, mean_eps: 0.100000
 535224/600000: episode: 714, duration: 19.661s, episode steps: 999, steps per second:  51, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.016367, mae: 1.673259, mean_q: 2.029827, mean_eps: 0.100000
 536015/600000: episode: 715, duration: 14.769s, episode steps: 791, steps per second:  54, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.015933, mae: 1.671157, mean_q: 2.025154, mean_eps: 0.100000
 536729/600000: episode: 716, duration: 13.363s, episode steps: 714, steps per second:  53, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.015084, mae: 1.665656, mean_q: 2.020421, mean_eps: 0.100000
 537767/600000: episode: 717, duration: 19.091s, episode steps: 1038, steps per second:  54, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.014653, mae: 1.668147, mean_q: 2.023947, mean_eps: 0.100000
 538252/600000: episode: 718, duration: 9.253s, episode steps: 485, steps per second:  52, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.899 [0.000, 5.000],  loss: 0.016154, mae: 1.689168, mean_q: 2.051094, mean_eps: 0.100000
 538926/600000: episode: 719, duration: 13.095s, episode steps: 674, steps per second:  51, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.014148, mae: 1.696797, mean_q: 2.060902, mean_eps: 0.100000
 539538/600000: episode: 720, duration: 12.262s, episode steps: 612, steps per second:  50, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.763 [0.000, 5.000],  loss: 0.016498, mae: 1.677512, mean_q: 2.036635, mean_eps: 0.100000
 540543/600000: episode: 721, duration: 21.525s, episode steps: 1005, steps per second:  47, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.013277, mae: 1.685029, mean_q: 2.045517, mean_eps: 0.100000
 541231/600000: episode: 722, duration: 17.239s, episode steps: 688, steps per second:  40, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.015033, mae: 1.709730, mean_q: 2.074313, mean_eps: 0.100000
 542420/600000: episode: 723, duration: 26.594s, episode steps: 1189, steps per second:  45, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.796 [0.000, 5.000],  loss: 0.014844, mae: 1.695683, mean_q: 2.056256, mean_eps: 0.100000
 543145/600000: episode: 724, duration: 15.399s, episode steps: 725, steps per second:  47, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.997 [0.000, 5.000],  loss: 0.016336, mae: 1.724288, mean_q: 2.091859, mean_eps: 0.100000
 544678/600000: episode: 725, duration: 31.247s, episode steps: 1533, steps per second:  49, episode reward: 31.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.016055, mae: 1.693554, mean_q: 2.054096, mean_eps: 0.100000
 545666/600000: episode: 726, duration: 21.423s, episode steps: 988, steps per second:  46, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.015757, mae: 1.698109, mean_q: 2.058926, mean_eps: 0.100000
 546284/600000: episode: 727, duration: 13.765s, episode steps: 618, steps per second:  45, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.016996, mae: 1.721342, mean_q: 2.088283, mean_eps: 0.100000
 547183/600000: episode: 728, duration: 19.665s, episode steps: 899, steps per second:  46, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.933 [0.000, 5.000],  loss: 0.015950, mae: 1.685458, mean_q: 2.043689, mean_eps: 0.100000
 548275/600000: episode: 729, duration: 21.869s, episode steps: 1092, steps per second:  50, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.017909, mae: 1.696217, mean_q: 2.055950, mean_eps: 0.100000
 548790/600000: episode: 730, duration: 10.300s, episode steps: 515, steps per second:  50, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.012023, mae: 1.676888, mean_q: 2.032965, mean_eps: 0.100000
 549732/600000: episode: 731, duration: 19.395s, episode steps: 942, steps per second:  49, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.016979, mae: 1.697807, mean_q: 2.056606, mean_eps: 0.100000
 550581/600000: episode: 732, duration: 15.805s, episode steps: 849, steps per second:  54, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.014145, mae: 1.715657, mean_q: 2.081125, mean_eps: 0.100000
 551689/600000: episode: 733, duration: 20.439s, episode steps: 1108, steps per second:  54, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.016999, mae: 1.746194, mean_q: 2.118132, mean_eps: 0.100000
 552251/600000: episode: 734, duration: 11.334s, episode steps: 562, steps per second:  50, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.098 [0.000, 5.000],  loss: 0.015912, mae: 1.748280, mean_q: 2.117436, mean_eps: 0.100000
 553338/600000: episode: 735, duration: 21.727s, episode steps: 1087, steps per second:  50, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.015346, mae: 1.735673, mean_q: 2.102899, mean_eps: 0.100000
 554285/600000: episode: 736, duration: 18.072s, episode steps: 947, steps per second:  52, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.019056, mae: 1.736137, mean_q: 2.103228, mean_eps: 0.100000
 555117/600000: episode: 737, duration: 15.620s, episode steps: 832, steps per second:  53, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.708 [0.000, 5.000],  loss: 0.014446, mae: 1.742422, mean_q: 2.111980, mean_eps: 0.100000
 555565/600000: episode: 738, duration: 8.337s, episode steps: 448, steps per second:  54, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.015263, mae: 1.724939, mean_q: 2.088392, mean_eps: 0.100000
 556304/600000: episode: 739, duration: 13.596s, episode steps: 739, steps per second:  54, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.013620, mae: 1.755580, mean_q: 2.125700, mean_eps: 0.100000
 557115/600000: episode: 740, duration: 15.675s, episode steps: 811, steps per second:  52, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.015408, mae: 1.743047, mean_q: 2.111337, mean_eps: 0.100000
 557606/600000: episode: 741, duration: 9.660s, episode steps: 491, steps per second:  51, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.079 [0.000, 5.000],  loss: 0.015324, mae: 1.728117, mean_q: 2.092911, mean_eps: 0.100000
 558606/600000: episode: 742, duration: 20.828s, episode steps: 1000, steps per second:  48, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.899 [0.000, 5.000],  loss: 0.014489, mae: 1.699167, mean_q: 2.058314, mean_eps: 0.100000
 559436/600000: episode: 743, duration: 17.448s, episode steps: 830, steps per second:  48, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.822 [0.000, 5.000],  loss: 0.014434, mae: 1.715813, mean_q: 2.079311, mean_eps: 0.100000
 560460/600000: episode: 744, duration: 20.208s, episode steps: 1024, steps per second:  51, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.955 [0.000, 5.000],  loss: 0.014141, mae: 1.729749, mean_q: 2.096834, mean_eps: 0.100000
 561256/600000: episode: 745, duration: 15.559s, episode steps: 796, steps per second:  51, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.015221, mae: 1.749148, mean_q: 2.120419, mean_eps: 0.100000
 561858/600000: episode: 746, duration: 12.184s, episode steps: 602, steps per second:  49, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.015883, mae: 1.745260, mean_q: 2.115360, mean_eps: 0.100000
 562709/600000: episode: 747, duration: 16.560s, episode steps: 851, steps per second:  51, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.014733, mae: 1.733718, mean_q: 2.100467, mean_eps: 0.100000
 563601/600000: episode: 748, duration: 17.836s, episode steps: 892, steps per second:  50, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.013999, mae: 1.738310, mean_q: 2.106776, mean_eps: 0.100000
 564428/600000: episode: 749, duration: 16.579s, episode steps: 827, steps per second:  50, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.016467, mae: 1.744767, mean_q: 2.113648, mean_eps: 0.100000
 565178/600000: episode: 750, duration: 15.425s, episode steps: 750, steps per second:  49, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.014368, mae: 1.738271, mean_q: 2.105858, mean_eps: 0.100000
 566039/600000: episode: 751, duration: 17.744s, episode steps: 861, steps per second:  49, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.014504, mae: 1.729063, mean_q: 2.096011, mean_eps: 0.100000
 566994/600000: episode: 752, duration: 19.437s, episode steps: 955, steps per second:  49, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.947 [0.000, 5.000],  loss: 0.014479, mae: 1.735133, mean_q: 2.102633, mean_eps: 0.100000
 567704/600000: episode: 753, duration: 14.235s, episode steps: 710, steps per second:  50, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.013885, mae: 1.735460, mean_q: 2.103932, mean_eps: 0.100000
 568646/600000: episode: 754, duration: 18.739s, episode steps: 942, steps per second:  50, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.772 [0.000, 5.000],  loss: 0.015858, mae: 1.725409, mean_q: 2.091336, mean_eps: 0.100000
 569342/600000: episode: 755, duration: 12.597s, episode steps: 696, steps per second:  55, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.017288, mae: 1.750196, mean_q: 2.120916, mean_eps: 0.100000
 569911/600000: episode: 756, duration: 11.186s, episode steps: 569, steps per second:  51, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.018947, mae: 1.725360, mean_q: 2.088886, mean_eps: 0.100000
 570399/600000: episode: 757, duration: 9.826s, episode steps: 488, steps per second:  50, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.014569, mae: 1.766480, mean_q: 2.141308, mean_eps: 0.100000
 571335/600000: episode: 758, duration: 19.167s, episode steps: 936, steps per second:  49, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.887 [0.000, 5.000],  loss: 0.014224, mae: 1.771216, mean_q: 2.145148, mean_eps: 0.100000
 572398/600000: episode: 759, duration: 19.564s, episode steps: 1063, steps per second:  54, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.881 [0.000, 5.000],  loss: 0.015242, mae: 1.780378, mean_q: 2.158112, mean_eps: 0.100000
 573024/600000: episode: 760, duration: 11.587s, episode steps: 626, steps per second:  54, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.120 [0.000, 5.000],  loss: 0.014091, mae: 1.761699, mean_q: 2.136579, mean_eps: 0.100000
 573985/600000: episode: 761, duration: 18.363s, episode steps: 961, steps per second:  52, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.014440, mae: 1.779169, mean_q: 2.154506, mean_eps: 0.100000
 574675/600000: episode: 762, duration: 14.039s, episode steps: 690, steps per second:  49, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.015107, mae: 1.758738, mean_q: 2.130077, mean_eps: 0.100000
 575437/600000: episode: 763, duration: 14.458s, episode steps: 762, steps per second:  53, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.705 [0.000, 5.000],  loss: 0.016324, mae: 1.803571, mean_q: 2.185867, mean_eps: 0.100000
 576297/600000: episode: 764, duration: 17.026s, episode steps: 860, steps per second:  51, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.084 [0.000, 5.000],  loss: 0.014815, mae: 1.768564, mean_q: 2.142156, mean_eps: 0.100000
 577372/600000: episode: 765, duration: 23.673s, episode steps: 1075, steps per second:  45, episode reward: 27.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.115 [0.000, 5.000],  loss: 0.016341, mae: 1.764018, mean_q: 2.135908, mean_eps: 0.100000
 578012/600000: episode: 766, duration: 13.233s, episode steps: 640, steps per second:  48, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.015152, mae: 1.762535, mean_q: 2.133733, mean_eps: 0.100000
 578727/600000: episode: 767, duration: 14.828s, episode steps: 715, steps per second:  48, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.947 [0.000, 5.000],  loss: 0.015116, mae: 1.767549, mean_q: 2.139925, mean_eps: 0.100000
 579667/600000: episode: 768, duration: 19.356s, episode steps: 940, steps per second:  49, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.014899, mae: 1.749673, mean_q: 2.117677, mean_eps: 0.100000
 580236/600000: episode: 769, duration: 12.306s, episode steps: 569, steps per second:  46, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.054 [0.000, 5.000],  loss: 0.013941, mae: 1.779559, mean_q: 2.154024, mean_eps: 0.100000
 580955/600000: episode: 770, duration: 15.264s, episode steps: 719, steps per second:  47, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.013533, mae: 1.809251, mean_q: 2.190485, mean_eps: 0.100000
 581710/600000: episode: 771, duration: 15.892s, episode steps: 755, steps per second:  48, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013824, mae: 1.790854, mean_q: 2.168287, mean_eps: 0.100000
 582269/600000: episode: 772, duration: 11.605s, episode steps: 559, steps per second:  48, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.014552, mae: 1.798182, mean_q: 2.175868, mean_eps: 0.100000
 582789/600000: episode: 773, duration: 11.225s, episode steps: 520, steps per second:  46, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.014332, mae: 1.796192, mean_q: 2.172260, mean_eps: 0.100000
 583539/600000: episode: 774, duration: 16.008s, episode steps: 750, steps per second:  47, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.015499, mae: 1.807848, mean_q: 2.188990, mean_eps: 0.100000
 583990/600000: episode: 775, duration: 9.131s, episode steps: 451, steps per second:  49, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.016151, mae: 1.796410, mean_q: 2.176131, mean_eps: 0.100000
 585097/600000: episode: 776, duration: 22.885s, episode steps: 1107, steps per second:  48, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.015076, mae: 1.794315, mean_q: 2.172163, mean_eps: 0.100000
 586085/600000: episode: 777, duration: 21.057s, episode steps: 988, steps per second:  47, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.017772, mae: 1.791889, mean_q: 2.169004, mean_eps: 0.100000
 587295/600000: episode: 778, duration: 22.217s, episode steps: 1210, steps per second:  54, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.017823, mae: 1.814603, mean_q: 2.197502, mean_eps: 0.100000
 588130/600000: episode: 779, duration: 17.049s, episode steps: 835, steps per second:  49, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.660 [0.000, 5.000],  loss: 0.014486, mae: 1.802304, mean_q: 2.182326, mean_eps: 0.100000
 588894/600000: episode: 780, duration: 15.343s, episode steps: 764, steps per second:  50, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.043 [0.000, 5.000],  loss: 0.015738, mae: 1.791665, mean_q: 2.169355, mean_eps: 0.100000
 589905/600000: episode: 781, duration: 18.767s, episode steps: 1011, steps per second:  54, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.014524, mae: 1.797759, mean_q: 2.177524, mean_eps: 0.100000
 590513/600000: episode: 782, duration: 11.186s, episode steps: 608, steps per second:  54, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.012974, mae: 1.846849, mean_q: 2.238193, mean_eps: 0.100000
 591416/600000: episode: 783, duration: 16.326s, episode steps: 903, steps per second:  55, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.821 [0.000, 5.000],  loss: 0.014709, mae: 1.841655, mean_q: 2.230490, mean_eps: 0.100000
 591989/600000: episode: 784, duration: 10.386s, episode steps: 573, steps per second:  55, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.015198, mae: 1.855440, mean_q: 2.246612, mean_eps: 0.100000
 592623/600000: episode: 785, duration: 12.396s, episode steps: 634, steps per second:  51, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.014886, mae: 1.839743, mean_q: 2.226480, mean_eps: 0.100000
 593120/600000: episode: 786, duration: 9.097s, episode steps: 497, steps per second:  55, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.014128, mae: 1.815280, mean_q: 2.198636, mean_eps: 0.100000
 593684/600000: episode: 787, duration: 11.160s, episode steps: 564, steps per second:  51, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.014891, mae: 1.842676, mean_q: 2.232332, mean_eps: 0.100000
 594277/600000: episode: 788, duration: 12.516s, episode steps: 593, steps per second:  47, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.014261, mae: 1.873516, mean_q: 2.269041, mean_eps: 0.100000
 595647/600000: episode: 789, duration: 29.042s, episode steps: 1370, steps per second:  47, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.934 [0.000, 5.000],  loss: 0.016230, mae: 1.840703, mean_q: 2.228003, mean_eps: 0.100000
 596115/600000: episode: 790, duration: 9.539s, episode steps: 468, steps per second:  49, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.014221, mae: 1.857705, mean_q: 2.251209, mean_eps: 0.100000
 596790/600000: episode: 791, duration: 13.870s, episode steps: 675, steps per second:  49, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.056 [0.000, 5.000],  loss: 0.014915, mae: 1.852045, mean_q: 2.244174, mean_eps: 0.100000
 597658/600000: episode: 792, duration: 18.752s, episode steps: 868, steps per second:  46, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.017160, mae: 1.874253, mean_q: 2.269100, mean_eps: 0.100000
 598257/600000: episode: 793, duration: 13.624s, episode steps: 599, steps per second:  44, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.015425, mae: 1.836556, mean_q: 2.224198, mean_eps: 0.100000
 599001/600000: episode: 794, duration: 16.082s, episode steps: 744, steps per second:  46, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.018371, mae: 1.863210, mean_q: 2.254971, mean_eps: 0.100000
 599801/600000: episode: 795, duration: 17.841s, episode steps: 800, steps per second:  45, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.016078, mae: 1.861354, mean_q: 2.251719, mean_eps: 0.100000
done, took 11462.250 seconds
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUehXgCyIRdq"
   },
   "source": [
    "# Actividad - Proyecto práctico\n",
    "\n",
    "\n",
    "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
    "*   Alumno 1: Gil Garcera, Javier \n",
    "*   Alumno 2: Palomares Mateo, Abel \n",
    "*   Alumno 3: Serrano López, Francisco Rubén \n",
    "*   Alumno 4: Vegas Romero, David \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwpYlnjWJhS9"
   },
   "source": [
    "---\n",
    "## **PARTE 1** - Instalación y requisitos previos\n",
    "\n",
    "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
    "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
    "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
    "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
    "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU2BPrK2JkP0"
   },
   "source": [
    "---\n",
    "### 1.1. Preparar enviroment (solo local)\n",
    "\n",
    "\n",
    "\n",
    "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
    "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
    "2. Instalar Anaconda\n",
    "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
    "\n",
    "\n",
    "```\n",
    "conda create --name miar_rl python=3.8\n",
    "conda activate miar_rl\n",
    "cd \"PATH_TO_FOLDER\"\n",
    "conda install git\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "\n",
    "4. Abrir la notebook con *jupyter-notebook*.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "jupyter-notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-kixNPiJqTc"
   },
   "source": [
    "---\n",
    "### 1.2. Localizar entorno de trabajo: Google colab o local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S_YDFwZ-JscI"
   },
   "outputs": [],
   "source": [
    "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
    "mount='/content/gdrive'\n",
    "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dp_a1iBJ0tf"
   },
   "source": [
    "---\n",
    "### 1.3. Montar carpeta de datos local (solo Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I6n7MIefJ21i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en el directorio: \n",
      "['dqn_SpaceInvaders-v0_weights_250000.h5f.index', 'dqn_SpaceInvaders-v0_weights_10000.h5f.index', 'dqn_SpaceInvaders-v0_weights_1000000.h5f.data-00000-of-00001', 'Proyecto_práctico_16_4.ipynb', '.jupyter', 'dqn_SpaceInvaders-v0_weights_1750000.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_log.json', 'alternativa_google_collab.txt', 'dqn_SpaceInvaders-v0_weights_500000.h5f.data-00000-of-00001', 'Proyecto_práctico.ipynb', 'dqn_SpaceInvaders-v0_weights_750000.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_weights_1750000.h5f.index', 'dqn_SpaceInvaders-v0_weights.h5f.index', 'dqn_SpaceInvaders-v0_weights_1500000.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_weights_1250000.h5f.data-00000-of-00001', 'Proyecto_práctico_16_3.ipynb', 'dqn_SpaceInvaders-v0_weights_500000.h5f.index', 'pesos_16_4', 'dqn_SpaceInvaders-v0_weights_1000000.h5f.index', 'dqn_SpaceInvaders-v0_weights_10000.h5f.data-00000-of-00001', 'Proyecto_práctico_local.ipynb', 'dqn_SpaceInvaders-v0_weights_1500000.h5f.index', 'README.md', '.ipynb_checkpoints', '.git', 'dqn_SpaceInvaders-v0_weights.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_weights_1250000.h5f.index', '.gitignore', 'dqn_SpaceInvaders-v0_weights_250000.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_weights_750000.h5f.index', 'checkpoint']\n"
     ]
    }
   ],
   "source": [
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    # Mount the Google Drive at mount\n",
    "    print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "    drive.mount(mount)\n",
    "\n",
    "    # Create drive_root if it doesn't exist\n",
    "    create_drive_root = True\n",
    "    if create_drive_root:\n",
    "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "      os.makedirs(drive_root, exist_ok=True)\n",
    "\n",
    "    # Change to the directory\n",
    "    print(\"\\nColab: Changing directory to \", drive_root)\n",
    "    %cd $drive_root\n",
    "# Verify we're in the correct working directory\n",
    "%pwd\n",
    "print(\"Archivos en el directorio: \")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1ZSL5bpJ560"
   },
   "source": [
    "---\n",
    "### 1.4. Instalar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UbVRjvHCJ8UF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting numpy==1.23.5\n",
      "  Using cached numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Using cached numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.3 requires numpy~=1.19.2, but you have numpy 1.23.5 which is incompatible.\n",
      "tensorflow 2.5.3 requires typing-extensions~=3.7.4, but you have typing-extensions 4.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: gym==0.17.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (0.17.3)\n",
      "Requirement already satisfied: scipy in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym==0.17.3) (1.23.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting git+https://github.com/Kojoley/atari-py.git\n",
      "  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-48pvqosb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-48pvqosb\n",
      "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from atari-py==1.2.2) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: pyglet==1.5.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: future in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyglet==1.5.0) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting h5py==3.10.0\n",
      "  Using cached h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from h5py==3.10.0) (1.23.5)\n",
      "Using cached h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Installing collected packages: h5py\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.3 requires h5py~=3.1.0, but you have h5py 3.10.0 which is incompatible.\n",
      "tensorflow 2.5.3 requires numpy~=1.19.2, but you have numpy 1.23.5 which is incompatible.\n",
      "tensorflow 2.5.3 requires typing-extensions~=3.7.4, but you have typing-extensions 4.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h5py-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: Pillow==9.5.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: keras-rl2==1.0.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from keras-rl2==1.0.5) (2.5.3)\n",
      "Collecting numpy~=1.19.2 (from tensorflow->keras-rl2==1.0.5)\n",
      "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
      "Collecting h5py~=3.1.0 (from tensorflow->keras-rl2==1.0.5)\n",
      "  Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.0)\n",
      "Collecting typing-extensions~=3.7.4 (from tensorflow->keras-rl2==1.0.5)\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->keras-rl2==1.0.5) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
      "Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: typing-extensions, numpy, h5py\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.10.0\n",
      "    Uninstalling h5py-3.10.0:\n",
      "      Successfully uninstalled h5py-3.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anyio 4.5.2 requires typing-extensions>=4.1; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "async-lru 2.0.4 requires typing-extensions>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "beautifulsoup4 4.13.4 requires typing-extensions>=4.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "exceptiongroup 1.3.0 requires typing-extensions>=4.6.0; python_version < \"3.13\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "jax 0.4.13 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
      "ml-dtypes 0.2.0 requires numpy>1.20, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h5py-3.1.0 numpy-1.19.5 typing-extensions-3.7.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting Keras==2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: Keras\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.2.4\n",
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed Keras-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting tensorflow==2.12.1\n",
      "  Using cached tensorflow-2.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.12.1)\n",
      "  Using cached absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (1.6.3)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow==2.12.1)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (1.34.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (3.1.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (18.1.1)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.12.1)\n",
      "  Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (1.15.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.1)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.1)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow==2.12.1) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.12.1) (0.44.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow==2.12.1) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow==2.12.1) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow==2.12.1) (8.5.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.12.1)\n",
      "  Using cached grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.40.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.1)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.32.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow==2.12.1)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow==2.12.1) (3.20.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.3.0)\n",
      "Using cached tensorflow-2.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "Using cached absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Using cached grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Installing collected packages: flatbuffers, tensorflow-estimator, tensorboard-data-server, numpy, grpcio, absl-py, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.3\n",
      "    Uninstalling tensorflow-2.5.3:\n",
      "      Successfully uninstalled tensorflow-2.5.3\n",
      "Successfully installed absl-py-2.3.0 flatbuffers-25.2.10 google-auth-oauthlib-1.0.0 grpcio-1.70.0 numpy-1.24.3 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.1 tensorflow-estimator-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: torch==2.0.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (3.7.4.3)\n",
      "Requirement already satisfied: sympy in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
      "Requirement already satisfied: wheel in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
      "Requirement already satisfied: cmake in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1) (4.0.3)\n",
      "Requirement already satisfied: lit in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: /home/fraserlp/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: agents==1.4.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: tensorflow in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from agents==1.4.0) (2.12.1)\n",
      "Requirement already satisfied: gym in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from agents==1.4.0) (0.17.3)\n",
      "Requirement already satisfied: ruamel.yaml in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from agents==1.4.0) (0.18.14)\n",
      "Requirement already satisfied: scipy in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym->agents==1.4.0) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym->agents==1.4.0) (1.24.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym->agents==1.4.0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from gym->agents==1.4.0) (1.6.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from ruamel.yaml->agents==1.4.0) (0.2.8)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (1.70.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (3.1.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorflow->agents==1.4.0) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->agents==1.4.0) (0.44.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow->agents==1.4.0) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow->agents==1.4.0) (8.5.0)\n",
      "Requirement already satisfied: future in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym->agents==1.4.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow->agents==1.4.0) (3.20.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/fraserlp/anaconda3/envs/miar_rl/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->agents==1.4.0) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install tensorflow==2.8\n",
    "  %pip install tensorflow==2.12.1\n",
    "else:\n",
    "  %pip install numpy==1.23.5\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install pyglet==1.5.0\n",
    "  %pip install h5py==3.10.0\n",
    "  %pip install Pillow==9.5.0\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install Keras==2.12.0\n",
    "  %pip install tensorflow==2.12.1\n",
    "  %pip install torch==2.0.1\n",
    "  %pip install agents==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hzP_5ZuGb2X"
   },
   "source": [
    "---\n",
    "## **PARTE 2**. Enunciado\n",
    "\n",
    "Consideraciones a tener en cuenta:\n",
    "\n",
    "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
    "\n",
    "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
    "\n",
    "Este proyecto práctico consta de tres partes:\n",
    "\n",
    "1.   Implementar la red neuronal que se usará en la solución\n",
    "2.   Implementar las distintas piezas de la solución DQN\n",
    "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
    "\n",
    "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
    "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
    "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
    "* Cada alumno deberá de subir la solución de forma individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_b3mzw8IzJP"
   },
   "source": [
    "---\n",
    "## **PARTE 3**. Desarrollo y preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duPmUNOVGb2a"
   },
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j3eRhgI-Gb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.0.1+cu117\n",
      "¿GPU disponible? [torch]: True\n",
      "Nombre de GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "TensorFlow: 2.12.1\n",
      "GPUs detectadas [tf]: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"¿GPU disponible? [torch]:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nombre de GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs detectadas [tf]:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4jgQjzoGb2a"
   },
   "source": [
    "#### Configuración base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jwOE6I_KGb2a"
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "env_name = 'SpaceInvaders-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9jGEZUcpGb2a"
   },
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yitXTADGb2b"
   },
   "source": [
    "1. Implementación de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O4GKrfWSGb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de acciones disponibles:6\n",
      "Formato de las observaciones:\n",
      "channels_last\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute (Permute)           (None, 84, 84, 4)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de acciones disponibles:\" + str(nb_actions))\n",
    "print(\"Formato de las observaciones:\")\n",
    "#env.observation_space\n",
    "## Next, we build a very simple model.\n",
    "#model = Sequential()\n",
    "#model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "#model.add(Dense(16))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(16))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(16))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(nb_actions))\n",
    "#model.add(Activation('linear'))\n",
    "#print(model.summary())\n",
    "\n",
    "\n",
    "# Next, we build our model. We use the same model that was described by Mnih et al. (2015).\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "print(K.image_data_format())\n",
    "if K.image_data_format() == 'channels_last':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_data_format() == 'channels_first':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\"\"\"\n",
    "from keras.layers import Lambda, Add, Subtract, Multiply, Reshape\n",
    "\n",
    "# Suponiendo que tu output antes era:\n",
    "features = Dense(512, activation='relu')(flattened)\n",
    "\n",
    "# Dueling DQN\n",
    "value = Dense(1, activation='linear')(features)\n",
    "advantage = Dense(nb_actions, activation='linear')(features)\n",
    "advantage_mean = Lambda(lambda x: K.mean(x, axis=1, keepdims=True))(advantage)\n",
    "q_values = Add()([value, Subtract()([advantage, advantage_mean])])\n",
    "\n",
    "model = Model(inputs=inputs, outputs=q_values)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Let's define the memory for storing the experience\\nmemory = SequentialMemory(limit=50000, window_length=1)\\n\\n# Define the policy that our agent will follow\\npolicy = BoltzmannQPolicy()\\n\\n# Define the agent\\ndqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,\\n               nb_steps_warmup=10,\\n               target_model_update=1e-2, policy=policy)\\n\\nadam_obj = Adam(learning_rate=1e-3)\\ndqn.compile(adam_obj, metrics=['mae'])\\n\\n# Train the agent\\ndqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\\n\\n# After training is done, we save the final weights.\\ndqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\\n# Finally, evaluate our algorithm for 5 episodes.\\ndqn.load_weights('dqn_{}_weights.h5f'.format(ENV_NAME))\\ndqn.test(env, nb_episodes=10, visualize=False)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Let's define the memory for storing the experience\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "\n",
    "# Define the policy that our agent will follow\n",
    "policy = BoltzmannQPolicy()\n",
    "\n",
    "# Define the agent\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
    "               nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "\n",
    "adam_obj = Adam(learning_rate=1e-3)\n",
    "dqn.compile(adam_obj, metrics=['mae'])\n",
    "\n",
    "# Train the agent\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.load_weights('dqn_{}_weights.h5f'.format(ENV_NAME))\n",
    "dqn.test(env, nb_episodes=10, visualize=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 00:42:25.103624: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: INTERNAL: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.\n",
      "2025-07-01 00:42:25.103649: E tensorflow/c/c_api.cc:2218] INTERNAL: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#               memory=memory, processor=processor,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#               nb_steps_warmup=50000, gamma=.99,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#               target_model_update=10000,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#               train_interval=4)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dqn \u001b[38;5;241m=\u001b[39m DQNAgent(model\u001b[38;5;241m=\u001b[39mmodel, nb_actions\u001b[38;5;241m=\u001b[39mnb_actions, policy\u001b[38;5;241m=\u001b[39mpolicy,\n\u001b[1;32m     15\u001b[0m                memory\u001b[38;5;241m=\u001b[39mmemory, processor\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[1;32m     16\u001b[0m                nb_steps_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.995\u001b[39m,\n\u001b[1;32m     17\u001b[0m                target_model_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m,\n\u001b[1;32m     18\u001b[0m                train_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.00025\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Training part\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5f'\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#log_filename = 'dqn_{}_log.json'.format(env_name)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#callbacks += [FileLogger(log_filename, interval=100)]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/rl/agents/dqn.py:167\u001b[0m, in \u001b[0;36mDQNAgent.compile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    164\u001b[0m metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [mean_q]  \u001b[38;5;66;03m# register default metrics\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# We never train the target model, hence we can set the optimizer and loss arbitrarily.\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_model \u001b[38;5;241m=\u001b[39m \u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_model_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/rl/util.py:16\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, custom_objects)\u001b[0m\n\u001b[1;32m     11\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mget_config(),\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m clone \u001b[38;5;241m=\u001b[39m model_from_config(config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects)\n\u001b[0;32m---> 16\u001b[0m clone\u001b[38;5;241m.\u001b[39mset_weights(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/keras/engine/training_v1.py:165\u001b[0m, in \u001b[0;36mModel.get_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m base_layer\u001b[38;5;241m.\u001b[39mLayer\u001b[38;5;241m.\u001b[39mget_weights(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/keras/engine/base_layer.py:1883\u001b[0m, in \u001b[0;36mLayer.get_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1882\u001b[0m         output_weights\u001b[38;5;241m.\u001b[39mappend(weight)\n\u001b[0;32m-> 1883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/keras/backend.py:4253\u001b[0m, in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   4251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensors:\n\u001b[0;32m-> 4253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrun(tensors)\n\u001b[1;32m   4254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/keras/backend.py:783\u001b[0m, in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.backend.get_session\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_session\u001b[39m(op_input_list\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the TF session to be used by the backend.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    If a default TensorFlow session is available, we will return it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m        A TensorFlow session.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43m_get_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_input_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _MANUAL_VAR_INIT:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mas_default():\n",
      "File \u001b[0;32m~/anaconda3/envs/miar_rl/lib/python3.8/site-packages/keras/backend.py:753\u001b[0m, in \u001b[0;36m_get_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    749\u001b[0m             configure_and_create_distributed_session(\n\u001b[1;32m    750\u001b[0m                 tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m    751\u001b[0m             )\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m             _SESSION\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_default_session_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m     session \u001b[38;5;241m=\u001b[39m _SESSION\u001b[38;5;241m.\u001b[39msession\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found."
     ]
    }
   ],
   "source": [
    "#memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "memory = SequentialMemory(limit=2000000, window_length=WINDOW_LENGTH)\n",
    "processor = AtariProcessor()\n",
    "\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
    "                              value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=2000000)\n",
    "#dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
    "#               memory=memory, processor=processor,\n",
    "#               nb_steps_warmup=50000, gamma=.99,\n",
    "#               target_model_update=10000,\n",
    "#               train_interval=4)\n",
    "\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
    "               memory=memory, processor=processor,\n",
    "               nb_steps_warmup=50000, gamma=0.995,\n",
    "               target_model_update=50000,\n",
    "               train_interval=4)\n",
    "\n",
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])\n",
    "\n",
    "# Training part\n",
    "#weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
    "#checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5f'\n",
    "#log_filename = 'dqn_{}_log.json'.format(env_name)\n",
    "#callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "#callbacks += [FileLogger(log_filename, interval=100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB9-_5HPGb2b"
   },
   "source": [
    "2. Implementación de la solución DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "foSlxWH1Gb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1750000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "28168/50000 [===============>..............] - ETA: 45s - reward: 0.0139done, took 58.687 seconds\n"
     ]
    }
   ],
   "source": [
    "#dqn.fit(env, callbacks=callbacks, nb_steps=1750000, log_interval=10000, visualize=False)\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=1750000, log_interval=50000, visualize=False)\n",
    "\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OHYryKd1Gb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 18.000, steps: 1091\n",
      "Episode 2: reward: 14.000, steps: 798\n",
      "Episode 3: reward: 12.000, steps: 903\n",
      "Episode 4: reward: 21.000, steps: 875\n",
      "Episode 5: reward: 21.000, steps: 856\n",
      "Episode 6: reward: 19.000, steps: 1151\n",
      "Episode 7: reward: 6.000, steps: 617\n",
      "Episode 8: reward: 15.000, steps: 543\n",
      "Episode 9: reward: 24.000, steps: 884\n",
      "Episode 10: reward: 13.000, steps: 716\n",
      "Media de la recompensa obtenida en 10 episodios: 16.3\n",
      "Desviación estandar de la recompensa obtenida en 10 episodios: 5.060632371551998\n"
     ]
    }
   ],
   "source": [
    "# Testing part to calculate the mean reward\n",
    "weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
    "dqn.load_weights(weights_filename)\n",
    "history = dqn.test(env, nb_episodes=10, visualize=False)\n",
    "recompensas = history.history.get('episode_reward', [])\n",
    "print(f\"Media de la recompensa obtenida en 10 episodios: {np.mean(np.array(recompensas))}\")\n",
    "print(f\"Desviación estandar de la recompensa obtenida en 10 episodios: {np.std(np.array(recompensas))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NAlu8b1Gb2b"
   },
   "source": [
    "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANFQiicXK3sO"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
